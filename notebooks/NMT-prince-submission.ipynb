{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Spring 2018 NLP Class Project: Neural Machine Translation</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "# from sacreBLEU.sacreBLEU import corpus_bleu\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pdb\n",
    "import os\n",
    "from underthesea import word_tokenize\n",
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# running on cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Project Overview\n",
    "\n",
    "The goal of this project is to build a neural machine translation system and experience how recent advances have made their way. Each team will build the following sequence of neural translation systems for two language pairs, __Vietnamese (Vi)→English (En)__ and __Chinese (Zh)→En__ (prepared corpora is be provided):\n",
    "\n",
    "1. Recurrent neural network based encoder-decoder without attention\n",
    "2. Recurrent neural network based encoder-decoder with attention\n",
    "2. Replace the recurrent encoder with either convolutional or self-attention based encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Upload & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = 2\n",
    "PAD_IDX = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(path):\n",
    "    f = open(path)\n",
    "    list_l = []\n",
    "    for line in f:\n",
    "        list_l.append(line.strip())\n",
    "    data = pd.DataFrame()\n",
    "    data[\"data\"] = list_l\n",
    "    return data\n",
    "\n",
    "# vietnamese -> english\n",
    "vien_en_train = read_dataset(\"data/iwslt-vi-en/train.tok.en\")\n",
    "vien_en_val = read_dataset(\"data/iwslt-vi-en/dev.tok.en\")\n",
    "\n",
    "vien_vi_train = read_dataset(\"data/iwslt-vi-en/train.tok.vi\")\n",
    "vien_vi_val = read_dataset(\"data/iwslt-vi-en/dev.tok.vi\")\n",
    "\n",
    "# chinese -> english\n",
    "zhen_en_train = read_dataset(\"data/iwslt-zh-en/train.tok.en\")\n",
    "zhen_en_val = read_dataset(\"data/iwslt-zh-en/dev.tok.en\")\n",
    "\n",
    "zhen_zh_train = read_dataset(\"data/iwslt-zh-en/train.tok.zh\")\n",
    "zhen_zh_val = read_dataset(\"data/iwslt-zh-en/dev.tok.zh\")\n",
    "\n",
    "# TEST\n",
    "# vietnamese -> english\n",
    "vien_en_test = read_dataset(\"data/iwslt-vi-en/test.tok.en\")\n",
    "vien_vi_test = read_dataset(\"data/iwslt-vi-en/test.tok.vi\")\n",
    "# chinese -> english\n",
    "zhen_en_test = read_dataset(\"data/iwslt-zh-en/test.tok.en\")\n",
    "zhen_zh_test = read_dataset(\"data/iwslt-zh-en/test.tok.zh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chinese -> english\n",
    "zhen_train = pd.DataFrame()\n",
    "zhen_train[\"en_data\"] = zhen_en_train[\"data\"]\n",
    "zhen_train[\"zh_data\"] = zhen_zh_train[\"data\"]\n",
    "\n",
    "# vietnamese -> english\n",
    "vien_train = pd.DataFrame()\n",
    "vien_train[\"en_data\"] = vien_en_train[\"data\"]\n",
    "vien_train[\"vi_data\"] = vien_vi_train[\"data\"]\n",
    "\n",
    "# chinese -> english\n",
    "zhen_val = pd.DataFrame()\n",
    "zhen_val[\"en_data\"] = zhen_en_val[\"data\"]\n",
    "zhen_val[\"zh_data\"] = zhen_zh_val[\"data\"]\n",
    "\n",
    "# vietnamese -> english\n",
    "vien_val = pd.DataFrame()\n",
    "vien_val[\"en_data\"] = vien_en_val[\"data\"]\n",
    "vien_val[\"vi_data\"] = vien_vi_val[\"data\"]\n",
    "\n",
    "# TEST: vietnamese -> english\n",
    "vien_test = pd.DataFrame()\n",
    "vien_test[\"en_data\"] = vien_en_test[\"data\"]\n",
    "vien_test[\"vi_data\"] = vien_vi_test[\"data\"]\n",
    "\n",
    "# TEST: chinese -> english\n",
    "zhen_test = pd.DataFrame()\n",
    "zhen_test[\"en_data\"] = zhen_en_test[\"data\"]\n",
    "zhen_test[\"zh_data\"] = zhen_zh_test[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<UNK>\",3:\"<PAD>\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word.lower())\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from lab notebook\n",
    "def unicodeToAscii(s):\n",
    "    \"\"\"About \"NFC\" and \"NFD\": \n",
    "    \n",
    "    For each character, there are two normal forms: normal form C \n",
    "    and normal form D. Normal form D (NFD) is also known as canonical \n",
    "    decomposition, and translates each character into its decomposed form. \n",
    "    Normal form C (NFC) first applies a canonical decomposition, then composes \n",
    "    pre-combined characters again.\n",
    "    \n",
    "    About unicodedata.category: \n",
    "    \n",
    "    Returns the general category assigned to the Unicode character \n",
    "    unichr as string.\"\"\"\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def data_tok(data, lang=\"vi\"):\n",
    "    \n",
    "    data[\"en_tokenized\"] = data[\"en_data\"].apply(lambda x: x.lower().split( ))\n",
    "    \n",
    "    if lang == \"vi\":\n",
    "        data[\"vi_tokenized\"] = data[\"vi_data\"].apply(lambda x: x.lower().split( ))\n",
    "    else:\n",
    "        data[\"zh_tokenized\"] = data[\"zh_data\"].apply(lambda x: x.lower().split( ))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vietnamese -> english\n",
    "vien_en_ = Lang(\"vien_en\")\n",
    "for s in vien_train[\"en_data\"]:\n",
    "    vien_en_.addSentence(s)\n",
    "    \n",
    "vien_vi_ = Lang(\"vi\")\n",
    "for s in vien_train[\"vi_data\"]:\n",
    "    vien_vi_.addSentence(s)\n",
    "    \n",
    "# chinese -> english\n",
    "zhen_en_ = Lang(\"zhen_en\")\n",
    "for s in zhen_train[\"en_data\"]:\n",
    "    zhen_en_.addSentence(s)\n",
    "    \n",
    "zhen_zh_ = Lang(\"zh\")\n",
    "for s in zhen_train[\"zh_data\"]:\n",
    "    zhen_zh_.addSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "# vietnamese -> english\n",
    "vien_train = data_tok(vien_train, lang=\"vi\")\n",
    "\n",
    "# chinese -> english\n",
    "zhen_train = data_tok(zhen_train, lang=\"zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_data</th>\n",
       "      <th>zh_data</th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>zh_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life in the deep oceans</td>\n",
       "      <td>深海 海中 的 生命   大卫   盖罗</td>\n",
       "      <td>[life, in, the, deep, oceans]</td>\n",
       "      <td>[深海, 海中, 的, 生命, 大卫, 盖罗]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>With vibrant video clips captured by submarine...</td>\n",
       "      <td>大卫   盖罗 通过 潜水 潜水艇 拍下 的 影片 把 我们 带到 了 地球 最 黑暗   ...</td>\n",
       "      <td>[with, vibrant, video, clips, captured, by, su...</td>\n",
       "      <td>[大卫, 盖罗, 通过, 潜水, 潜水艇, 拍下, 的, 影片, 把, 我们, 带到, 了,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is Bill Lange . I &amp;apos;m Dave Gallo .</td>\n",
       "      <td>大卫   盖罗   这位 是 比尔   兰格    我 是 大卫   盖罗</td>\n",
       "      <td>[this, is, bill, lange, ., i, &amp;apos;m, dave, g...</td>\n",
       "      <td>[大卫, 盖罗, 这位, 是, 比尔, 兰格, 我, 是, 大卫, 盖罗]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             en_data  \\\n",
       "0                            Life in the deep oceans   \n",
       "1  With vibrant video clips captured by submarine...   \n",
       "2        This is Bill Lange . I &apos;m Dave Gallo .   \n",
       "\n",
       "                                             zh_data  \\\n",
       "0                               深海 海中 的 生命   大卫   盖罗   \n",
       "1  大卫   盖罗 通过 潜水 潜水艇 拍下 的 影片 把 我们 带到 了 地球 最 黑暗   ...   \n",
       "2              大卫   盖罗   这位 是 比尔   兰格    我 是 大卫   盖罗   \n",
       "\n",
       "                                        en_tokenized  \\\n",
       "0                      [life, in, the, deep, oceans]   \n",
       "1  [with, vibrant, video, clips, captured, by, su...   \n",
       "2  [this, is, bill, lange, ., i, &apos;m, dave, g...   \n",
       "\n",
       "                                        zh_tokenized  \n",
       "0                            [深海, 海中, 的, 生命, 大卫, 盖罗]  \n",
       "1  [大卫, 盖罗, 通过, 潜水, 潜水艇, 拍下, 的, 影片, 把, 我们, 带到, 了,...  \n",
       "2              [大卫, 盖罗, 这位, 是, 比尔, 兰格, 我, 是, 大卫, 盖罗]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "# vietnamese -> english\n",
    "vien_val = data_tok(vien_val, lang=\"vi\")\n",
    "# chinese -> english\n",
    "zhen_val = data_tok(zhen_val, lang=\"zh\")\n",
    "\n",
    "# TEST\n",
    "vien_test = data_tok(vien_test, lang=\"vi\")\n",
    "zhen_test = data_tok(zhen_test, lang=\"zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2index_dataset(data, source_language=\"zh\"):\n",
    "    \n",
    "    if source_language == \"zh\" and \"zh_data\" not in [*data.columns]:\n",
    "        raise ValueError, \"Source language should be compatible with the data you pass!\"\n",
    "    elif source_language == \"vi\" and \"vi_data\" not in [*data.columns]:\n",
    "        raise ValueError, \"Source language should be compatible with the data you pass!\"\n",
    "    else:   \n",
    "        if source_language == \"zh\":\n",
    "            # chinese -> english\n",
    "            for language in [\"en\",\"zh\"]:\n",
    "                indices_data = []\n",
    "                if language == \"en\":\n",
    "                    lang_obj = zhen_en_\n",
    "                else:\n",
    "                    lang_obj = zhen_zh_\n",
    "\n",
    "                for tokens in data[language + \"_tokenized\"]:\n",
    "\n",
    "                    index_list = [lang_obj.word2index[token] if \\\n",
    "                                  token in lang_obj.word2index else UNK_IDX \\\n",
    "                                  for token in tokens]\n",
    "                    index_list.append(EOS_token)\n",
    "                    indices_data.append(index_list)\n",
    "\n",
    "                data[language + \"_indices\"] = indices_data\n",
    "        else:\n",
    "            # vietnamese -> english\n",
    "            for language in [\"en\",\"vi\"]:\n",
    "                indices_data = []\n",
    "                if language == \"en\":\n",
    "                    lang_obj = vien_en_\n",
    "                else:\n",
    "                    lang_obj = vien_vi_\n",
    "\n",
    "                for tokens in data[language + \"_tokenized\"]:\n",
    "\n",
    "                    index_list = [lang_obj.word2index[token] if \\\n",
    "                                  token in lang_obj.word2index else UNK_IDX \\\n",
    "                                  for token in tokens]\n",
    "                    index_list.append(EOS_token)\n",
    "                    indices_data.append(index_list)\n",
    "\n",
    "                data[language + \"_indices\"] = indices_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "# vietnamese -> english\n",
    "vien_train = token2index_dataset(vien_train, \n",
    "                                 source_language=\"vi\")\n",
    "# chinese -> english\n",
    "zhen_train = token2index_dataset(zhen_train, \n",
    "                                 source_language=\"zh\")\n",
    "\n",
    "# validation\n",
    "# vietnamese -> english\n",
    "vien_val = token2index_dataset(vien_val, \n",
    "                               source_language=\"vi\")\n",
    "# chinese -> english\n",
    "zhen_val = token2index_dataset(zhen_val, \n",
    "                               source_language=\"zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# vietnamese -> english\n",
    "vien_test = token2index_dataset(vien_test, source_language=\"vi\")\n",
    "# chinese -> english\n",
    "zhen_test = token2index_dataset(zhen_test, source_language=\"zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# vietnamese -> english\n",
    "class Vietnamese(Dataset):\n",
    "    \n",
    "    def __init__(self, data, val = False):\n",
    "        self.data = data\n",
    "        self.val = val\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        english = self.data.iloc[idx,:][\"en_indices\"]\n",
    "        vietnamese = self.data.iloc[idx,:][\"vi_indices\"]\n",
    "        en_lengths = self.data.iloc[idx,:][\"en_lengths\"]\n",
    "        vi_lengths = self.data.iloc[idx,:][\"vi_lengths\"]\n",
    "        \n",
    "        if self.val:\n",
    "            en_data = self.data.iloc[idx,:][\"en_data\"].lower()\n",
    "            return [vietnamese, english, vi_lengths, en_lengths, en_data]\n",
    "        else:\n",
    "            return [vietnamese, english, vi_lengths, en_lengths]\n",
    "    \n",
    "# chinese -> english\n",
    "class Chinese(Dataset):\n",
    "    def __init__(self, data, val = False):\n",
    "        self.data = data\n",
    "        self.val = val\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        english = self.data.iloc[idx,:][\"en_indices\"]\n",
    "        chinese = self.data.iloc[idx,:][\"zh_indices\"]\n",
    "        en_lengths = self.data.iloc[idx,:][\"en_lengths\"]\n",
    "        zh_lengths = self.data.iloc[idx,:][\"zh_lengths\"]\n",
    "        \n",
    "        if self.val:\n",
    "            en_data = self.data.iloc[idx,:][\"en_data\"].lower()\n",
    "            return [chinese, english, zh_lengths, en_lengths, en_data]\n",
    "        else:\n",
    "            return [chinese, english, zh_lengths, en_lengths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lengths \n",
    "max_len_ = 30\n",
    "min_len_ = 2\n",
    "\n",
    "# vietnamese -> english\n",
    "# train\n",
    "vien_train[\"en_lengths\"] = vien_train[\"en_indices\"].apply(lambda x: len(x))\n",
    "vien_train[\"vi_lengths\"] = vien_train[\"vi_indices\"].apply(lambda x:len(x))\n",
    "vien_train = vien_train[np.logical_and(vien_train[\"en_lengths\"]>=min_len_,\n",
    "                                       vien_train[\"vi_lengths\"]>=min_len_)]\n",
    "vien_train = vien_train[vien_train[\"vi_lengths\"]<=max_len_]\n",
    "\n",
    "# val\n",
    "vien_val[\"en_lengths\"] = vien_val[\"en_indices\"].apply(lambda x: len(x))\n",
    "vien_val[\"vi_lengths\"] = vien_val[\"vi_indices\"].apply(lambda x:len(x))\n",
    "vien_val = vien_val[np.logical_and(vien_val[\"en_lengths\"]>=min_len_,\n",
    "                                   vien_val[\"vi_lengths\"]>=min_len_)]\n",
    "vien_val = vien_val[vien_val[\"vi_lengths\"]<=max_len_]\n",
    "\n",
    "# chinese -> english\n",
    "# train\n",
    "zhen_train[\"en_lengths\"] = zhen_train[\"en_indices\"].apply(lambda x: len(x))\n",
    "zhen_train[\"zh_lengths\"] = zhen_train[\"zh_indices\"].apply(lambda x:len(x))\n",
    "zhen_train = zhen_train[np.logical_and(zhen_train[\"en_lengths\"]>=min_len_,\n",
    "                                       zhen_train[\"zh_lengths\"]>=min_len_)]\n",
    "zhen_train = zhen_train[zhen_train[\"zh_lengths\"]<=max_len_]\n",
    "# val\n",
    "zhen_val[\"en_lengths\"] = zhen_val[\"en_indices\"].apply(lambda x: len(x))\n",
    "zhen_val[\"zh_lengths\"] = zhen_val[\"zh_indices\"].apply(lambda x:len(x))\n",
    "zhen_val = zhen_val[np.logical_and(zhen_val[\"en_lengths\"]>=min_len_,\n",
    "                                   zhen_val[\"zh_lengths\"]>=min_len_)]\n",
    "zhen_val = zhen_val[zhen_val[\"zh_lengths\"]<=max_len_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "vien_test[\"en_lengths\"] = vien_test[\"en_indices\"].apply(lambda x: len(x))\n",
    "vien_test[\"vi_lengths\"] = vien_test[\"vi_indices\"].apply(lambda x:len(x))\n",
    "\n",
    "vien_test = vien_test[np.logical_and(vien_test[\"en_lengths\"]>=min_len_,\n",
    "                                     vien_test[\"vi_lengths\"]>=min_len_)]\n",
    "vien_test = vien_test[vien_test[\"vi_lengths\"]<=max_len_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "zhen_test[\"en_lengths\"] = zhen_test[\"en_indices\"].apply(lambda x: len(x))\n",
    "zhen_test[\"zh_lengths\"] = zhen_test[\"zh_indices\"].apply(lambda x:len(x))\n",
    "\n",
    "zhen_test = zhen_test[np.logical_and(zhen_test[\"en_lengths\"]>=min_len_,\n",
    "                                     zhen_test[\"zh_lengths\"]>=min_len_)]\n",
    "zhen_test = zhen_test[zhen_test[\"zh_lengths\"]<=max_len_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en_data</th>\n",
       "      <th>zh_data</th>\n",
       "      <th>en_tokenized</th>\n",
       "      <th>zh_tokenized</th>\n",
       "      <th>en_indices</th>\n",
       "      <th>zh_indices</th>\n",
       "      <th>en_lengths</th>\n",
       "      <th>zh_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Life in the deep oceans</td>\n",
       "      <td>深海 海中 的 生命   大卫   盖罗</td>\n",
       "      <td>[life, in, the, deep, oceans]</td>\n",
       "      <td>[深海, 海中, 的, 生命, 大卫, 盖罗]</td>\n",
       "      <td>[4, 5, 6, 7, 8, 3]</td>\n",
       "      <td>[4, 5, 6, 7, 9, 10, 3]</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is Bill Lange . I &amp;apos;m Dave Gallo .</td>\n",
       "      <td>大卫   盖罗   这位 是 比尔   兰格    我 是 大卫   盖罗</td>\n",
       "      <td>[this, is, bill, lange, ., i, &amp;apos;m, dave, g...</td>\n",
       "      <td>[大卫, 盖罗, 这位, 是, 比尔, 兰格, 我, 是, 大卫, 盖罗]</td>\n",
       "      <td>[45, 39, 46, 47, 44, 48, 49, 50, 18, 44, 3]</td>\n",
       "      <td>[9, 10, 47, 32, 48, 49, 50, 32, 9, 10, 3]</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And we &amp;apos;re going to tell you some stories...</td>\n",
       "      <td>我们 将 用 一些 影片 来讲 讲述 一些 深海 海里 的 故事</td>\n",
       "      <td>[and, we, &amp;apos;re, going, to, tell, you, some...</td>\n",
       "      <td>[我们, 将, 用, 一些, 影片, 来讲, 讲述, 一些, 深海, 海里, 的, 故事]</td>\n",
       "      <td>[30, 51, 52, 53, 21, 54, 55, 22, 56, 57, 6, 58...</td>\n",
       "      <td>[17, 51, 52, 53, 15, 54, 55, 53, 4, 56, 6, 57, 3]</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             en_data  \\\n",
       "0                            Life in the deep oceans   \n",
       "2        This is Bill Lange . I &apos;m Dave Gallo .   \n",
       "3  And we &apos;re going to tell you some stories...   \n",
       "\n",
       "                                 zh_data  \\\n",
       "0                   深海 海中 的 生命   大卫   盖罗   \n",
       "2  大卫   盖罗   这位 是 比尔   兰格    我 是 大卫   盖罗   \n",
       "3       我们 将 用 一些 影片 来讲 讲述 一些 深海 海里 的 故事   \n",
       "\n",
       "                                        en_tokenized  \\\n",
       "0                      [life, in, the, deep, oceans]   \n",
       "2  [this, is, bill, lange, ., i, &apos;m, dave, g...   \n",
       "3  [and, we, &apos;re, going, to, tell, you, some...   \n",
       "\n",
       "                                    zh_tokenized  \\\n",
       "0                        [深海, 海中, 的, 生命, 大卫, 盖罗]   \n",
       "2          [大卫, 盖罗, 这位, 是, 比尔, 兰格, 我, 是, 大卫, 盖罗]   \n",
       "3  [我们, 将, 用, 一些, 影片, 来讲, 讲述, 一些, 深海, 海里, 的, 故事]   \n",
       "\n",
       "                                          en_indices  \\\n",
       "0                                 [4, 5, 6, 7, 8, 3]   \n",
       "2        [45, 39, 46, 47, 44, 48, 49, 50, 18, 44, 3]   \n",
       "3  [30, 51, 52, 53, 21, 54, 55, 22, 56, 57, 6, 58...   \n",
       "\n",
       "                                          zh_indices  en_lengths  zh_lengths  \n",
       "0                             [4, 5, 6, 7, 9, 10, 3]           6           7  \n",
       "2          [9, 10, 47, 32, 48, 49, 50, 32, 9, 10, 3]          11          11  \n",
       "3  [17, 51, 52, 53, 15, 54, 55, 53, 4, 56, 6, 57, 3]          17          13  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_SENTENCE_LENGTH = 50\n",
    "# BATCH_SIZE = 32\n",
    "\n",
    "# def translation_collate_(batch):\n",
    "    \n",
    "#     target_data = []\n",
    "#     source_data = []\n",
    "#     target_lengths = []\n",
    "#     source_lengths = []\n",
    "\n",
    "#     for datum in batch:\n",
    "#         target_lengths.append(datum[2])\n",
    "#         source_lengths.append(datum[3])\n",
    "        \n",
    "#     # PAD\n",
    "#     for datum in batch:\n",
    "#         if datum[2] > MAX_SENTENCE_LENGTH:\n",
    "#             padded_vec_target = np.array(datum[0])[:MAX_SENTENCE_LENGTH]\n",
    "#         else:\n",
    "#             padded_vec_target = np.pad(np.array(datum[0]),\n",
    "#                                 pad_width=((0,MAX_SENTENCE_LENGTH - datum[2])),\n",
    "#                                 mode=\"constant\", constant_values=PAD_IDX)\n",
    "            \n",
    "#         if datum[3] > MAX_SENTENCE_LENGTH:\n",
    "#             padded_vec_source = np.array(datum[1])[:MAX_SENTENCE_LENGTH]\n",
    "#         else:\n",
    "#             padded_vec_source = np.pad(np.array(datum[1]),\n",
    "#                                 pad_width=((0,MAX_SENTENCE_LENGTH - datum[3])),\n",
    "#                                 mode=\"constant\", constant_values=PAD_IDX)\n",
    "            \n",
    "#         target_data.append(padded_vec_target)\n",
    "#         source_data.append(padded_vec_source)\n",
    "        \n",
    "#     return [torch.from_numpy(np.array(source_data)), torch.from_numpy(np.array(target_data)),\n",
    "#             torch.from_numpy(np.array(source_lengths)), torch.from_numpy(np.array(target_lengths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vietnamese -> english\n",
    "# vien_dataset = {\"train\": Vietnamese(vien_train), \"val\": Vietnamese(vien_val)}\n",
    "\n",
    "# vien_loader = {x: DataLoader(vien_dataset[x], batch_size=BATCH_SIZE, \n",
    "#                             collate_fn=translation_collate_,\n",
    "#                             shuffle=False, num_workers=0) for x in [\"train\", \"val\"]}\n",
    "\n",
    "# # chinese -> english\n",
    "# zhen_dataset = {\"train\": Chinese(zhen_train), \"val\": Chinese(zhen_val)}\n",
    "\n",
    "# zhen_loader = {x: DataLoader(zhen_dataset[x], batch_size=BATCH_SIZE,\n",
    "#                              collate_fn=translation_collate_,\n",
    "#                              shuffle=False, num_workers=0) for x in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vietnamese -> english\n",
    "# vien_train_data = next(iter(vien_loader[\"train\"]))\n",
    "# vien_val_data = next(iter(vien_loader[\"val\"]))\n",
    "\n",
    "# # chinese -> english\n",
    "# zhen_train_data = next(iter(zhen_loader[\"train\"]))\n",
    "# zhen_val_data = next(iter(zhen_loader[\"val\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def out_token_2_string(index_tensor, \n",
    "#                        language):\n",
    "#     sentence = []\n",
    "#     for i in index_tensor:\n",
    "#         if i.item() not in [0, 1, 3]: # <PAD>, <SOS>, <EOS>\n",
    "#             sentence.append(language.index2word[i.item()])\n",
    "#     return (' ').join(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacreBLEU.sacreBLEU import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: RNN Encoder-Decoder without Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RNNencoder\n",
    "class RNNencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_size, \n",
    "                 hidden_size, \n",
    "                 num_gru_layers=1):\n",
    "        \n",
    "        super(RNNencoder, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_gru_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(self.input_size, \n",
    "                                      self.hidden_size,\n",
    "                                      padding_idx=0)\n",
    "        \n",
    "        self.GRU = nn.GRU(self.hidden_size, \n",
    "                          self.hidden_size,\n",
    "                          batch_first = True,\n",
    "                          bidirectional = False)\n",
    "        \n",
    "        if self.GRU.bidirectional:\n",
    "            self.num_directions = 2\n",
    "        else:\n",
    "            self.num_directions = 1\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        return torch.zeros(self.num_layers*self.num_directions, \n",
    "                           batch_size, self.hidden_size).to(device)\n",
    "\n",
    "    def forward(self,\n",
    "                source_sentence,\n",
    "                source_lengths,\n",
    "                hidden):\n",
    "        \n",
    "        sort_original_source = sorted(range(len(source_lengths)), \n",
    "                               key=lambda sentence: -source_lengths[sentence])\n",
    "        unsort_to_original_source = sorted(range(len(source_lengths)), \n",
    "                                    key=lambda sentence: sort_original_source[sentence])\n",
    "        \n",
    "        source_sentence = source_sentence[sort_original_source]\n",
    "        source_lengths = source_lengths[sort_original_source]\n",
    "        batch_size, seq_len_source = source_sentence.size()\n",
    "        \n",
    "        embeds_source = self.embedding(source_sentence)\n",
    "        \n",
    "        embeds_source = torch.nn.utils.rnn.pack_padded_sequence(embeds_source, \n",
    "                                                                source_lengths, \n",
    "                                                                batch_first=True)\n",
    "        output = embeds_source\n",
    "        \n",
    "        output, hidden = self.GRU(output, hidden)\n",
    "        \n",
    "        hidden = hidden.view(batch_size, self.hidden_size)\n",
    "        \n",
    "        hidden = hidden[unsort_to_original_source] ## back to original indices\n",
    "        output, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        hidden = hidden.view(1, batch_size, self.hidden_size)\n",
    "        \n",
    "        return hidden, output[unsort_to_original_source]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNdecoder\n",
    "class RNNdecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hidden_size, \n",
    "                 vocab_size):\n",
    "        \n",
    "        super(RNNdecoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, \n",
    "                                      self.hidden_size,\n",
    "                                      padding_idx=0)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.GRU = nn.GRU(self.hidden_size, \n",
    "                          self.hidden_size,\n",
    "                          batch_first=True)\n",
    "        \n",
    "\n",
    "        self.linear_layer = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        \n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "    def forward(self, \n",
    "                input_, \n",
    "                decoder_hidden,\n",
    "                encoder_outputs=None):\n",
    "        \n",
    "        # seq_len will always be 1 in the decoder at each time step\n",
    "        batch_size = input_.size(0)\n",
    "        output = self.embedding(input_)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "#         cat_out = torch.cat((output, decoder_hidden), 2)\n",
    "\n",
    "        output, decoder_hidden = self.GRU(output, decoder_hidden)\n",
    "\n",
    "        output = self.linear_layer(output.squeeze(dim=1))\n",
    "\n",
    "        output = self.log_softmax(output)\n",
    "\n",
    "        return output, decoder_hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translator for RNN encoder-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_rnn(encoder_model,\n",
    "                  decoder_model,\n",
    "                  source_sentence,\n",
    "                  target_sentence,\n",
    "                  source_lengths):\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < 0.6 else False\n",
    "    \n",
    "    batch_size = source_sentence.size(0)\n",
    "    encoder_hidden = encoder_model.init_hidden(batch_size)\n",
    "    \n",
    "    encoder_hidden, encoder_output = encoder_model(source_sentence,\n",
    "                                                   source_lengths,\n",
    "                                                   encoder_hidden)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoder_input = torch.FloatTensor([[SOS_token]]*batch_size).to(device)\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        decoder_out = []\n",
    "         \n",
    "        for time_step in range(MAX_SENTENCE_LENGTH):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder_model(decoder_input,\n",
    "                                                           decoder_hidden,\n",
    "                                                           encoder_outputs=None)\n",
    "            decoder_out.append(decoder_output.unsqueeze(-1))\n",
    "            decoder_input = target_sentence[:,time_step].view(-1,1)\n",
    "            \n",
    "        decoder_out = torch.cat(decoder_out,\n",
    "                                dim=-1)\n",
    "    else:\n",
    "        \n",
    "        decoder_out = []\n",
    "        for time_step in range(MAX_SENTENCE_LENGTH):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder_model(decoder_input,\n",
    "                                                           decoder_hidden,\n",
    "                                                           encoder_output)\n",
    "            \n",
    "            decoder_out.append(decoder_output.unsqueeze(-1))\n",
    "            top_scores, top_indices = decoder_output.topk(1)\n",
    "            decoder_input = top_indices.squeeze().detach().view(-1,1)\n",
    "            \n",
    "        decoder_out = torch.cat(decoder_out,\n",
    "                                dim=-1)\n",
    "        \n",
    "    return decoder_out, decoder_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN_TARGET = 50 # EN\n",
    "MAX_LEN_SOURCE = 50 # CHINESE/VIETNAMESE\n",
    "\n",
    "def translation_collate(batch):\n",
    "    \n",
    "    if MAX_LEN_TARGET <= 10:\n",
    "        raise ValueError(\"MAX_LEN_TARGET too small\")\n",
    "    elif MAX_LEN_SOURCE <= 10:\n",
    "        raise ValueError(\"MAX_LEN_SOURCE too small\")\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        target_sentence = []\n",
    "        source_sentence = []\n",
    "        target_lengths = []\n",
    "        source_lengths = []\n",
    "\n",
    "        for datum in batch:\n",
    "            target_lengths.append(datum[3])\n",
    "            source_lengths.append(datum[2])\n",
    "\n",
    "        max_target_length = max(target_lengths)\n",
    "        max_source_len = max(source_lengths)\n",
    "\n",
    "        if max_target_length < MAX_LEN_TARGET:\n",
    "            MAX_LEN_TARGET = max_target_length\n",
    "\n",
    "        if max_source_len < MAX_LEN_SOURCE:\n",
    "            MAX_LEN_SOURCE = max_source_len\n",
    "\n",
    "        # padding\n",
    "        for datum in batch:\n",
    "            if datum[2] > MAX_LEN_SOURCE:\n",
    "                padded_vec_source = np.array(datum[0])[:MAX_LEN_SOURCE]\n",
    "            else:\n",
    "                padded_vec_source = np.pad(np.array(datum[0]),\n",
    "                                    pad_width=((0,MAX_LEN_SOURCE - datum[2])),\n",
    "                                    mode=\"constant\", constant_values=PAD_IDX)\n",
    "            if datum[3] > MAX_LEN_TARGET:\n",
    "                padded_vec_target = np.array(datum[1])[:MAX_LEN_TARGET]\n",
    "            else:\n",
    "                padded_vec_target = np.pad(np.array(datum[1]),\n",
    "                                    pad_width=((0,MAX_LEN_TARGET - datum[3])),\n",
    "                                    mode=\"constant\", constant_values=PAD_IDX)\n",
    "                \n",
    "            target_sentence.append(padded_vec_target)\n",
    "            source_sentence.append(padded_vec_source)\n",
    "\n",
    "        source_sentence = np.array(source_sentence)\n",
    "        target_sentence = np.array(target_sentence)\n",
    "        source_lengths = np.array(source_lengths)\n",
    "        target_lengths = np.array(target_lengths)\n",
    "\n",
    "        source_lengths[source_lengths>MAX_LEN_SOURCE] = MAX_LEN_SOURCE\n",
    "        target_lengths[target_lengths>MAX_LEN_TARGET] = MAX_LEN_TARGET\n",
    "\n",
    "    return [torch.from_numpy(source_sentence), torch.from_numpy(target_sentence),\n",
    "            torch.from_numpy(source_lengths), torch.from_numpy(target_lengths)]\n",
    "\n",
    "def translation_collate_val(batch):\n",
    "    return [torch.from_numpy(np.array(batch[0][0])).unsqueeze(0), \n",
    "            torch.from_numpy(np.array(batch[0][1])).unsqueeze(0),\n",
    "            torch.from_numpy(np.array(batch[0][2])).unsqueeze(0), \n",
    "            torch.from_numpy(np.array(batch[0][3])).unsqueeze(0),batch[0][4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_LEN = 48\n",
    "# train,val,en_lang,vi_lang = vien_train, vien_val, vien_en_, vien_vi_\n",
    "train, val, en_lang, zh_lang = zhen_train, zhen_val, zhen_en_, zhen_zh_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIEN TEST\n",
    "test, en_lang, vi_lang = vien_test, vien_en_, vien_vi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZHEN TEST\n",
    "zh_test, en_lang, zh_lang = zhen_test, zhen_en_, zhen_zh_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vietnamese -> English\n",
    "# TEST \n",
    "\n",
    "batch_sizes = {\"train\":128,\"val\":1, \"train_val\":1,\"val_train\":128}\n",
    "train_used = train\n",
    "collate_fn_dict = {\"train\":translation_collate, \"val\": translation_collate_val,\\\n",
    "                   \"train_val\":translation_collate_val,\"val_train\":translation_collate}\n",
    "translation_dataset = {\"train\": Vietnamese(train_used), \n",
    "                       \"val\": Vietnamese(test, val = True), # changing val test with test set\n",
    "                       \"train_val\":Vietnamese(train.iloc[:50], val = True),\n",
    "                       \"val_train\":Vietnamese(val)\n",
    "                                               }\n",
    "\n",
    "dataloader = {x: DataLoader(translation_dataset[x],\n",
    "                            batch_size=batch_sizes[x], \n",
    "                            collate_fn=collate_fn_dict[x],\n",
    "                            shuffle=True, num_workers=0) for x in [\"train\", \"val\", \"train_val\",\"val_train\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chinese -> English\n",
    "# TEST\n",
    "\n",
    "batch_sizes = {\"test\":1, \"val_train\":128}\n",
    "# train_used = shuffle_sorted_batches(train_sorted, bs_dict[\"train\"])\n",
    "# train_used = train.iloc[:50]\n",
    "# train_used = train\n",
    "collate_fn_dict = {\"test\":translation_collate_val, \"val_train\":translation_collate}\n",
    "\n",
    "translation_dataset = {\"test\": Chinese(zh_test, val = True),\n",
    "                       \"val_train\":Chinese(val)}\n",
    "\n",
    "dataloader = {x: DataLoader(translation_dataset[x], \n",
    "                            batch_size=batch_sizes[x], \n",
    "                            collate_fn=collate_fn_dict[x],\n",
    "                            shuffle=True, num_workers=0) for x in [\"test\", \"val_train\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacreBLEU.sacreBLEU import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: RNN Encoder-Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMencoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 num_lstm_layers):\n",
    "\n",
    "        super(LSTMencoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.embedding = Embedding(input_size,\n",
    "                                   self.embed_size,\n",
    "                                   padding_idx=0)\n",
    "\n",
    "        self.dropout_ = nn.Dropout(p = 0.1)\n",
    "        self.num_layers = num_lstm_layers\n",
    "\n",
    "        self.lstm = LSTM(self.embed_size, self.hidden_size,\n",
    "                         batch_first=True, bidirectional=True,\n",
    "                         num_layers = self.num_layers,\n",
    "                         dropout = 0.15)\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers*2,\n",
    "                           batch_size,\n",
    "                           self.hidden_size).to(device),\\\n",
    "               torch.zeros(self.num_layers*2,\n",
    "                           batch_size,\n",
    "                           self.hidden_size).to(device)\n",
    "\n",
    "    def forward(self,\n",
    "                encoder_inputs,\n",
    "                source_lengths):\n",
    "\n",
    "        sort_original_source = torch.sort(source_lengths, descending=True)[1]\n",
    "        unsort_to_original_source = torch.sort(sort_original_source)[1]\n",
    "\n",
    "        embeds_source = self.embedding(encoder_inputs)\n",
    "        \n",
    "        lstm_out = self.dropout_(embeds_source)\n",
    "\n",
    "        batch_size, seq_len = embeds_source.size()\n",
    "\n",
    "        hidden, context = self.initHidden(batch_size)\n",
    "        sorted_output = lstm_out[sort_original_source]\n",
    "        sorted_len = source_lengths[sort_original_source]\n",
    "\n",
    "        packed_output = nn.utils.rnn.pack_padded_sequence(sorted_output, \n",
    "                                                          sorted_lengths, \n",
    "                                                          batch_first = True)\n",
    "\n",
    "        packed_outs, (hiddden, context) = self.lstm(packed_output,(hidden, context))\n",
    "        hidden = hidden[:,unsort_to_original_source,:]\n",
    "        context = context[:,unsort_to_original_source,:]\n",
    "\n",
    "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(packed_outs,\n",
    "                                                       padding_value=PAD_IDX,\n",
    "                                                       batch_first = True)\n",
    "        # UNSORT OUTPUT\n",
    "        lstm_out = lstm_out[unsort_to_original_source]\n",
    "        hidden = hidden.view(self.num_layers, 2, batch_size, -1).transpose(1, 2).contiguous().view(self.num_layers, batch_size, -1)\n",
    "        context = context.view(self.num_layers, 2, batch_size, -1).transpose(1, 2).contiguous().view(self.num_layers, batch_size, -1)\n",
    "\n",
    "        return output, hidden, context\n",
    "\n",
    "\n",
    "\n",
    "def initLSTM(input_size,\n",
    "             hidden_size,\n",
    "             **kwargs):\n",
    "\n",
    "    model = nn.LSTM(input_size,\n",
    "                    hidden_size,\n",
    "                    **kwargs)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "\n",
    "        if (\"weight\" in name) or (\"bias\" in name):\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def initLSTMCell(input_size,\n",
    "                 hidden_size,\n",
    "                 **kwargs):\n",
    "\n",
    "    model = nn.LSTMCell(input_size,\n",
    "                        hidden_size,\n",
    "                        **kwargs)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def initGRUCell(input_size,\n",
    "                hidden_size,\n",
    "                **kwargs):\n",
    "\n",
    "    model = nn.GRUCell(input_size,\n",
    "                       hidden_size,\n",
    "                       **kwargs)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "\n",
    "        if 'weight' in name or 'bias' in name:\n",
    "            param.data.uniform_(-0.1, 0.1)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Attention: attention module\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 attn_size):\n",
    "\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn_size = attn_size\n",
    "\n",
    "        self.linear_layer1 = nn.Linear(self.hidden_size, self.attn_size)\n",
    "\n",
    "        self.linear_layer2 = nn.Linear(self.hidden_size + self.attn_size, self.attn_size)\n",
    "        \n",
    "    def forward(self,\n",
    "                hidden,\n",
    "                encoder_outs,\n",
    "                source_lengths):\n",
    "\n",
    "        # hidden_size -> attn_size\n",
    "        attn_hidden = self.linear_layer1(hidden)\n",
    "\n",
    "        # get scores\n",
    "        attn_score = torch.sum((encoder_outs.transpose(0,1) * attn_hidden.unsqueeze(0)),2)\n",
    "\n",
    "        attn_mask = torch.transpose(seq_mask(source_lengths,\n",
    "                                             max_len = max(source_lengths).item()),\n",
    "                                    0,1)\n",
    "\n",
    "        masked_attn = attn_mask*attn_score\n",
    "        masked_attn[masked_attn==0] = -1e10\n",
    "\n",
    "        # softmax over attention to get weights\n",
    "        attn_scores = F.softmax(masked_attn, dim=0)\n",
    "        # compute weighted sum according to attention scores\n",
    "        attn_hidden = torch.sum(attn_scores.unsqueeze(2)*encoder_outs.transpose(0,1), 0)\n",
    "\n",
    "        attn_hidden = self.linear_layer2(torch.cat((attn_hidden, hidden), dim=1))\n",
    "        attn_hidden = torch.tanh(attn_hidden)\n",
    "\n",
    "        return attn_hidden, attn_scores\n",
    "\n",
    "# AttnDecoderRNN\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embed_size,\n",
    "                 hidden_size,\n",
    "                 num_rnn_layers = 1,\n",
    "                 attention = True,\n",
    "                 dropout_percent=0.1):\n",
    "\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed_size = embed_size\n",
    "        encoder_output_size = self.hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_size,\n",
    "                                      PAD_IDX)\n",
    "\n",
    "        self.dropout_f = nn.Dropout(p=dropout_percent)\n",
    "\n",
    "        self.num_layers = num_rnn_layers\n",
    "\n",
    "        if attention:\n",
    "            self.attention = Attention(self.hidden_size,\n",
    "                                       encoder_output_size)\n",
    "        else:\n",
    "            self.attention = None\n",
    "\n",
    "        self.layers = nn.ModuleList([initLSTMCell(input_size=self.hidden_size+self.embed_size if ((layer == 0) and attention) \\\n",
    "                                                  else self.embed_size if layer == 0 else self.hidden_size,\n",
    "                                                  hidden_size=self.hidden_size,)for layer in range(self.num_layers)])\n",
    "\n",
    "        self.linear_layer = nn.Linear(self.hidden_size, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, \n",
    "                decoder_inputs,\n",
    "                context, \n",
    "                prev_hiddens,\n",
    "                prev_context,\n",
    "                encoder_outputs,\n",
    "                source_lengths):\n",
    "        \n",
    "        batch_size = decoder_inputs.size(0)\n",
    "\n",
    "        # embed\n",
    "        embed_target = self.embedding(decoder_inputs)\n",
    "        out = self.dropout_f(embed_target)\n",
    "        \n",
    "        if self.attention is not None:\n",
    "            input_ = torch.cat([out.squeeze(1), context], dim = 1)\n",
    "        else:\n",
    "            input_ = out.squeeze(1)\n",
    "\n",
    "        context_ = []\n",
    "        decoder_hiddens_ = []\n",
    "\n",
    "        for layer, rnn in enumerate(self.layers):\n",
    "            hidden, con = rnn(input_, (prev_hiddens[layer],\n",
    "                                       prev_context[layer]))\n",
    "            input_ = self.dropout_f(hidden)\n",
    "            decoder_hiddens_.append(hidden.unsqueeze(0))\n",
    "            context_.append(con.unsqueeze(0))\n",
    "\n",
    "        decoder_hiddens_ = torch.cat(decoder_hiddens_, dim = 0)\n",
    "        context_ = torch.cat(context_, dim = 0)\n",
    "\n",
    "        if self.attention is not None:\n",
    "            out, attn_score = self.attention(hidden,\n",
    "                                             encoder_outputs,\n",
    "                                             source_lengths)\n",
    "        else:\n",
    "            out = hidden\n",
    "            attn_score = None\n",
    "\n",
    "        context_vec = out\n",
    "        out = self.dropout_f(out)\n",
    "\n",
    "        # linear: hidden_size -> vocab_size\n",
    "        deco_out = self.linear_layer(out)\n",
    "        deco_out = self.log_softmax(deco_out)\n",
    "\n",
    "        return out_vocab, context_vec, decoder_hiddens_, context_, attn_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translator Function for Attention\n",
    "For LSTMencoder and AttnDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_attn(encoder_model, decoder_model,\n",
    "                   source_sentence, target_sentence,\n",
    "                   source_lengths, target_lengths,\n",
    "                   val=False):\n",
    "    \n",
    "    if val == False:\n",
    "        \n",
    "        teacher_forcing = True if random.random() < 0.6 else False\n",
    "\n",
    "        batch_size, seq_len_source = source_sentence.size()\n",
    "        \n",
    "        encoder_out, encoder_hidden, encoder_context = encoder_model(source_sentence, source_lengths)\n",
    "        \n",
    "        max_source_length = max(source_lengths).item()\n",
    "        max_target_length = max(target_lengths).item()\n",
    "        \n",
    "        prev_hiddens = encoder_hidden\n",
    "        prev_context = encoder_context\n",
    "        \n",
    "        prev_ys = torch.zeros((batch_size, encoder_out.size(-1))).to(device)\n",
    "        \n",
    "        # decoder should start with SOS tokens at the first timestep\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size).to(device)\n",
    "        \n",
    "        if teacher_forcing:\n",
    "            \n",
    "            decoder_out = []\n",
    "            \n",
    "            for time_step in range(max_target_length):\n",
    "                \n",
    "                out_, prev_ys, prev_hiddens,\\ \n",
    "                prev_context, attn_score = decoder_model(decoder_input,\n",
    "                                                         prev_ys,\n",
    "                                                         prev_hiddens,\n",
    "                                                         prev_context,\n",
    "                                                         encoder_out,\n",
    "                                                         source_lengths)\n",
    "\n",
    "                decoder_out.append(out_.unsqueeze(-1))\n",
    "                decoder_input = target_sentence[:,time_step].view(-1,1)\n",
    "                \n",
    "            decoder_out = torch.cat(decoder_out,\n",
    "                                    dim=-1)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            decoder_out = []\n",
    "            \n",
    "            for time_step in range(max_target_length):\n",
    "                \n",
    "                out_, prev_ys, prev_hiddens,\\\n",
    "                prev_context, attn_score = decoder_model(decoder_input,\n",
    "                                                         prev_ys,\n",
    "                                                         prev_hiddens,\n",
    "                                                         prev_context, \n",
    "                                                         encoder_out,\n",
    "                                                         source_lengths)\n",
    "                \n",
    "                decoder_out.append(out_.unsqueeze(-1))\n",
    "                top_scores, top_indices = out_.topk(1)\n",
    "                decoder_input = top_indices.squeeze().detach().view(-1,1)\n",
    "\n",
    "            decoder_out = torch.cat(decoder_out,\n",
    "                                    dim=-1)\n",
    "        return decoder_out\n",
    "    \n",
    "    else: # Val\n",
    "        \n",
    "        encoder_model.eval()\n",
    "        decoder_model.eval()\n",
    "        batch_size, seq_len_source = source_sentence.size()\n",
    "        \n",
    "        encoder_out, encoder_hidden, encoder_context = encoder_model(source_sentence, \n",
    "                                                                     source_lengths)\n",
    "        max_source_length = max(source_lengths).item()\n",
    "        max_target_length = max(target_lengths).item()\n",
    "        \n",
    "        prev_hiddens = encoder_hidden\n",
    "        prev_context = encoder_context\n",
    "        \n",
    "        prev_ys = torch.zeros((batch_size, encoder_out.size(-1))).to(device)\n",
    "        \n",
    "        # SOS\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size).to(device)\n",
    "        \n",
    "        decoder_out = []\n",
    "        \n",
    "        for i in range(max_target_length):\n",
    "            \n",
    "            out_, prev_ys, prev_hiddens, \\\n",
    "            prev_context, attn_score = decoder_model(decoder_input,\n",
    "                                                     prev_ys,\n",
    "                                                     prev_hiddens,\n",
    "                                                     prev_context, \n",
    "                                                     encoder_out,\n",
    "                                                     source_lengths)\n",
    "            \n",
    "            decoder_out.append(out_.unsqueeze(-1))\n",
    "            top_scores, top_indices = out_.topk(1)\n",
    "            decoder_input = top_indices.squeeze().detach().view(-1,1)\n",
    "\n",
    "        decoder_out = torch.cat(decoder_out,dim=-1)\n",
    "        \n",
    "        return decoder_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training & Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder_optimizer,\n",
    "          decoder_optimizer, \n",
    "          encoder_model, decoder_model, \n",
    "          loss_function,\n",
    "          data_loader, \n",
    "          en_lang, # \"vien_en_\" for vietnamese -> eng, \"zhen_en_\" for chinese -> eng\n",
    "          num_epochs=10, val_interval=1, rm = 0.8, \n",
    "          enc_scheduler=None, \n",
    "          dec_scheduler=None):\n",
    "\n",
    "    mode_list = [\"train\",\"val_train\"] # val_train, val every val_interval train epochs\n",
    "    loss_hist = {\"train\": [], \"val_train\": []}\n",
    "    BLEU_hist = {\"train\": [], \"val\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print (\"epoch\", epoch)\n",
    "\n",
    "        for ex, mode in enumerate(mode_list):\n",
    "            \n",
    "            start = time.time()\n",
    "            total = 0\n",
    "            top1_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            \n",
    "            if mode == \"train\":\n",
    "                encoder.train()\n",
    "                decoder.train()\n",
    "                \n",
    "            elif mode == \"val_train\":\n",
    "                encoder.eval()\n",
    "                decoder.eval()\n",
    "            else:\n",
    "                raise ValueError\n",
    "                \n",
    "            for data in data_loader[mode]:\n",
    "                \n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "\n",
    "                encoder_input, decoder_input = data[0].to(device), data[1].to(device)\n",
    "                source_lengths, target_lengths = data[2].to(device), data[3].to(device)\n",
    "\n",
    "                if mode == \"val_train\":                \n",
    "                    output = encode_decode_attn(encoder_model, decoder_model,\n",
    "                                                encoder_input, decoder_input,\n",
    "                                                source_lengths, target_lengths,\n",
    "                                                rand_num=rm, val=True)\n",
    "                else:\n",
    "                    output = encode_decode_attn(encoder_model, decoder_model,\n",
    "                                                encoder_input, decoder_input,\n",
    "                                                source_lengths, target_lengths,\n",
    "                                                rand_num=rm, val=False)\n",
    "                    \n",
    "                loss = loss_function(output.float(), \n",
    "                                     decoder_input[:,:output.size(-1)].long())\n",
    "                \n",
    "                batch = decoder_input.size(0)\n",
    "                \n",
    "                running_loss += loss.item()*batch\n",
    "                \n",
    "                total += batch\n",
    "                \n",
    "                if mode == \"train\":\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(encoder.parameters(), 0.15)\n",
    "                    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 0.15)\n",
    "                    \n",
    "                    encoder_optimizer.step()\n",
    "                    decoder_optimizer.step()\n",
    "                    \n",
    "            epoch_loss = running_loss / total \n",
    "            loss_hist[mode].append(epoch_loss)\n",
    "            print(\"epoch {} {} loss = {}, time = {}\".format(epoch, mode, epoch_loss,\n",
    "                                                                           time.time() - start))\n",
    "        if (enc_scheduler is not None) and (dec_scheduler is not None):\n",
    "            enc_scheduler.step(epoch_loss)\n",
    "            dec_scheduler.step(epoch_loss)\n",
    "            \n",
    "        if epoch % val_interval == 0:\n",
    "            val_bleu_score = eval_(encoder_model, decoder_model, data_loader[\"val\"], en_lang)\n",
    "            BLEU_hist[\"val\"].append(val_bleu_score)\n",
    "            print(\"validation BLEU = \", val_bleu_score)\n",
    "\n",
    "    return encoder_model, decoder_model, loss_hist, BLEU_hist\n",
    "\n",
    "def eval_(encoder, \n",
    "          decoder, \n",
    "          val_dataloader, \n",
    "          vien_en_, # change with zhen_en_ for chinese -> english\n",
    "          ):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    pred_corpus = []\n",
    "    ref_corpus = []\n",
    "\n",
    "    for data in val_dataloader:\n",
    "        \n",
    "        encoder_input = data[0].to(device)\n",
    "        source_lengths = data[2].to(device)\n",
    "        \n",
    "        batch_size, seq_len = encoder_input.size()[:2]\n",
    "        \n",
    "        encoder_out, encoder_hidden, encoder_context = encoder(encoder_input,\n",
    "                                                               source_lengths)\n",
    "        max_source_length = max(source_lengths).item()\n",
    "        \n",
    "        prev_hiddens = encoder_hidden\n",
    "        prev_context = encoder_context\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size).to(device)\n",
    "        prev_output = torch.zeros((batch_size, encoder_out.size(-1))).to(device)\n",
    "        \n",
    "        decoder_out = []\n",
    "        \n",
    "        for i in range(seq_len*2):\n",
    "            \n",
    "            out_, prev_output, prev_hiddens,\\\n",
    "            prev_context, attention_score = decoder_model(decoder_input,\n",
    "                                                          prev_output,\n",
    "                                                          prev_hiddens,\n",
    "                                                          prev_context, \n",
    "                                                          encoder_out,\n",
    "                                                          source_lengths)\n",
    "            top_scores, top_indices = out_.topk(1)\n",
    "            decoder_out.append(top_indices.item())\n",
    "            decoder_input = top_indices.squeeze().detach().view(-1,1)\n",
    "            \n",
    "            if top_indices.item() == EOS_token:\n",
    "                break\n",
    "        \n",
    "        ref_corpus.append(data[-1])\n",
    "        \n",
    "        pred_sent = id2text_(decoder_out,vien_en_)\n",
    "        pred_corpus.append(pred_sent)\n",
    "\n",
    "    print (\"true corpus\", ref_corpus[:5])\n",
    "    print (\"pred corpus\", pred_corpus[:5])\n",
    "    \n",
    "    # import above: from sacreBLEU.sacreBLEU import corpus_bleu\n",
    "    score = corpus_bleu((\" \").join(pred_corpus),\n",
    "                        (\" \").join(ref_corpus))[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Performance\n",
    "\n",
    "__enc7, dec7__ is our best encoder-decoder pair. Please see the __training \\& validation__ process __below__.\n",
    "\n",
    "Please search for transformed_dataset to see the mentioned dataloader.\n",
    "\n",
    "transformed_dataset = {'train': Vietnamese(train_used), \n",
    "                       'val': Vietnamese(__test__, val = True), # changing val test with test set\n",
    "                       'train_val':Vietnamese(train.iloc[:50], val = True),\n",
    "                       'val_train':Vietnamese(val)\n",
    "                                               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true corpus ['it would be unconscionable .', 'then finally she said , &quot; the third thing i want you to promise me is that you &apos;ll never drink alcohol . &quot;', 'do you know what they call a 400 baseball hitter ?', 'because the pictures made it feel more real to you .', 'i gave her my whole rap , and when i finished she looked at me and she said , &quot; mmm mmm mmm . &quot;']\n",
      "pred corpus ['but the more optimistic one is the pro-social', 'and so , i &apos;m not to , , , , , , , , , ,', 'you know , when you go to the theater , you see the people who are in the .', 'and you &apos;re in a wheelchair . you &apos;re in your', 'and she said , &quot; well , i']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.27469722465982"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_vi = dataloader[\"val\"] # changed val with test loader in the dict\n",
    "\n",
    "eval_(enc7, dec7, test_data_vi, vien_en_, \"attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  24.65522102888692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.65522102888692"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_vi = dataloader[\"val\"] # changed val with test loader\n",
    "\n",
    "BeamSearch(enc7, dec7, test_data_vi, vien_en_, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8d3b3924d68b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data_zh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# changed val with test loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_zh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzhen_en_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attention\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mBeamSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_vi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvien_en_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "test_data_zh = dataloader[\"val\"] # changed val with test loader\n",
    "\n",
    "eval_(enc7, dec7, test_data_zh, zhen_en_, \"attention\")\n",
    "\n",
    "BeamSearch(enc7, dec7, test_data_vi, vien_en_, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation Started Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = RNNencoder_(vien_vi_.n_words,300,300, 2).to(device) # this is the old encoder\n",
    "# decoder = AttnDecoderRNN(vien_en_.n_words,300,512,n_layers=2, attention = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-4)\n",
    "# enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, min_lr=1e-4,  patience=0)\n",
    "# decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-4)\n",
    "# dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, min_lr=1e-4,  patience=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # vietnamese -> english\n",
    "# criterion = nn.NLLLoss(ignore_index=0)\n",
    "# enc, dec, loss_hist, acc_hist = train_model(encoder_optimizer, \n",
    "#                                             decoder_optimizer, \n",
    "#                                             encoder, decoder, \n",
    "#                                             criterion,\n",
    "#                                             \"attention\", \n",
    "#                                             dataloader,vien_en_, \n",
    "#                                             num_epochs = 14, rm = 0.95,\\\n",
    "#                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 5.554496881626442, time = 1236.9642140865326\n",
      "epoch 0 val_train loss = 7.429110933809865, time = 4.553696870803833\n",
      "true corpus ['it &apos;s my way of helping other victims , and it &apos;s my final request of you .', 'so we took a lot of samples from this road and we tested them in the lab .', 'this is a satellite picture showing north korea at night compared to neighbors .', 'you can zoom in and zoom out , you can wind back and fast forward .', 'it &apos;s not to say that our mothers aren &apos;t key in our success .']\n",
      "pred corpus ['and i said , &quot; well , i &apos;m going to do that . &quot;', 'and we &apos;re not going to be a very important .', 'and the reason that we &apos;re going to do is that we &apos;re going to do that , and we &apos;re not going to be a very good .', 'and we &apos;re not going to be a very good .', 'and the reason that we &apos;re going to do is that we &apos;re going to do that .']\n",
      "validation BLEU =  6.4868810256491765\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 4.766088347511274, time = 1238.111055135727\n",
      "epoch 1 val_train loss = 6.833039258450878, time = 4.595963001251221\n",
      "true corpus ['but it is not only about me .', 'we need every one of you to understand the secrets of domestic violence .', 'and with a mobile phone , you can record a song , load it up to soundcloud and become famous .', 'and here i am today .', 'we don &apos;t work from offices .']\n",
      "pred corpus ['i &apos;m going to show you the first time i &apos;m going to do .', 'we need to be able to do this .', 'and i &apos;m going to show you the', 'i &apos;m going to show you the first time i &apos;m going to do .', 'we &apos;re going to see the world , and we &apos;re going to do it .']\n",
      "validation BLEU =  10.190620287755644\n",
      "==================================================\n",
      "epoch 2\n",
      "epoch 2 train loss = 4.443997247168095, time = 1236.4621512889862\n",
      "epoch 2 val_train loss = 6.309693762720848, time = 4.596256732940674\n",
      "true corpus ['so , dancing is one of the most human of activities .', 'they kill our livestock .', 'and he very clearly explained to me that emotional displays are very dangerous in a place like this , not just for me , but for them .', 'and i think the answer that they &apos;re looking for is , &quot; if you are a little bit skinnier and you have shinier hair , you will be so happy and fabulous . &quot;', 'the answer is easy .']\n",
      "pred corpus ['and i think it &apos;s a that , .', 'and we were going to , the .', 'and i think the reason to the .', 'and i think it &apos;s a that , .', 'and i think it &apos;s a that , .']\n",
      "validation BLEU =  9.392364263323074\n",
      "==================================================\n",
      "epoch 3\n",
      "epoch 3 train loss = 4.160728392005602, time = 1236.0671837329865\n",
      "epoch 3 val_train loss = 6.197981785754768, time = 4.573515176773071\n",
      "true corpus ['we cleared tons and tons of stinking , rotting fish carcasses from the local fish processing plant .', 'as you can see , the river can be very narrow at certain points , allowing north koreans to secretly cross .', '&quot; you can go to a real school now , &quot; he said .', 'they own 26 square miles of vacant lots .', 'my friend got to come with me .']\n",
      "pred corpus ['we &apos;ve been able to see the ice , the ice , the ice , the ice , the ice , the ice , the ice , the ice , the ice , the', 'and the the the , , , , , , , ,', '&quot; what &apos;s your name ? &quot;', 'they &apos;re not the , the . .', 'and i &apos;m , i']\n",
      "validation BLEU =  9.155241160584533\n",
      "==================================================\n",
      "epoch 4\n",
      "epoch 4 train loss = 3.957955827943828, time = 1236.0368819236755\n",
      "epoch 4 val_train loss = 6.401236082583058, time = 4.635239839553833\n",
      "true corpus ['we always wondered what they knew about us .', 'you just couldn &apos;t imagine how amazing a sunflower is and how it affects people .', 'that was awkward .', 'and when you &apos;re describing your science , beware of jargon .', 'that &apos;s double the amount of people taken from africa during the entire trans-atlantic slave trade .']\n",
      "pred corpus ['we were in the middle of the , , , , , , , , , , ,', 'so , if you &apos;re a marketer , you &apos;re not a good person .', 'i think it &apos;s a .', 'so , if you look at the brain , you &apos;ll see the phantom .', 'and the aspiration of the world is to be the']\n",
      "validation BLEU =  12.52949222925048\n",
      "==================================================\n",
      "Training completed. Best BLEU is 12.52949222925048\n"
     ]
    }
   ],
   "source": [
    "# LASTRUN - START\n",
    "\n",
    "encoder = LSTMencoder(vien_vi_.n_words,512,512, 2).to(device)\n",
    "decoder = AttnDecoderRNN(vien_en_.n_words,512,1024,n_layers=2, attention=True).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-4,  patience=0)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-4,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "enc, dec, loss_hist, acc_hist = train(encoder_optimizer,\n",
    "                                      decoder_optimizer,\n",
    "                                      encoder, decoder,\n",
    "                                      criterion, \"attention\",\n",
    "                                      dataloader,vien_en_,\n",
    "                                      num_epochs = 5, rm = 0.95,\n",
    "                                      enc_scheduler = enc_scheduler,\n",
    "                                      dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 3.9035900663819625, time = 1227.8427731990814\n",
      "epoch 0 val_train loss = 6.266674137115478, time = 4.5217108726501465\n",
      "true corpus ['the waters here have been recorded at reaching over 24 meters in height , and traveled over two miles inland .', 'i had my first apartment , my first little green american express card , and i had a very big secret .', 'this is when we started asking passing tourists to take the picture .', 'according to a quranic verse &quot; salam &quot; -- peace -- &quot; is the word of the all-merciful god , raheem . &quot;', 'they are bird-blending machines .']\n",
      "pred corpus ['and i was was a the , , the , the the , , the the', 'and i was i i , , ,', 'and i was , the , , , , . the . the . the . the .', 'it &apos;s a shepherd that &apos;s been a the , &quot; the &quot;', 'and they &apos;re the , the ,']\n",
      "validation BLEU =  12.725447875469124\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 3.6219868814313747, time = 1229.3076164722443\n",
      "epoch 1 val_train loss = 6.257456617939229, time = 4.606155633926392\n",
      "true corpus ['i didn &apos;t know what it meant , but i could see that my father was very , very happy .', 'we &apos;re working with local communities .', 'plus you get strawberries .', 'so we can benefit from the international community for education , english language training , job training , and more .', 'just go and read her book .']\n",
      "pred corpus ['i was a , , ,', 'we &apos;re going to , ,', 'and you can , , ,', 'and we can do it the . ,', 'she &apos;s a , ,']\n",
      "validation BLEU =  11.231004886369707\n",
      "==================================================\n",
      "epoch 2\n",
      "epoch 2 train loss = 3.3806566712272477, time = 1228.5328114032745\n",
      "epoch 2 val_train loss = 6.831397959650779, time = 4.5956573486328125\n",
      "true corpus ['recently , the new york times reported that between 100,000 and 300,000 american children are sold into sex slavery every year .', 'we cleaned schools . we de-mudded and gutted homes ready for renovation and rehabilitation .', 'thank you .', 'i mean , just think how long it takes a child to learn to speak .', 'almost 200 organizations were established in benghazi during and immediately after the fall of gaddafi -- almost 300 in tripoli .']\n",
      "pred corpus ['and they &apos;re not even the , , , .', 'and we &apos;re going to , , .', 'thank you .', 'i don &apos;t know if you &apos;re a teacher , but i &apos;m not a vegetarian , i &apos;m not .', 'the first thing that happened was that the police were not the the .']\n",
      "validation BLEU =  15.247831073893444\n",
      "==================================================\n",
      "epoch 3\n",
      "epoch 3 train loss = 3.19224824786852, time = 1228.9282581806183\n",
      "epoch 3 val_train loss = 6.978017754457435, time = 4.615445613861084\n",
      "true corpus ['how can you do — ? &quot; and i said , &quot; i do something very , very , very difficult .', 'as you can imagine , the town had been devastated .', 'and we were amazed that the local people , in such a fertile valley , would not have any agriculture .', 'we are the soil .', 'but you have to maintain it .']\n",
      "pred corpus ['i &apos;m going to have a lot of . , , , , , , ,', 'and we have a lot of , , , , , , , , , , . , the .', 'we had to change the bears .', 'we have a lot of we , . .', 'you have to get the detail out of it .']\n",
      "validation BLEU =  16.787565894791555\n",
      "==================================================\n",
      "epoch 4\n",
      "epoch 4 train loss = 3.0009591300414002, time = 1229.719583272934\n",
      "epoch 4 val_train loss = 7.019450596400669, time = 4.62275767326355\n",
      "true corpus ['they knew their image would be seen by you out in the world .', 'but one day , in 1995 , my mom brought home a letter from a coworker &apos;s sister .', 'no expensive staff time required .', 'we couldn &apos;t retouch the photo unless it was cleaned , dry and reclaimed .', 'and the zambians said , &quot; yes , that &apos;s why we have no agriculture here . &quot;']\n",
      "pred corpus ['and they will be a you . .', 'and i was a to to she ,', 'barnett exaggerated : the astounding athletic power of quadcopters', 'so we went to the dam to build a prototype site , and we had a whole bunch of projects that were illegally available to the customers .', 'and so we went to the barefoot government , and we said , &quot; well , you know ,']\n",
      "validation BLEU =  16.936454235891773\n",
      "==================================================\n",
      "Training completed. Best BLEU is 16.936454235891773\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc.parameters(), lr=1e-3)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-5,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec.parameters(), lr=1e-3)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-5,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "enc2, dec2, loss_hist, acc_hist = train(encoder_optimizer,\n",
    "                                        decoder_optimizer, \n",
    "                                        enc, dec, # encoder - decoder returned above\n",
    "                                        criterion,\n",
    "                                        \"attention\",\n",
    "                                        dataloader, vien_en_,\n",
    "                                        num_epochs = 5, rm = 0.95,\n",
    "                                        enc_scheduler = enc_scheduler, \n",
    "                                        dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dec2.state_dict(), \"rnn_decoder_vietnamese_good.pth\")\n",
    "torch.save(enc2.state_dict(), \"rnn_encoder_vietnamese_good.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  3.375153977073988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.375153977073988"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc2, dec2, dataloader[\"val\"], vien_en_, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 2.6355759009699433, time = 1231.4814236164093\n",
      "epoch 0 val_train loss = 6.755882358551025, time = 4.598157644271851\n",
      "true corpus ['i was just three years old when my brother came along , and i was so excited that i had a new being in my life .', 'hopefully less awkward than that one in the middle .', 'one of the smartest things conor did , from the very beginning , was to create the illusion that i was the dominant partner in the relationship .', 'i was able to leave , because of one final , sadistic beating that broke through my denial .', 'thank you so much . thank you .']\n",
      "pred corpus ['and i was was i i to the , , i', 'that &apos;s the first time that the kid &apos;s . .', 'i &apos;ve been to the to of to the , , , , ,', 'i was i was , , , i to i to i to', 'thank you . thank you .']\n",
      "validation BLEU =  16.029540231897602\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 2.622434728581503, time = 1231.2793803215027\n",
      "epoch 1 val_train loss = 6.832007227138597, time = 4.612725257873535\n",
      "true corpus ['so i figured that the problem is the solution .', 'and i &apos;d like to share a few things that people wrote on this wall .', 'thanks so much . max little , everybody .', 'in a community of 10,000 people , we get 200 clients .', 'as you can see , the river can be very narrow at certain points , allowing north koreans to secretly cross .']\n",
      "pred corpus ['and i think that to the , , , , , , . .', 'this is a headline about the library of the library .', 'chade-meng tan : everyday life in the future of the world', 'we can &apos;t make it be used by the mosquito .', 'now , the chinese government will rise to about 70 million chinese dollars , and it &apos;s going to be one of the most crowded parts of the country .']\n",
      "validation BLEU =  17.028085719188425\n",
      "==================================================\n",
      "epoch 2\n",
      "epoch 2 train loss = 2.5636118613855317, time = 1232.17422747612\n",
      "epoch 2 val_train loss = 7.005921266516861, time = 4.573944091796875\n",
      "true corpus ['and when you &apos;re describing your science , beware of jargon .', 'this was the first time i heard that people in my country were suffering .', 'so do you still not want to continue ? &quot;', 'he &apos;s not greedy . he doesn &apos;t see skin color .', 'thanks .']\n",
      "pred corpus ['let &apos;s take a look at the next step .', 'and i &apos;m not of . , i', 'well , it &apos;s not . , .', 'she was a wonderful kid .', 'thank you .']\n",
      "validation BLEU =  17.49104894267658\n",
      "==================================================\n",
      "Training completed. Best BLEU is 17.49104894267658\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc2.parameters(), lr=1e-4)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-6,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec2.parameters(), lr=1e-4)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-6,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "enc3, dec3, loss_hist, acc_hist = train(encoder_optimizer,\n",
    "                                        decoder_optimizer,\n",
    "                                        enc2, dec2,\n",
    "                                        criterion,\n",
    "                                        \"attention\",\n",
    "                                        dataloader, vien_en_,\n",
    "                                        num_epochs = 3, rm = 0.95,\n",
    "                                        enc_scheduler = enc_scheduler, \n",
    "                                        dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(enc3, \"best_attn_encoder_rnn.pth\")\n",
    "torch.save(dec3, \"best_attn_decoder_rnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  19.15777061690079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.15777061690079"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc3, dec3, dataloader[\"val\"], vien_en_, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  19.721609375445407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.721609375445407"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc3, dec3, dataloader[\"val\"], vien_en_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  19.943231471415235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19.943231471415235"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc3, dec3, dataloader[\"val\"], vien_en_, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc3 = torch.load(\"best_attn_encoder_rnn.pth\")\n",
    "dec3 = torch.load(\"best_attn_decoder_rnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adc563/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train loss = 2.4629972229044714, time = 1234.3856925964355\n",
      "epoch 0 val_train loss = 7.045825487253618, time = 4.654397010803223\n",
      "true corpus ['penn state asked me , a communications teacher , to teach a communications class for engineering students .', 'but nobody helped them , because they were so focused on taking care of themselves and their families .', 'that &apos;s the real zipper .', 'it could take an hour . it could take weeks .', 'here &apos;s me on the soccer team and in v magazine .']\n",
      "pred corpus ['i &apos;m asking you to read , not just how hard the children are , but also the best way to do it .', 'and i think that to the , , , , , ,', 'and i think it &apos;s a the the .', 'and i &apos;m going to to', 'i &apos;ve been working with projects like this .']\n",
      "validation BLEU =  17.5791288832173\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 2.4973496287396157, time = 1235.0308747291565\n",
      "epoch 1 val_train loss = 7.077768590498944, time = 4.568317413330078\n",
      "true corpus ['extraordinary .', 'that means they can be self-administered .', 'under the taliban , girls who went to school numbered in the hundreds -- remember , it was illegal .', 'it was more like a restaurant .', 'so i didn &apos;t give up . i continued .']\n",
      "pred corpus ['the vast majority of people ,', 'and i think that &apos;s the the , , , , , . .', 'they were the first to taliban .', 'i &apos;m not sure if i &apos;m going to .', 'i was a the , , i']\n",
      "validation BLEU =  18.318960555966363\n",
      "==================================================\n",
      "Training completed. Best BLEU is 18.318960555966363\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc3.parameters(), lr=5e-5)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-6,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec3.parameters(), lr=5e-5)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-6,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "enc4, dec4, loss_hist, acc_hist = train(encoder_optimizer,\n",
    "                                        decoder_optimizer,\n",
    "                                        enc3, dec3,\n",
    "                                        criterion,\n",
    "                                        \"attention\",\n",
    "                                        dataloader,vien_en_,\n",
    "                                        num_epochs = 2, rm = 0.95,\n",
    "                                        enc_scheduler = enc_scheduler, \n",
    "                                        dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.28189574524616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.28189574524616"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc4, dec4, dataloader[\"val\"], vien_en_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 2.408123344059025, time = 1232.0732686519623\n",
      "epoch 0 val_train loss = 7.148522694256841, time = 4.555002689361572\n",
      "true corpus ['so the last question people ask me is , &quot; what is it like to be a model ? &quot;', 'but i will do a trial .', 'he looked at me suspiciously , but luckily he believed me .', 'so i put the specimen in , which i &apos;m now going to take out to see what happened .', 'it &apos;s difficult to witness something so overwhelming .']\n",
      "pred corpus ['and i said , &quot; well , i', 'so , i &apos;ve been to a to', 'and he said , &quot; well , i', 'it &apos;s a little bit like the one that i &apos;m going to .', 'i was a the the , , ,']\n",
      "validation BLEU =  18.432938641819742\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 2.423812474525007, time = 1232.1433029174805\n",
      "epoch 1 val_train loss = 7.110661590342619, time = 4.557958364486694\n",
      "true corpus ['you have to learn how to get these people to come and talk to you .', 'we are lying on the floor together , and our bodies are so weak we are ready to die . &quot;', 'that &apos;s why , after 10 years of hiding my identity , i decided to risk going to south korea , and i started a new life yet again .', 'and the zambians said , &quot; yes , that &apos;s why we have no agriculture here . &quot;', 'what are you going to get out of those samples ?']\n",
      "pred corpus ['you have to be really authentic .', 'and we &apos;re not we , , , , , , , , , , , , ,', 'the only thing that happened was that the police killed the world .', 'and so , i got up on the front of the chart , and i said , &quot; what &apos;s going on ? &quot;', 'well , you know , you .']\n",
      "validation BLEU =  18.37828850390651\n",
      "==================================================\n",
      "Training completed. Best BLEU is 18.432938641819742\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc4.parameters(), lr=3e-5)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-6,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec4.parameters(), lr=3e-5)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=5e-6,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "enc5, dec5, loss_hist, acc_hist = train(encoder_optimizer,\n",
    "                                        decoder_optimizer,\n",
    "                                        enc4, dec4,\n",
    "                                        criterion,\n",
    "                                        \"attention\", \n",
    "                                        dataloader, vien_en_,\n",
    "                                        num_epochs = 2, rm = 0.95,\n",
    "                                        enc_scheduler = enc_scheduler, \n",
    "                                        dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.43469747827706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.43469747827706"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chinese -> English - do not run with the same dataloader !!!\n",
    "BeamSearch(enc4, dec4, dataloader[\"val\"], zhen_en_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.43054028818054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.43054028818054"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc5, dec5, dataloader[\"val\"], vien_en_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 2.3565232976972266, time = 1231.4803340435028\n",
      "epoch 0 val_train loss = 7.174542779338603, time = 4.53424859046936\n",
      "true corpus ['the day of the tsunami , he &apos;d actually been in charge of making sure the tsunami gates were closed .', 'and first , i commend you on your model knowledge . very impressive .', 'so i decided to start a lawsuit against them , because i wanted to have this information .', 'and of course , everything in africa grew beautifully .', 'the journey by bus took one week , and we were almost caught several times .']\n",
      "pred corpus ['so , we have a . , , , .', 'i want you to just think it &apos;s a great thing to be a , .', 'and i said , &quot; well , i', 'there &apos;s a lot of work in africa .', 'and the next morning , i &apos;d be walking around the table , and i was going to go to the']\n",
      "validation BLEU =  18.336935850030034\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 2.3440570105882537, time = 1232.2761716842651\n",
      "epoch 1 val_train loss = 7.2279723984854565, time = 4.6325154304504395\n",
      "true corpus ['he shares it unconditionally and he shares it regardless .', 'it started burning a hole in my stomach , so within weeks , i flew down to los angeles to meet with the director of free the slaves and offer them my help .', 'who calls whom ? who sends whom an email ?', 'you can clearly communicate your science without compromising the ideas .', 'thank you .']\n",
      "pred corpus ['i was born in the a to to', 'but i didn &apos;t want to hurt them .', 'who &apos;s got the best flute ?', 'so i think that &apos;s a what we &apos;re thinking of .', 'thank you .']\n",
      "validation BLEU =  18.934308537072194\n",
      "==================================================\n",
      "epoch 2\n",
      "epoch 2 train loss = 2.2987714128116283, time = 1232.6613454818726\n",
      "epoch 2 val_train loss = 7.290154564137361, time = 4.660839319229126\n",
      "true corpus ['north koreans have to travel incredible distances on the path to freedom .', 'on march 11 , 2011 , i watched from home , as the rest of the world did , as the tragic events unfolded in japan .', 'but &quot; how many times will i get stopped ? when will i get stopped ? &quot;', 'never the word &quot; i , &quot; and the word &quot; we &quot; 32 times .', 'first , you have to offer them confidentiality .']\n",
      "pred corpus ['the lakota soldiers were in the the the the the the the the the the the the', 'and i was very , were the the , , , , , , ,', 'and the question is , &quot; how do i get to the truth ? &quot;', 'there are two things i can do with all the money that i &apos;m going to share with you .', 'and you have to get to the of , you']\n",
      "validation BLEU =  19.25923659068878\n",
      "==================================================\n",
      "epoch 3\n",
      "epoch 3 train loss = 2.37757207414674, time = 1232.2283847332\n",
      "epoch 3 val_train loss = 7.179579616079525, time = 4.607082366943359\n",
      "true corpus ['i realized that this was a symbolic moment in my life .', 'i grew up there . i raised my sons there .', 'he doesn &apos;t care about religious differences , and get this : he has never told a lie .', 'he wasn &apos;t alone when he started .', 'and then we help them to go and find the knowledge , because nobody in the world can succeed alone .']\n",
      "pred corpus ['so i was in my lab .', 'i was a child . , , , , , ,', 'you know , you &apos;re a you ,', 'and then he said , &quot; i &apos;m', 'so we started to think ,']\n",
      "validation BLEU =  18.712981066763277\n",
      "==================================================\n",
      "epoch 4\n",
      "epoch 4 train loss = 2.3191846871786126, time = 1231.9192190170288\n",
      "epoch 4 val_train loss = 7.290878393212143, time = 4.600586414337158\n",
      "true corpus ['saying that you want to be a model when you grow up is akin to saying that you want to win the powerball when you grow up .', 'they &apos;re our natural garbage collectors .', 'planning is the kiss of death of entrepreneurship .', 'and i hope what you &apos;re seeing is that these pictures are not pictures of me .', 'well , hopefully not as awkward as that picture .']\n",
      "pred corpus ['and i know that i have a lot of friends , and i ,', 'and they are judged in the same way .', 'and the second was &quot; to', 'this is a picture of a . the of . , , , , . ,', 'i &apos;m going to do it the']\n",
      "validation BLEU =  19.212701271989037\n",
      "==================================================\n",
      "Training completed. Best BLEU is 19.25923659068878\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc4.parameters(), lr=5e-5)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-6,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec4.parameters(), lr=5e-5)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-6,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "enc6, dec6, loss_hist6, acc_hist6 = train(encoder_optimizer,\n",
    "                                          decoder_optimizer,\n",
    "                                          enc4, dec4, # 4 was better than 5\n",
    "                                          criterion,\n",
    "                                          \"attention\",\n",
    "                                          dataloader, vien_en_,\n",
    "                                          num_epochs = 5, rm = 0.95,\n",
    "                                          enc_scheduler = enc_scheduler, \n",
    "                                          dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.92370830109886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.92370830109886"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeamSearch(enc6, dec6, dataloader[\"val\"], vien_en_, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 2.3299497075632645, time = 1234.203326702118\n",
      "epoch 0 val_train loss = 7.314455038187456, time = 4.549794673919678\n",
      "true corpus ['i can feel the brush of sweaty bodies passing me in the darkness , but i can &apos;t see much else .', 'we &apos;re pale , gray creatures .', 'thank you .', 'my councilman even called in and said how they endorse and love what we &apos;re doing .', 'you never arrive in a community with any ideas , and you sit with the local people .']\n",
      "pred corpus ['the difference between the two in the morning is that , up to a number of meters , i &apos;m wearing a lot of these minus sheep that have to go off the mountain to the nearest sea , and to the ,', 'we &apos;re trying to make them grow alive .', 'thank you .', 'so we started to think , what . ,', 'and we have a lot of . , , . , . . .']\n",
      "validation BLEU =  19.317700375205195\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 2.27979019665766, time = 1233.5050673484802\n",
      "epoch 1 val_train loss = 7.293009487463504, time = 4.713450193405151\n",
      "true corpus ['and my father -- that &apos;s him -- he was the first ever in his family to receive an education .', 'the dyed black hands are the father , while the blue and red hands are his sons .', 'there were no breaks for food , no water breaks , and the severe dehydration made urinating pretty much inconsequential .', 'here &apos;s me at a slumber party a few days before i shot french vogue .', 'and you can even see how i go from frankfurt by train to cologne , and how often i call in between .']\n",
      "pred corpus ['and he &apos;s a a to to to , , , , , , , , , , , , , , , , , , , , , , , , , , .', 'he &apos;s a a the the the . . . . the . . . . . . . . . . . .', 'there &apos;s a lot of love , a little bit of bad cats .', 'and i &apos;m not even a guy , . .', 'so i &apos;ve been doing this for the last couple of years .']\n",
      "validation BLEU =  19.26613675137422\n",
      "==================================================\n",
      "epoch 2\n",
      "epoch 2 train loss = 2.306069415216939, time = 1233.1934139728546\n",
      "epoch 2 val_train loss = 7.320470085922553, time = 4.554952621459961\n",
      "true corpus ['we had an amazing local woman who guided us .', 'it &apos;s tragic that north koreans have to hide their identities and struggle so hard just to survive .', 'some don &apos;t even know they &apos;re enslaved , people working 16 , 17 hours a day without any pay , because this has been the case all their lives .', 'so we can benefit from the international community for education , english language training , job training , and more .', 'conor proceeded to beat me once or twice a week for the next two and a half years of our marriage .']\n",
      "pred corpus ['we went to school , we went to school , we went to school , we went to school , we went', 'in fact , the military is now being killed .', 'so they &apos;re not going to , , , , ,', 'and i think that &apos;s the the , , , , , , , , . ,', 'in fact , i think it &apos;s a the the .']\n",
      "validation BLEU =  19.34048507849997\n",
      "==================================================\n",
      "epoch 3\n",
      "epoch 3 train loss = 2.358325977159726, time = 1234.4305102825165\n",
      "epoch 3 val_train loss = 7.288775043098294, time = 4.5897064208984375\n",
      "true corpus ['they have nothing to compare it to .', '&quot; as i worked , i couldn &apos;t help but think about the individuals and the stories represented in the images .', 'which is why that ivy league degree and the wall street job and his bright shiny future meant so much to him .', 'and these projects came from questions i had , like , how much are my neighbors paying for their apartments ?', '&quot; before i die , i want to plant a tree . &quot;']\n",
      "pred corpus ['they &apos;re the ones who are .', 'i know that i have to be part of this story of telling the stories of the story , and i don &apos;t think that &apos;s the way consciousness is .', 'and the reason he knew that was because he knew that he was going to have to go to court to get a job .', 'and the answer is , the , , , , , , , , , , , , , , , , , , , .', '&quot; i feel like i was in a hotel room with a family of accident . &quot;']\n",
      "validation BLEU =  19.093885919733008\n",
      "==================================================\n",
      "epoch 4\n",
      "epoch 4 train loss = 2.344424665739953, time = 1232.566342830658\n",
      "epoch 4 val_train loss = 7.298277771229647, time = 4.584500074386597\n",
      "true corpus ['according to a quranic verse &quot; salam &quot; -- peace -- &quot; is the word of the all-merciful god , raheem . &quot;', 'but if we don &apos;t change the composition of the soil , we will never do this .', 'since my family couldn &apos;t speak chinese , i had to guide them , somehow , through more than 2,000 miles in china and then into southeast asia .', 'and i always just say , &quot; oh , i was scouted , &quot; but that means nothing .', 'and first , i commend you on your model knowledge . very impressive .']\n",
      "pred corpus ['there are truths about phrases that are not reported to be represented .', 'we &apos;re going to use it to make it happen .', 'but you can &apos;t tell me , you know , the people who are', 'i &apos;m going to make it a', 'i want you to just think it &apos;s a little bit difficult to be here with a girl who is really involved in this game , and that is a wonderful thing']\n",
      "validation BLEU =  19.127579715374882\n",
      "==================================================\n",
      "Training completed. Best BLEU is 19.34048507849997\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc6.parameters(), lr=1e-5)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-6,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec6.parameters(), lr=1e-5)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-6,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "\n",
    "enc7, dec7, loss_hist6, acc_hist6 = train(encoder_optimizer,\n",
    "                                          decoder_optimizer,\n",
    "                                          enc6, dec6,\n",
    "                                          criterion,\n",
    "                                          \"attention\",\n",
    "                                          dataloader, vien_en_,\n",
    "                                          num_epochs = 5, rm = 0.95,\n",
    "                                          enc_scheduler = enc_scheduler, \n",
    "                                          dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# encoder_optimizer = optim.Adam(enc7.parameters(), lr=5e-6)\n",
    "# enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, min_lr=9e-7,  patience=0)\n",
    "# decoder_optimizer = optim.Adam(dec7.parameters(), lr=5e-6)\n",
    "# dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, min_lr=9e-7,  patience=0)\n",
    "\n",
    "# # vietnamese -> english\n",
    "# criterion = nn.NLLLoss(ignore_index=0)\n",
    "# enc8, dec8, loss_hist6, acc_hist6 = train(encoder_optimizer, \n",
    "#                                             decoder_optimizer, \n",
    "#                                             enc7, dec7, \n",
    "#                                             criterion,\n",
    "#                                             \"attention\", \n",
    "#                                             dataloader,vien_en_, \n",
    "#                                             num_epochs = 5, rm = 0.95,\\\n",
    "#                                            enc_scheduler = enc_scheduler, dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "epoch 0 train loss = 2.253924560923617, time = 1232.7297248840332\n",
      "epoch 0 val_train loss = 7.296722560026208, time = 4.623219966888428\n",
      "true corpus ['it was an isolated incident , and he was never going to hurt me again .', 'i remarried a kind and gentle man , and we have those three kids .', 'so luckily i brought an outfit change .', 'there she is .', 'because you can see where i am , where i sleep at night , what i am doing .']\n",
      "pred corpus ['and then , of course , they don &apos;t .', 'i am a dad .', 'i &apos;ve been working with a to to', 'she &apos;s a very , , ,', 'and i know that as a kid , i have to do something about it .']\n",
      "validation BLEU =  19.133692547201704\n",
      "==================================================\n",
      "epoch 1\n",
      "epoch 1 train loss = 2.2141385778340186, time = 1231.6295711994171\n",
      "epoch 1 val_train loss = 7.308412345574826, time = 4.6126954555511475\n",
      "true corpus ['i was very lucky to grow up in a family where education was prized and daughters were treasured .', 'the next question people always ask me is , &quot; do they retouch all the photos ? &quot;', 'we see vocal tremor , weakness and rigidity .', 'the journey by bus took one week , and we were almost caught several times .', 'we have helped to start 40,000 businesses .']\n",
      "pred corpus ['i think that the girls in the school are girls in the .', 'and so i said , &quot; well ,', 'and i said , &quot; well ,', 'and the next morning , i &apos;d be walking around with a guy from the university of california .', 'and we were really excited to be able to do , .']\n",
      "validation BLEU =  19.102110514010544\n",
      "==================================================\n",
      "epoch 2\n",
      "epoch 2 train loss = 2.231265351505166, time = 1232.1816697120667\n",
      "epoch 2 val_train loss = 7.313315582275391, time = 4.611903667449951\n",
      "true corpus ['and the first answer is , &quot; i don &apos;t know , they don &apos;t put me in charge of that . &quot;', 'however , gaddafi left behind a heavy burden , a legacy of tyranny , corruption and seeds of diversions .', 'we take photos constantly .', 'before march , 2011 , i was a photographic retoucher based in new york city .', 'one was that he , too , had just graduated from an ivy league school , and that he worked at a very impressive wall street bank .']\n",
      "pred corpus ['and she said , &quot; i &apos;m going to', 'we know that isolation kills .', 'and then we were on june 12 , and we', 'i was in the a to , , , , , , , , . .', 'he &apos;s a former member of the with . .']\n",
      "validation BLEU =  19.147639869494206\n",
      "==================================================\n",
      "epoch 3\n",
      "epoch 3 train loss = 2.2306349583682126, time = 1232.5661568641663\n",
      "epoch 3 val_train loss = 7.334201277518759, time = 4.54818320274353\n",
      "true corpus ['the person with the idea may not have the knowledge , but the knowledge is available .', 'i was so shocked .', 'but if we don &apos;t change the composition of the soil , we will never do this .', 'and it hit me : one of the most important things we all make are memories .', 'and we need to establish that existentially before we do so sociopolitically .']\n",
      "pred corpus ['but i think that the , the , , , , , , , , . .', 'i was a little the , , i', 'we &apos;re going to use it to make it happen .', 'i &apos;m going to talk about the , , , .', 'so we need to do that in a , , , . , . .']\n",
      "validation BLEU =  19.233480537204994\n",
      "==================================================\n",
      "epoch 4\n",
      "epoch 4 train loss = 2.235858963012925, time = 1231.660903453827\n",
      "epoch 4 val_train loss = 7.3307899144231055, time = 4.605321407318115\n",
      "true corpus ['takes about $ 300 , by the way , in the neurologist &apos;s clinic to do it .', 'i was helping clean the onsen , the communal onsen , the huge giant bathtubs .', 'to me , afghanistan is a country of hope and boundless possibilities , and every single day the girls of sola remind me of that .', 'gardening is my graffiti . i grow my art .', 'he had just been really stressed out by the wedding and by becoming a family with me .']\n",
      "pred corpus ['and they were going to give it back .', 'it &apos;s a border of honor and comfort and shelter in the bible .', 'i think that the way i of is , , , , i', 'and i &apos;ve been to russia since i was a to of .', 'he had been in a catastrophic position with me , and i had a dream of that .']\n",
      "validation BLEU =  19.351311379020526\n",
      "==================================================\n",
      "Training completed. Best BLEU is 19.351311379020526\n"
     ]
    }
   ],
   "source": [
    "encoder_optimizer = optim.Adam(enc7.parameters(), lr=1e-6)\n",
    "enc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-7,  patience=0)\n",
    "decoder_optimizer = optim.Adam(dec7.parameters(), lr=1e-6)\n",
    "dec_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, \n",
    "                                                           min_lr=1e-7,  patience=0)\n",
    "\n",
    "# vietnamese -> english\n",
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "enc8, dec8, loss_hist6, acc_hist6 = train(encoder_optimizer,\n",
    "                                          decoder_optimizer,\n",
    "                                          enc7, dec7,\n",
    "                                          criterion,\n",
    "                                          \"attention\",\n",
    "                                          dataloader, vien_en_,\n",
    "                                          num_epochs = 5, rm = 0.95,\n",
    "                                          enc_scheduler = enc_scheduler,\n",
    "                                          dec_scheduler = dec_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# [BeamSearch(enc7, dec7, dataloader[\"val\"], vien_en_, 8) for x in range(10)]\n",
    "# scores go down as we increase the beam size too much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.81742572124765\n",
      "BLEU score calculated on the validation set is  20.74348936315408\n",
      "BLEU score calculated on the validation set is  20.78065253900282\n",
      "BLEU score calculated on the validation set is  20.822702964482854\n",
      "BLEU score calculated on the validation set is  20.786162523535292\n",
      "BLEU score calculated on the validation set is  20.77832767049285\n",
      "BLEU score calculated on the validation set is  20.8010395838305\n",
      "BLEU score calculated on the validation set is  20.746004956538503\n",
      "BLEU score calculated on the validation set is  20.846297169599904\n",
      "BLEU score calculated on the validation set is  20.76642701381443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.81742572124765,\n",
       " 20.74348936315408,\n",
       " 20.78065253900282,\n",
       " 20.822702964482854,\n",
       " 20.786162523535292,\n",
       " 20.77832767049285,\n",
       " 20.8010395838305,\n",
       " 20.746004956538503,\n",
       " 20.846297169599904,\n",
       " 20.76642701381443]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[BeamSearch(enc7, dec7, dataloader[\"val\"], vien_en_, 3) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.999334492052036\n",
      "BLEU score calculated on the validation set is  21.072687856938643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.999334492052036, 21.072687856938643]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[BeamSearch(enc7, dec7, dataloader[\"val\"], vien_en_, 2) for x in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score calculated on the validation set is  20.997950236516527\n",
      "BLEU score calculated on the validation set is  20.967508433357416\n",
      "BLEU score calculated on the validation set is  20.987145049548253\n",
      "BLEU score calculated on the validation set is  21.107329578393895\n",
      "BLEU score calculated on the validation set is  20.92650789232682\n",
      "BLEU score calculated on the validation set is  21.014706833233507\n",
      "BLEU score calculated on the validation set is  20.957583094547942\n",
      "BLEU score calculated on the validation set is  21.05644986944498\n",
      "BLEU score calculated on the validation set is  20.937051853904997\n",
      "BLEU score calculated on the validation set is  21.011069857017333\n",
      "BLEU score calculated on the validation set is  21.015142363469657\n",
      "BLEU score calculated on the validation set is  20.99320398021949\n",
      "BLEU score calculated on the validation set is  20.949605129255378\n",
      "BLEU score calculated on the validation set is  20.99183222094368\n",
      "BLEU score calculated on the validation set is  21.066599009583822\n",
      "BLEU score calculated on the validation set is  21.00828760056704\n",
      "BLEU score calculated on the validation set is  20.991591556416193\n",
      "BLEU score calculated on the validation set is  21.006153810510092\n",
      "BLEU score calculated on the validation set is  21.008781753343847\n",
      "BLEU score calculated on the validation set is  20.98935781975807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[20.997950236516527,\n",
       " 20.967508433357416,\n",
       " 20.987145049548253,\n",
       " 21.107329578393895,\n",
       " 20.92650789232682,\n",
       " 21.014706833233507,\n",
       " 20.957583094547942,\n",
       " 21.05644986944498,\n",
       " 20.937051853904997,\n",
       " 21.011069857017333,\n",
       " 21.015142363469657,\n",
       " 20.99320398021949,\n",
       " 20.949605129255378,\n",
       " 20.99183222094368,\n",
       " 21.066599009583822,\n",
       " 21.00828760056704,\n",
       " 20.991591556416193,\n",
       " 21.006153810510092,\n",
       " 21.008781753343847,\n",
       " 20.98935781975807]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[BeamSearch(enc7, dec7, dataloader[\"val\"], vien_en_, 2) for x in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best encoder - attn\n",
    "torch.save(enc7, \"best_attn_rnn_totest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adc563/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type AttnDecoderRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/adc563/pytorch-cpu/py3.6.3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Attention_Module. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# save best decoder - attn\n",
    "torch.save(dec7, \"best_attn_rnn_DEC_totest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeamSearch\n",
    "def BeamSearch(encoder_model, \n",
    "               decoder_model, \n",
    "               val_loader,\n",
    "               en_, # vien_en_ or zhen_en_\n",
    "               beam_size, \n",
    "               device = \"cuda\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Params\n",
    "    :encoder_model: Trained RNN or CNN encoder model.\n",
    "    :decoder_model: Trained RNN or RNN w/attention decoder model.\n",
    "    :val_loader: Validation dataloader object.\n",
    "    :en_: The English language (target) object of the passed val_loader language.\n",
    "    :beam_size: The function selects beam_size-many hypotheses with the highest log prob\n",
    "                at each timestep.\n",
    "\n",
    "    Returns\n",
    "    :4-gram precision BLEU score for the given validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    encoder_model.eval()\n",
    "    decoder_model.eval()\n",
    "\n",
    "    model_corpus = []\n",
    "    reference_corpus = []\n",
    "\n",
    "    encoder_model = encoder_model.to(device)\n",
    "    decoder_model = decoder_model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_total = 0\n",
    "\n",
    "    # iterate over val_loader until computing the final\n",
    "    # corpus-level BLEU score\n",
    "    for sentence_pair in val_loader:\n",
    "        # encoder input = source sentence\n",
    "        encoder_input = sentence_pair[0].to(device)\n",
    "        source_lengths = sentence_pair[2].to(device)\n",
    "\n",
    "        seqlen_ = torch.max(source_lengths) # max_len\n",
    "        batch_size, seq_len = encoder_input.size()[:2]\n",
    "        \n",
    "        encoder_out, encoder_hidden, encoder_context = encoder_model(encoder_input,\n",
    "                                                                     source_lengths)\n",
    "        \n",
    "        prev_hiddens, prev_context = encoder_hidden, encoder_context\n",
    "\n",
    "        # first input to the decoder should be SOS tokens (1)\n",
    "        decoder_input = torch.tensor([[SOS_token]]*batch_size).to(device)\n",
    "\n",
    "        prev_output = torch.zeros((batch_size, \n",
    "                                   encoder_out.size(-1))).to(device)\n",
    "\n",
    "        decoder_input_list = [None]*beam_size\n",
    "\n",
    "        end_beam = [False]*beam_size\n",
    "\n",
    "        # init beam scores - batch_size x beam_size\n",
    "        beam_scores = torch.zeros((batch_size,beam_size)).to(device)\n",
    "\n",
    "        decoder_out_list = [[]]*beam_size\n",
    "\n",
    "        for t in range(seq_len+20):\n",
    "\n",
    "            if t == 0:\n",
    "\n",
    "                outs, prev_output, prev_hiddens, \\\n",
    "                prev_context, attn_score = decoder_model(decoder_input,\n",
    "                                                              prev_output,\n",
    "                                                              prev_hiddens,\n",
    "                                                              prev_context, \n",
    "                                                              en_out,\n",
    "                                                              source_lengths)\n",
    "                \n",
    "                # get top beam_size-many scores and their indices\n",
    "                top_scores, top_indices = outs.topk(beam_size)\n",
    "                out_s, vocab_size = outs.size()\n",
    "\n",
    "                prev_out_list = [prev_output]*beam_size\n",
    "                prev_hidden_list = [prev_hiddens]*beam_size\n",
    "                prev_context_list = [prev_context]*beam_size\n",
    "\n",
    "                for beam_i in range(beam_size):\n",
    "\n",
    "                    beam_scores[0][beam_i] = top_scores[0][beam_i].item()\n",
    "                    decoder_input_list[beam_i] = top_indices[0][beam_i].squeeze().detach().\\\n",
    "                                                                                    view(-1,1)\n",
    "                    decoder_out_list[beam_i].append(top_indices[0][beam_i].item())\n",
    "\n",
    "                    if top_indices[0][beam_i].item() == EOS_token:\n",
    "                        end_beam[beam_i] = True\n",
    "\n",
    "            else:\n",
    "\n",
    "                out_t, hidden_t, context_t, hold_beam = beam_size*[None], beam_size*[None], \\\n",
    "                                                        beam_size*[None], beam_size*[None]\n",
    "                \n",
    "                prev_ys = copy.deepcopy(decoder_out_list)\n",
    "\n",
    "                for beam_i in [*range(beam_size)]:\n",
    "\n",
    "                    if not end_beam[beam_i]:\n",
    "\n",
    "                        hold_beam[beam_i], out_t[beam_i], hidden_t[beam_i], \\\n",
    "                        context_t[beam_i], attn_score = decoder_model(decoder_input_list[beam_i],\n",
    "                                                                        prev_out_list[beam_i],\n",
    "                                                                        prev_hidden_list[beam_i],\n",
    "                                                                        prev_context_list[beam_i],\n",
    "                                                                        encoder_out,\n",
    "                                                                        source_lengths)\n",
    "\n",
    "                        hold_beam[beam_i] = hold_beam[beam_i] + beam_scores[0][beam_i]\n",
    "\n",
    "                    if end_beam[beam_i]:\n",
    "\n",
    "                        hold_beam[beam_i] = torch.zeros(out_s, vocab_size).fill_(-np.inf).to(device)\n",
    "\n",
    "                hold_beam = torch.cat(hold_beam, dim=1)\n",
    "                top_scores, top_indices = hold_beam.topk(beam_size)\n",
    "\n",
    "                hidden_id = top_indices//vocab_size\n",
    "                top_indices_ = top_indices%vocab_size\n",
    "\n",
    "                for beam_i in range(beam_size):\n",
    "\n",
    "                    if not end_beam[beam_i]:\n",
    "\n",
    "                        beam_scores[0][beam_i] = top_scores[0][beam_i].item()\n",
    "                        list_decoder_input[beam_i] = top_indices_[0][beam_i].squeeze().detach().view(-1,1)\n",
    "                        decoder_out_list[beam_i] = copy.deepcopy(prev_ys[hidden_id[0][beam_i]])\n",
    "                        decoder_out_list[beam_i].append(top_indices_[0][beam_i].item())\n",
    "\n",
    "                        # <EOS>\n",
    "                        if top_indices_[0][beam_i].item() == EOS_token:\n",
    "                            end_beam[beam_i] = True\n",
    "\n",
    "                        else:\n",
    "                            prev_out_list[beam_i] = out_t[hidden_id[0][beam_i]]\n",
    "                            prev_context_list[beam_i] = context_t[hidden_id[0][beam_i]]\n",
    "                            prev_hidden_list[beam_i] = hidden_t[hidden_id[0][beam_i]]\n",
    "                            \n",
    "                # all batch <EOS>\n",
    "                if all(end_beam):\n",
    "                    break\n",
    "\n",
    "        max_score_id = np.argmax(beam_scores)\n",
    "\n",
    "        decoder_out = decoder_out_list[max_score_id]\n",
    "\n",
    "        reference_corpus.append(sentence_pair[-1]) # true/reference sentence\n",
    "        pred_sentence = id2text_(decoder_out, en_) # predicted sentence\n",
    "        model_corpus.append(pred_sentence)\n",
    "    \n",
    "    # import above - from sacreBLEU.sacreBLEU import corpus_bleu\n",
    "    # WARNING: Do not forget to join the lists before computing BLEU score!\n",
    "    # Otherwise your BLEU score will be far below the true one.\n",
    "    bleu_score = corpus_bleu((\" \").join(model_corpus),\n",
    "                             (\" \").join(reference_corpus))[0]\n",
    "\n",
    "    print (\"BLEU score calculated on the validation set is \", score)\n",
    "\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 CNN Encoder + RNN Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNNencoder\n",
    "class CNNencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 vocab_size, \n",
    "                 embed_size, \n",
    "                 hidden_size, \n",
    "                 kernel_size, \n",
    "                 num_layers,\n",
    "                 percent_dropout=0.3):\n",
    "        \n",
    "        super(CNNencoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.embed_size = embed_size\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, \n",
    "                                      self.embed_size, \n",
    "                                      padding_idx=0)\n",
    "        \n",
    "        self.dropout_f = nn.Dropout(percent_dropout)\n",
    "        \n",
    "        in_channels = self.embed_size\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels,\n",
    "                              self.hidden_size,\n",
    "                              kernel_size, \n",
    "                              padding=kernel_size//2)\n",
    "        \n",
    "        # todo\n",
    "        self.conv2 = nn.Conv1d(60, self.hidden_size, \n",
    "                               kernel_size,\n",
    "                               padding=kernel_size//2)\n",
    "        \n",
    "        self.ReLU = nn.ReLU()\n",
    "\n",
    "    def forward(self, source_sentence):\n",
    "        \n",
    "        batch_size, seq_len = source_sentence.size()\n",
    "        \n",
    "        embeds_source = self.embedding(source_sentence)\n",
    "        \n",
    "        out = self.conv1(embeds_source.transpose(1, 2)).transpose(1,2)\n",
    "        out = self.ReLU(out)\n",
    "        out = F.max_pool1d(out, kernel_size=5, stride=5)\n",
    "        \n",
    "        out = self.conv2(out.transpose(1, 2)).transpose(1,2)\n",
    "        out = self.ReLU(out)\n",
    "        out = torch.mean(out, dim=1).view(1, batch_size, self.hidden_size)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_cnn(encoder_model,\n",
    "                  decoder_model,\n",
    "                  source_sentence,\n",
    "                  target_sentence,\n",
    "                  source_lengths):\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < 0.6 else False\n",
    "    \n",
    "    batch_size = source_sentence.size(0)\n",
    "    \n",
    "    encoder_hidden = encoder_model(source_sentence)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]]*batch_size).to(device)\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        decoder_out = []\n",
    "         \n",
    "        for time_step in range(MAX_SENTENCE_LENGTH):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder_model(decoder_input,\n",
    "                                                           decoder_hidden,\n",
    "                                                           encoder_outputs=None)\n",
    "            decoder_out.append(decoder_output.unsqueeze(-1))\n",
    "            decoder_input = target_sentence[:,time_step].view(-1,1)\n",
    "            \n",
    "        decoder_out = torch.cat(decoder_out,\n",
    "                                dim=-1)\n",
    "    else:\n",
    "        \n",
    "        decoder_out = []\n",
    "        for time_step in range(MAX_SENTENCE_LENGTH):\n",
    "            \n",
    "            decoder_output, decoder_hidden = decoder_model(decoder_input,\n",
    "                                                           decoder_hidden,\n",
    "                                                           encoder_output)\n",
    "            \n",
    "            decoder_out.append(decoder_output.unsqueeze(-1))\n",
    "            top_scores, top_indices = decoder_output.topk(1)\n",
    "            decoder_input = top_indices.squeeze().detach().view(-1,1)\n",
    "            \n",
    "        decoder_out = torch.cat(decoder_out,\n",
    "                                dim=-1)\n",
    "        \n",
    "    return decoder_out, decoder_hidden\n",
    "\n",
    "\n",
    "def train_cnn(encoder_optimizer,\n",
    "              decoder_optimizer,\n",
    "              encoder_model, decoder_model,\n",
    "              loss_function,\n",
    "              data_loader,\n",
    "              en_lang, # \"vien_en_\" for vietnamese -> eng, \"zhen_en_\" for chinese -> eng\n",
    "              num_epochs=10, val_interval=1, rm = 0.8, \n",
    "              enc_scheduler=None, \n",
    "              dec_scheduler=None):\n",
    "\n",
    "    mode_list = [\"train\",\"val_train\"] # val_train, val every val_interval train epochs\n",
    "    loss_hist = {\"train\": [], \"val_train\": []}\n",
    "    BLEU_hist = {\"train\": [], \"val\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print (\"epoch\", epoch)\n",
    "\n",
    "        for ex, mode in enumerate(mode_list):\n",
    "            \n",
    "            start = time.time()\n",
    "            total = 0\n",
    "            top1_correct = 0\n",
    "            running_loss = 0\n",
    "            running_total = 0\n",
    "            \n",
    "            if mode == \"train\":\n",
    "                encoder.train()\n",
    "                decoder.train()\n",
    "                \n",
    "            elif mode == \"val_train\":\n",
    "                encoder.eval()\n",
    "                decoder.eval()\n",
    "            else:\n",
    "                raise ValueError\n",
    "                \n",
    "            for data in data_loader[mode]:\n",
    "                \n",
    "                encoder_optimizer.zero_grad()\n",
    "                decoder_optimizer.zero_grad()\n",
    "\n",
    "                encoder_input, decoder_input = data[0].to(device), data[1].to(device)\n",
    "                source_lengths, target_lengths = data[2].to(device), data[3].to(device)\n",
    "\n",
    "                if mode == \"val_train\":                \n",
    "                    \n",
    "                    output = encode_decode_cnn(encoder_model, decoder_model,\n",
    "                                               encoder_input, decoder_input,\n",
    "                                               source_lengths)\n",
    "                else:\n",
    "                    output = encode_decode_cnn(encoder_model, decoder_model,\n",
    "                                               encoder_input, decoder_input,\n",
    "                                               source_lengths)\n",
    "                    \n",
    "                loss = loss_function(output.float(), \n",
    "                                     decoder_input[:,:output.size(-1)].long())\n",
    "                \n",
    "                batch = decoder_input.size(0)\n",
    "                \n",
    "                running_loss += loss.item()*batch\n",
    "                \n",
    "                total += batch\n",
    "                \n",
    "                if mode == \"train\":\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    \n",
    "                    torch.nn.utils.clip_grad_norm_(encoder.parameters(), 0.15)\n",
    "                    torch.nn.utils.clip_grad_norm_(decoder.parameters(), 0.15)\n",
    "                    \n",
    "                    encoder_optimizer.step()\n",
    "                    decoder_optimizer.step()\n",
    "                    \n",
    "            epoch_loss = running_loss / total \n",
    "            loss_hist[mode].append(epoch_loss)\n",
    "            print(\"epoch {} {} loss = {}, time = {}\".format(epoch, mode, epoch_loss,\n",
    "                                                                           time.time() - start))\n",
    "        if (enc_scheduler is not None) and (dec_scheduler is not None):\n",
    "            enc_scheduler.step(epoch_loss)\n",
    "            dec_scheduler.step(epoch_loss)\n",
    "            \n",
    "        if epoch % val_interval == 0:\n",
    "            val_bleu_score = eval_(encoder_model, decoder_model, data_loader[\"val\"], en_lang)\n",
    "            BLEU_hist[\"val\"].append(val_bleu_score)\n",
    "            print(\"validation BLEU = \", val_bleu_score)\n",
    "\n",
    "    return encoder_model, decoder_model, loss_hist, BLEU_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "bi=True\n",
    "# bi=False\n",
    "encoder_ = CNNencoder(zhen_zh_.n_words,\n",
    "                      300,300, 5,1,\n",
    "                      percent_dropout=0.3).to(device)\n",
    "\n",
    "decoder_ = RNNdecoder(300,zhen_en_.n_words).to(device)\n",
    "encoder_optimizer = optim.Adam(encoder_.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder_.parameters(), lr=learning_rate)\n",
    "criterion = nn.NLLLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with encode decode cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss =  2.0075799999086135\n",
      "Validation BLEU =  6.015097639602013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss =  1.9711387605708715\n",
      "Traning BLEU =  6.245280354192027\n",
      "epoch 0 train loss = 2.2194282125410028, accurancy = 0 time = 1621.194352388382\n",
      "epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:root:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:root:If you insist your data is detokenized, or don't care, you can suppress this message with '--force'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss =  1.9987231105064898\n",
      "Validation BLEU =  5.756828060121056\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-355-546b1d76c123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m enc, dec = train_model(encoder_optimizer, decoder_optimizer, encoder_, decoder_, \n\u001b[0;32m----> 2\u001b[0;31m                        zhen_loader, criterion, num_epochs = 3, lang_en=zhen_en_)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-353-ee9cf76ed314>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(encoder_optimizer, decoder_optimizer, encoder, decoder, dataloader, loss_function, num_epochs, lang_en)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation Loss = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation BLEU = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Traning BLEU = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-353-ee9cf76ed314>\u001b[0m in \u001b[0;36mvalidate_model\u001b[0;34m(encoder, decoder, dataloader, loss_fun, lang_en)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mencoder_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdecoder_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msource_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_decode_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc, dec, loss_hist, bleu_hist = train_cnn(encoder_optimizer, decoder_optimizer,\n",
    "                                           encoder_, decoder_,\n",
    "                                           criterion, zhen_loader, zhen_en_,\n",
    "                                           num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
