{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Spring 2018 NLP Class Project: Neural Machine Translation</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pdb\n",
    "import os\n",
    "from underthesea import word_tokenize\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install spacy && python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Project Overview\n",
    "\n",
    "The goal of this project is to build a neural machine translation system and experience how recent advances have made their way. Each team will build the following sequence of neural translation systems for two language pairs, __Vietnamese (Vi)→English (En)__ and __Chinese (Zh)→En__ (prepared corpora is be provided):\n",
    "\n",
    "1. Recurrent neural network based encoder-decoder without attention\n",
    "2. Recurrent neural network based encoder-decoder with attention\n",
    "2. Replace the recurrent encoder with either convolutional or self-attention based encoder.\n",
    "4. [Optional] Build either or both fully self-attention translation system or/and multilingual translation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Upload & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of sentence\n",
    "SOS_token = 1\n",
    "# end of sentence\n",
    "EOS_token = 3\n",
    "\n",
    "## 2 = unk\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0:\"<PAD>\",1: \"<SOS>\", 2:\"<UNK>\", 3: \"<EOS>\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    \"\"\"About \"NFC\" and \"NFD\": \n",
    "    \n",
    "    For each character, there are two normal forms: normal form C \n",
    "    and normal form D. Normal form D (NFD) is also known as canonical \n",
    "    decomposition, and translates each character into its decomposed form. \n",
    "    Normal form C (NFC) first applies a canonical decomposition, then composes \n",
    "    pre-combined characters again.\n",
    "    \n",
    "    About unicodedata.category: \n",
    "    \n",
    "    Returns the general category assigned to the Unicode character \n",
    "    unichr as string.\"\"\"\n",
    "    \n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Trim\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False,\n",
    "             dataset=\"train\"):\n",
    "    \n",
    "    \"\"\"Takes as input;\n",
    "    - lang1, lang2: either (vi, en) or (zh, en)\n",
    "    - dataset: one of (\"train\",\"dev\",\"test\")\"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "    eos = [\".\",\"?\",\"!\",\"\\n\"]\n",
    "    # Read the pretokenized lang1 file and split into lines\n",
    "    lang1_lines = open(\"../data/tokens_and_preprocessing_em/pretokenized_data/iwslt-%s-%s-processed/%s.tok.%s\" % (lang1, lang2, dataset, lang1), encoding=\"utf-8\").\\\n",
    "        read().strip().split(\"\\n\")\n",
    "    # Read the lang2 file and split into lines\n",
    "    lang2_lines = open(\"../data/tokens_and_preprocessing_em/pretokenized_data/iwslt-%s-%s-processed/%s.tok.%s\" % (lang1, lang2, dataset, lang2), encoding=\"utf-8\").\\\n",
    "        read().strip().split(\"\\n\")\n",
    "    \n",
    "    # create sentence pairs (lists of length 2 that consist of string pairs)\n",
    "    # e.g. [\"And we &apos;re going to tell you some stories from the sea here in video .\",\n",
    "    #       \"我们 将 用 一些 影片 来讲 讲述 一些 深海 海里 的 故事  \"]\n",
    "    # check if there are the same number of sentences in each set\n",
    "    assert len(lang1_lines) == len(lang2_lines), \"Two languages must have the same number of sentences. \"+ str(len(lang1_lines)) + \" sentences were passed for \" + str(lang1) + \".\" + str(len(lang2_lines)) + \" sentences were passed for \" + str(lang2)+\".\"\n",
    "    # normalize if not Chinese, Chinese normalization is already handeled\n",
    "    if lang1 == \"zh\":\n",
    "        lang1_lines = lang1_lines\n",
    "    else:\n",
    "        lang1_lines = [normalizeString(s) for s in lang1_lines]\n",
    "    lang2_lines = [normalizeString(s) for s in lang2_lines]\n",
    "    # construct pairs\n",
    "    pair_ran = range(len(lang1_lines))\n",
    "    pairs = [[lang1_lines[i]] + [lang2_lines[i]] for i in pair_ran]\n",
    "    \n",
    "#     # Split every line into pairs and normalize\n",
    "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 133317 sentence pairs\n",
      "Trimmed to 133317 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 16144\n",
      "en 47568\n",
      "['nhung toi cho rang tren tat ca mot buc tranh tuoi ep ve the gioi nay', 'But I want to argue above all a big picture positive for this world .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False, dataset=\"train\"):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse, dataset=dataset)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# example\n",
    "input_lang, output_lang, pairs = prepareData('vi', 'en', False, dataset=\"train\")\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213376 sentence pairs\n",
      "Trimmed to 213376 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 88917\n",
      "en 59329\n",
      "['大量 的 样本 是 必须 的 ', 'A very large sample is needed .']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('zh', 'en', False, dataset=\"train\")\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Vietnamese to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Please find the original tokenizing code provided by Elman Mansimov in the following link:\n",
    "# # https://github.com/derincen/neural-machine-translation/tree/master/data/tokens_and_preprocessing_em/preprocess_translation\n",
    "\n",
    "# def tokenize_vi(f_names, f_out_names):\n",
    "#     for f_name, f_out_name in zip(f_names, f_out_names):\n",
    "#         lines = open(f_name, 'r').readlines()\n",
    "#         tok_lines = open(f_out_name, 'w')\n",
    "#         for i, sentence in enumerate(lines):\n",
    "#             if i > 0 and i % 1000 == 0:\n",
    "#                 print (f_name.split('/')[-1], i, len(lines))\n",
    "#             tok_lines.write(word_tokenize(sentence, format=\"text\") + '\\n')\n",
    "#         tok_lines.close()\n",
    "\n",
    "# def tokenize_en(f_names, f_out_names):\n",
    "#     tokenizer = spacy.load('en_core_web_sm')\n",
    "\n",
    "#     for f_name, f_out_name in zip(f_names, f_out_names):\n",
    "#         lines = open(f_name, 'r').readlines()\n",
    "#         tok_lines = open(f_out_name, 'w')\n",
    "#         for i, sentence in enumerate(lines):\n",
    "#             if i > 0 and i % 1000 == 0:\n",
    "#                 print (f_name.split('/')[-1], i, len(lines))\n",
    "#             # replaced tokenizer(sentence) with str(tokenizer(sentence)) to avoid \n",
    "#             # type error while joining\n",
    "#             tok_lines.write(' '.join(str(tokenizer(sentence))) + '\\n')\n",
    "#         tok_lines.close()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     root = '../data/tokens_and_preprocessing_em/pretokenized_data/iwslt-vi-en-processed/'\n",
    "#     tokenize_vi([os.path.join(root, 'train.vi'), os.path.join(root, 'dev.vi'), \n",
    "#                  os.path.join(root, 'test.vi')],\\\n",
    "#                [os.path.join(root, 'train.tok.vi'), os.path.join(root, 'dev.tok.vi'), \n",
    "#                 os.path.join(root, 'test.tok.vi')])\n",
    "\n",
    "#     tokenize_en([os.path.join(root, 'train.en'), os.path.join(root, 'dev.en'), \n",
    "#                  os.path.join(root, 'test.en')],\\\n",
    "#                 [os.path.join(root, 'train.tok.en'), os.path.join(root, 'dev.tok.en'), \n",
    "#                  os.path.join(root, 'test.tok.en')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 133317 sentence pairs\n",
      "Trimmed to 133317 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 16144\n",
      "en 47568\n",
      "Reading lines...\n",
      "Read 1268 sentence pairs\n",
      "Trimmed to 1268 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 1370\n",
      "en 3816\n",
      "Reading lines...\n",
      "Read 1553 sentence pairs\n",
      "Trimmed to 1553 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 1325\n",
      "en 3619\n"
     ]
    }
   ],
   "source": [
    "# Format: languagepair_language_dataset\n",
    "# Train \n",
    "vien_vi_train, vien_en_train, vi_en_train_pairs = prepareData('vi', 'en', False, dataset=\"train\")\n",
    "# Dev \n",
    "vien_vi_dev, vien_en_dev, vi_en_dev_pairs = prepareData('vi', 'en', False, dataset=\"dev\")\n",
    "# Test\n",
    "vien_vi_test, vien_en_test, vi_en_test_pairs = prepareData('vi', 'en', False, dataset=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Chinese to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Please find the original tokenizing code provided by Elman Mansimov in the following link:\n",
    "# # https://github.com/derincen/neural-machine-translation/tree/master/data/tokens_and_preprocessing_em/preprocess_translation\n",
    "\n",
    "# def tokenize_zh(f_names, f_out_names):\n",
    "#     for f_name, f_out_name in zip(f_names, f_out_names):\n",
    "#         lines = open(f_name, 'r').readlines()\n",
    "#         tok_lines = open(f_out_name, 'w')\n",
    "#         for i, sentence in enumerate(lines):\n",
    "#             if i > 0 and i % 1000 == 0:\n",
    "#                 print (f_name.split('/')[-1], i, len(lines))\n",
    "#             tok_lines.write(' '.join(jieba.cut(sentence, cut_all=True)))\n",
    "#         tok_lines.close()\n",
    "\n",
    "# def tokenize_en(f_names, f_out_names):\n",
    "#     tokenizer = spacy.load('en_core_web_sm')\n",
    "\n",
    "#     for f_name, f_out_name in zip(f_names, f_out_names):\n",
    "#         lines = open(f_name, 'r').readlines()\n",
    "#         tok_lines = open(f_out_name, 'w')\n",
    "#         for i, sentence in enumerate(lines):\n",
    "#             if i > 0 and i % 1000 == 0:\n",
    "#                 print (f_name.split('/')[-1], i, len(lines))\n",
    "#             # replaced tokenizer(sentence) with str(tokenizer(sentence)) to avoid \n",
    "#             # type error while joining\n",
    "#             tok_lines.write(' '.join(str(tokenizer(sentence))) + '\\n')\n",
    "#         tok_lines.close()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     root = '../data/tokens_and_preprocessing_em/pretokenized_data/iwslt-zh-en-processed/'\n",
    "#     tokenize_zh([os.path.join(root, 'dev.zh'), os.path.join(root, 'test.zh'), os.path.join(root, 'train.zh')],\\\n",
    "#                 [os.path.join(root, 'dev.tok.zh'), os.path.join(root, 'test.tok.zh'), os.path.join(root, 'train.tok.zh')])\n",
    "\n",
    "# #     tokenize_en([os.path.join(root, 'dev.en'), os.path.join(root, 'test.en'), os.path.join(root, 'train.en')],\\\n",
    "# #                [os.path.join(root, 'dev.tok.en'), os.path.join(root, 'test.tok.en'), os.path.join(root, 'train.tok.en')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213376 sentence pairs\n",
      "Trimmed to 213376 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 88917\n",
      "en 59329\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Trimmed to 1261 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 6132\n",
      "en 3916\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Trimmed to 1397 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 5214\n",
      "en 3423\n"
     ]
    }
   ],
   "source": [
    "# Format: languagepair_language_dataset\n",
    "# Train \n",
    "zhen_zh_train, zhen_en_train, zh_en_train_pairs = prepareData('zh', 'en', False, dataset=\"train\")\n",
    "# Dev \n",
    "zhen_zh_dev, zhen_en_dev, zh_en_dev_pairs = prepareData('zh', 'en', False, dataset=\"dev\")\n",
    "# Test\n",
    "zhen_zh_test, zhen_en_test, zh_en_test_pairs = prepareData('zh', 'en', False, dataset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我们 将 用 一些 影片 来讲 讲述 一些 深海 海里 的 故事  ',\n",
       " 'And we apos re going to tell you some stories from the sea here in video .']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_en_train_pairs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Check Source & Target Vocabs\n",
    "\n",
    "Since the source and target languages can have very different table lookup layers, it's good practice to have separate vocabularies for each. Thus, we build vocabularies for each language that we will be using. \n",
    "\n",
    "In the first class (Lang) of this section, we have already defined vocabularies for all languages. So, there is no need to redefine another function. We chech each vocabulary below.\n",
    "\n",
    "#### Chinese Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in Chinese training corpus is 88917\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in Chinese training corpus is \" + str(zhen_zh_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10479"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_zh_train.word2index[\"格\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'格'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_zh_train.index2word[10479]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vietnamese Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in Vietnamese training corpus is 16144\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in Vietnamese training corpus is \" + str(vien_vi_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6752"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_vi_train.word2index[\"Hamburger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hamburger'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_vi_train.index2word[6752]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Vocabulary for Zh-En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in English training corpus for Zh-En is 59329\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in English training corpus for Zh-En is \" + str(zhen_en_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_en_train.word2index[\"translate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_en_train.index2word[1451]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Vocabulary for Vi-En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in English training corpus for Vi-En is 47568\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in English training corpus for Vi-En is \" + str(vien_en_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "847"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_en_train.word2index[\"machine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_en_train.index2word[847]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "SOS_IDX = 1\n",
    "UNK_IDX = 2\n",
    "EOS_IDX = 3\n",
    "# convert token to id in the dataset\n",
    "def token2index_dataset(paired_tokens, \n",
    "                        lang1_token2id_vocab,\n",
    "                        lang2_token2id_vocab):\n",
    "    \"\"\"Takes as input:\n",
    "    - paired_tokens: a list of sentence pairs that consist of source & target lang sentences.\n",
    "    - lang1_token2id_vocab: token2index vocabulary for the first language. \n",
    "                            Get by method Lang_dataset.word2index\n",
    "    - lang2_token2id_vocab: token2index vocabulary for the second language. \n",
    "                            Get by method Lang_dataset.word2index\n",
    "                            \n",
    "    Returns:\n",
    "    - indices_data_lang_1, indices_data_lang2: A list of lists where each sub-list holds corresponding indices for each\n",
    "                                               token in the sentence.\"\"\"\n",
    "    indices_data_lang_1, indices_data_lang_2 = [], []\n",
    "    vocabs = [lang1_token2id_vocab, lang2_token2id_vocab]\n",
    "    \n",
    "    # lang1\n",
    "    for t in range(len(paired_tokens)):\n",
    "        index_list = [SOS_IDX] + [vocabs[0][token] if token in vocabs[0]\\\n",
    "                                    else UNK_IDX for token in paired_tokens[t][0]] + [EOS_IDX]\n",
    "        indices_data_lang_1.append(index_list)\n",
    "    # lang2\n",
    "    for t in range(len(paired_tokens)):\n",
    "        index_list = [SOS_IDX] + [vocabs[1][token] if token in vocabs[1] \\\n",
    "                                    else UNK_IDX for token in paired_tokens[t][1]] + [EOS_IDX]\n",
    "        indices_data_lang_2.append(index_list)\n",
    "        \n",
    "    return indices_data_lang_1, indices_data_lang_2\n",
    "\n",
    "# train indices\n",
    "zhen_zh_train_indices, zhen_en_train_indices = token2index_dataset(zh_en_train_pairs,\n",
    "                                                                   zhen_zh_train.word2index,\n",
    "                                                                   zhen_en_train.word2index)\n",
    "\n",
    "vien_vi_train_indices, vien_en_train_indices = token2index_dataset(vi_en_train_pairs,\n",
    "                                                                   vien_vi_train.word2index,\n",
    "                                                                   vien_en_train.word2index)\n",
    "\n",
    "# dev indices\n",
    "zhen_zh_dev_indices, zhen_en_dev_indices = token2index_dataset(zh_en_dev_pairs,\n",
    "                                                               zhen_zh_dev.word2index,\n",
    "                                                               zhen_en_dev.word2index)\n",
    "\n",
    "vien_vi_dev_indices, vien_en_dev_indices = token2index_dataset(vi_en_dev_pairs,\n",
    "                                                               vien_vi_dev.word2index,\n",
    "                                                               vien_en_dev.word2index)\n",
    "\n",
    "# test indices\n",
    "zhen_zh_test_indices, zhen_en_test_indices = token2index_dataset(zh_en_test_pairs,\n",
    "                                                                 zhen_zh_test.word2index,\n",
    "                                                                 zhen_en_test.word2index)\n",
    "\n",
    "vien_vi_test_indices, vien_en_test_indices = token2index_dataset(vi_en_test_pairs,\n",
    "                                                                 vien_vi_test.word2index,\n",
    "                                                                 vien_en_test.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese training set length = 213376\n",
      "Chinese-English (En) training set length = 213376\n",
      "\n",
      "Vietnamese training set length = 133317\n",
      "Vietnamese-English (En) training set length = 133317\n",
      "\n",
      "Chinese dev set length = 1261\n",
      "Chinese-English (En) dev set length = 1261\n",
      "\n",
      "Vietnamese dev set length = 1268\n",
      "Vietnamese-English (En) dev set length = 1268\n",
      "\n",
      "Chinese test set length = 1397\n",
      "Chinese-English (En) test set length = 1397\n",
      "\n",
      "Vietnamese test set length = 1553\n",
      "Vietnamese-English (En) test set length = 1553\n"
     ]
    }
   ],
   "source": [
    "# check length\n",
    "# train\n",
    "print (\"Chinese training set length = \"+str(len(zhen_zh_train_indices)))\n",
    "print (\"Chinese-English (En) training set length = \"+str(len(zhen_en_train_indices)))\n",
    "print (\"\\nVietnamese training set length = \"+str(len(vien_vi_train_indices)))\n",
    "print (\"Vietnamese-English (En) training set length = \"+str(len(vien_en_train_indices)))\n",
    "# dev\n",
    "print (\"\\nChinese dev set length = \"+str(len(zhen_zh_dev_indices)))\n",
    "print (\"Chinese-English (En) dev set length = \"+str(len(zhen_en_dev_indices)))\n",
    "print (\"\\nVietnamese dev set length = \"+str(len(vien_vi_dev_indices)))\n",
    "print (\"Vietnamese-English (En) dev set length = \"+str(len(vien_en_dev_indices)))\n",
    "# test\n",
    "print (\"\\nChinese test set length = \"+str(len(zhen_zh_test_indices)))\n",
    "print (\"Chinese-English (En) test set length = \"+str(len(zhen_en_test_indices)))\n",
    "print (\"\\nVietnamese test set length = \"+str(len(vien_vi_test_indices)))\n",
    "print (\"Vietnamese-English (En) test set length = \"+str(len(vien_en_test_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UNK_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88915"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zhen_zh_train.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "\n",
    "MAX_SENTENCE_LENGTH = 300\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# zhen token2index vocabs\n",
    "zhen_zh_train_token2id = zhen_zh_train.word2index\n",
    "zhen_en_train_token2id = zhen_en_train.word2index\n",
    "\n",
    "# vien token2index vocabs\n",
    "vien_vi_train_token2id = vien_vi_train.word2index\n",
    "vien_en_train_token2id = vien_en_train.word2index\n",
    "\n",
    "class TranslationDataset():\n",
    "    \"\"\"\n",
    "    Class that represents a train/dev/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 data_source, # training indices data of the source language\n",
    "                 data_target, # training indices data of the target language\n",
    "                 token2id_source=None, # token2id dict of the source language\n",
    "                 token2id_target=None  # token2id dict of the target language\n",
    "                ):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.source_sentences, self.target_sentences =  data_source, data_target\n",
    "        \n",
    "        self.token2id_source = token2id_source\n",
    "        self.token2id_target = token2id_target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "\n",
    "#         source_word_idx, target_word_idx = [], []\n",
    "        source_mask, target_mask = [], []\n",
    "        \n",
    "        for index in self.source_sentences[batch_index][:MAX_SENTENCE_LENGTH]:\n",
    "            if index != UNK_IDX:\n",
    "                source_mask.append(0)\n",
    "            else:\n",
    "                source_mask.append(1)\n",
    "                \n",
    "        for index in self.target_sentences[batch_index][:MAX_SENTENCE_LENGTH]:\n",
    "            if index != UNK_IDX:\n",
    "                target_mask.append(0)\n",
    "            else:\n",
    "                target_mask.append(1)\n",
    "        \n",
    "        source_indices = self.source_sentences[batch_index][:MAX_SENTENCE_LENGTH]\n",
    "        target_indices = self.target_sentences[batch_index][:MAX_SENTENCE_LENGTH]\n",
    "        \n",
    "        source_list = [source_indices, source_mask, len(source_indices)]\n",
    "        target_list = [target_indices, target_mask, len(target_indices)]\n",
    "        \n",
    "        return source_list + target_list\n",
    "\n",
    "    \n",
    "def translation_collate(batch, max_sentence_length):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    source_data, target_data = [], []\n",
    "    source_mask, target_mask = [], []\n",
    "    source_lengths, target_lengths = [], []\n",
    "\n",
    "    for datum in batch:\n",
    "        source_lengths.append(datum[2])\n",
    "        target_lengths.append(datum[5])\n",
    "        \n",
    "        # PAD\n",
    "        source_data_padded = np.pad(np.array(datum[0]), pad_width=((0, MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        source_data.append(source_data_padded)\n",
    "        \n",
    "        source_mask_padded = np.pad(np.array(datum[1]), pad_width=((0, MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        source_mask.append(source_mask_padded)\n",
    "        \n",
    "        target_data_padded = np.pad(np.array(datum[3]), pad_width=((0, MAX_SENTENCE_LENGTH-datum[5])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        target_data.append(target_data_padded)\n",
    "        \n",
    "        target_mask_padded = np.pad(np.array(datum[4]), pad_width=((0, MAX_SENTENCE_LENGTH-datum[5])),\n",
    "                               mode=\"constant\", constant_values=0)\n",
    "        target_mask.append(target_mask_padded)\n",
    "        \n",
    "    ind_dec_order = np.argsort(source_lengths)[::-1]\n",
    "    source_data = np.array(source_data)[ind_dec_order]\n",
    "    target_data = np.array(target_data)[ind_dec_order]\n",
    "    source_mask = np.array(source_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    target_mask = np.array(target_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    source_lengths = np.array(source_lengths)[ind_dec_order]\n",
    "    target_lengths = np.array(target_lengths)[ind_dec_order]\n",
    "    \n",
    "    source_list = [torch.from_numpy(source_data), \n",
    "               torch.from_numpy(source_mask).float(), source_lengths]\n",
    "    target_list = [torch.from_numpy(target_data), \n",
    "               torch.from_numpy(target_mask).float(), target_lengths]\n",
    "        \n",
    "    return source_list + target_list\n",
    "\n",
    "\n",
    "zhen_train_dataset = TranslationDataset(zhen_zh_train_indices,\n",
    "                                       zhen_en_train_indices,\n",
    "                                       token2id_source=zhen_zh_train_token2id,\n",
    "                                       token2id_target=zhen_en_train_token2id)\n",
    "\n",
    "zhen_train_loader = torch.utils.data.DataLoader(dataset=zhen_train_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                               shuffle=False)\n",
    "\n",
    "zhen_dev_dataset = TranslationDataset(zhen_zh_dev_indices,\n",
    "                                       zhen_en_dev_indices,\n",
    "                                       token2id_source=zhen_zh_train_token2id,\n",
    "                                       token2id_target=zhen_en_train_token2id)\n",
    "\n",
    "zhen_dev_loader = torch.utils.data.DataLoader(dataset=zhen_dev_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                             shuffle=False)\n",
    "\n",
    "vien_train_dataset = TranslationDataset(vien_vi_train_indices,\n",
    "                                       vien_en_train_indices,\n",
    "                                       token2id_source=vien_vi_train_token2id,\n",
    "                                       token2id_target=vien_en_train_token2id)\n",
    "\n",
    "vien_train_loader = torch.utils.data.DataLoader(dataset=vien_train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                             shuffle=False)\n",
    "\n",
    "vien_dev_dataset = TranslationDataset(vien_vi_dev_indices,\n",
    "                                       vien_en_dev_indices,\n",
    "                                       token2id_source=vien_vi_train_token2id,\n",
    "                                       token2id_target=vien_en_train_token2id)\n",
    "\n",
    "vien_dev_loader = torch.utils.data.DataLoader(dataset=vien_dev_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                             shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1,  2, 83,  ...,  0,  0,  0],\n",
       "         [ 1, 38,  2,  ...,  0,  0,  0],\n",
       "         [ 1,  2, 83,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [ 1,  2, 83,  ...,  0,  0,  0],\n",
       "         [ 1,  2,  2,  ...,  0,  0,  0],\n",
       "         [ 1,  2, 83,  ...,  0,  0,  0]]), tensor([[[0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [1.],\n",
       "          [0.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]), array([283, 204, 204, 182, 178, 160, 150, 145, 139, 138, 136, 117, 115,\n",
       "        107, 106, 105, 100,  99,  87,  85,  82,  81,  79,  76,  74,  70,\n",
       "         68,  64,  43,  35,  32,  16]), tensor([[  1,   3,   2,  ...,   0,   0,   0],\n",
       "         [  1,   3,   2,  ...,   0,   0,   0],\n",
       "         [  1,   3,   2,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  1, 142,   2,  ...,   0,   0,   0],\n",
       "         [  1, 990,   2,  ...,   0,   0,   0],\n",
       "         [  1,   3,   2,  ...,   0,   0,   0]]), tensor([[[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]],\n",
       " \n",
       "         [[0.],\n",
       "          [0.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [0.],\n",
       "          [0.],\n",
       "          [0.]]]), array([234, 176, 176, 141, 178, 141, 110, 130, 137, 132, 124, 129, 118,\n",
       "        132, 106,  82,  77,  91, 103,  65,  73,  94,  76,  60,  68,  80,\n",
       "         46,  59,  55,  24,  16,  20])]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*vien_dev_loader][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Evaluation Metric\n",
    "\n",
    "We use BLEU as the evaluation metric. Specifically, we focus on the corpus-level BLEU function. \n",
    "\n",
    "The code for BLEU is taken from https://github.com/mjpost/sacreBLEU/blob/master/sacrebleu.py#L1022-L1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Users/derin/anaconda/lib/python3.6/site-packages (1.2.12)\n",
      "Requirement already satisfied: typing in /Users/derin/anaconda/lib/python3.6/site-packages (from sacrebleu) (3.6.6)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sacrebleu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-a42160e8fb94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msacrebleu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sacrebleu'"
     ]
    }
   ],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Beam Search Algorithm\n",
    "\n",
    "In this section, we implement the Beam Search algorithm in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize k-many score lists\n",
    "# start only with the whole x\n",
    "# initialize k-many prev y's lists\n",
    "# choose top-k for y1 from the whole vocab\n",
    "# choose top-k for the second time step by expanding the first time step\n",
    "# compute scores by adding log probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-250-fada104b1e20>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-250-fada104b1e20>\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    def score(prev_ys = None):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "beam_size_k = 10\n",
    "\n",
    "class BeamSearch:\n",
    "    \n",
    "    \"\"\"RECURSE\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 beam_size=beam_size_k, ## insert num \n",
    "                 softmax_out\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Class that holds beam information, and search & score functions\n",
    "        - beam_size = beam size\n",
    "        - softmax_out = the softmax over the vocabulary at time step t, as computed by the RNN decoder,\n",
    "                        given the source sequence X and the previously decoded y_<t tokens.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.beam_size = beam_size\n",
    "        self.softmax_out = softmax_out\n",
    "        \n",
    "        # initialize paths\n",
    "        self.paths = np.empty((self.beam_size))\n",
    "        \n",
    "        # initialize the dictionary that will hold the path scores \n",
    "        # and update the scores at each time step\n",
    "        self.path_score_dict = {}\n",
    "        # we will later use each i < k as a key and populate this\n",
    "        # dict with scores\n",
    "\n",
    "        \n",
    "    def search():\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def score(prev_ys = None):\n",
    "        \"\"\"- prev_ys = previously decoded tokens (previously generated target language tokens)\n",
    "        \"\"\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model\n",
    "\n",
    "1. Recurrent neural network based encoder-decoder without attention\n",
    "2. Recurrent neural network based encoder-decoder with attention\n",
    "2. Replace the recurrent encoder with either convolutional or self-attention based encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'L'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-251-44c2d177c939>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'L'"
     ]
    }
   ],
   "source": [
    "torch.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction loss = binary cross entropy between two (vocab_size x 1) vectors\n",
    "# used during training, since we can compare the real Y and and the generated Y\n",
    "# still at each time step of the decoder, we compare up to and including\n",
    "# the real t-th token and the generated t-th, then optimize\n",
    "\n",
    "def loss_function(y_hat, y):\n",
    "    \n",
    "    \"\"\"Takes as input;\n",
    "    - y: correct \"log-softmax\"(binary vector) that represents the correct t-th token in the target sentence,\n",
    "                 (vocab_size x 1) vector\n",
    "    - y_hat: predicted LogSoftmax for the predicted t-th token in the target sentence.\n",
    "             (vocab_size x 1) vector\n",
    "    Returns;\n",
    "    - NLL Loss in training time\"\"\"\n",
    "    y_hat = torch.log(y_hat)\n",
    "    loss = nn.functional.binary_cross_entropy(y_hat,y)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "# generation/inference time - validation loss = BLEU\n",
    "\n",
    "def compute_BLEU(corpus_hat,corpus):\n",
    "    ## TODO\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-490-9eef64826b7c>, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-490-9eef64826b7c>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    if self.time_step = 0:\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "MAX_PATH_LENGTH = 400 # make changeable later !!!\n",
    "\n",
    "class TargetOut:\n",
    "    def __init__(self,\n",
    "                 beam_size=5,\n",
    "                 source_sentence_length=400,\n",
    "                 time_step=0):\n",
    "        \"\"\"\n",
    "        - beam: the tensor that will be populated with beam_size-many paths in each timestep\n",
    "        - beam_size: the width of the beam, top k tokens to include in the beam search,\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialized again for each timestep\n",
    "        self.beam = torch.empty(beam_size)\n",
    "        self.beam_size = beam_size\n",
    "        self.beam_seq = beam_seq\n",
    "        self.time_step = time_step\n",
    "        \n",
    "        self.max_target_length = source_sentence_length*(1.5)\n",
    "        # path is kept by hold_path\n",
    "        self.path = torch.empty(beam_size, max_target_length)\n",
    "    \n",
    "    def _add_and_score_paths(self, \n",
    "             top_k_tokens):\n",
    "        \n",
    "        \"\"\"top_k_tokens: torch.FloatTensor of indices according to logSoftmax \n",
    "        (not embeddings - embedding matrix indices or vocab indices)\"\"\"\n",
    "        \n",
    "        time_step = self.time_step\n",
    "        self.path[:,time_step] = top_k_tokens\n",
    "        \n",
    "        return self\n",
    "            \n",
    "    def _score_paths(self,gru_out):\n",
    "        \n",
    "        \"\"\"For each path, computes log(P(Y_i|Y_i-1,..,Y_i-n,X)) + log(P(Y_i-1|Y_i-2,..,Y_i-n,X)) + ...\n",
    "        -gru_out is a softmax over the vocabulary for each timestep, so \n",
    "        we need to take its log to obtain the scores\"\"\"\n",
    "        if self.time_step = 0:\n",
    "            \n",
    "        \n",
    "    \n",
    "    def _hold_path_score(self):\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: RNN-based Encoder-Decoder without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.]])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.FloatTensor([2]).view(-1,1),torch.FloatTensor([3]).view(-1,1)],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN-based encoder-decoder without attention\n",
    "\n",
    "class RNNencoder(nn.Module):\n",
    "    \n",
    "    \"\"\"Takes as input the variable-length input sequence X, \n",
    "    maps it to a fixed-length (final hidden) vector.\n",
    "    \n",
    "    We normalize (divide by the length) the final hidden vector.\n",
    "    BUT, we don't do the same thing for prev_ys\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size=len(zhen_zh_train_token2id), # for chinese\n",
    "                 embedding_size=300,\n",
    "                 percent_dropout=0.3, \n",
    "                 hidden_size=256,\n",
    "                 num_gru_layers=1):\n",
    "        \n",
    "        super(RNNencoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embedding_size\n",
    "        self.dropout = percent_dropout\n",
    "        self.embed_source = nn.Embedding(self.vocab_size,\n",
    "                                         self.embed_size,\n",
    "                                         padding_idx=0\n",
    "                                        )\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_gru_layers\n",
    "        \n",
    "        self.GRU = nn.GRU(self.embed_size, \n",
    "                          self.hidden_size, \n",
    "                          self.num_layers, \n",
    "                          batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.drop_out_function = nn.Dropout(self.dropout)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(2*self.num_layers, ## 2 for bidirectional\n",
    "                             batch_size, self.hidden_size).to(device)\n",
    "        return hidden\n",
    "    \n",
    "    def forward(self, \n",
    "                source_sentence, \n",
    "                source_mask, \n",
    "                source_lengths):\n",
    "        \n",
    "        \"\"\"Returns source lengths to feed into the decoder, since we do not want\n",
    "        the translation length to be above/below a certain treshold*source sentence length.\"\"\"\n",
    "        \n",
    "        sort_original_source = sorted(range(len(source_lengths)), \n",
    "                             key=lambda sentence: -source_lengths[sentence])\n",
    "        unsort_to_original_source = sorted(range(len(source_lengths)), \n",
    "                             key=lambda sentence: sort_original_source[sentence])\n",
    "        \n",
    "        source_sentence = source_sentence[sort_original_source]\n",
    "        _source_mask = source_mask[sort_original_source]\n",
    "        source_lengths = source_lengths[sort_original_source]\n",
    "        batch_size, seq_len_source = source_sentence.size()\n",
    "        # init hidden\n",
    "        self.hidden_source = self.init_hidden(batch_size)\n",
    "#         print (\"self.hidden_source shape = \"+str(self.hidden_source.size()))\n",
    "        # embeddings for source language\n",
    "        # carry the commented lines to the decoder\n",
    "        print (\"source sentence shape = \"+str(source_sentence.size()))\n",
    "#         print (\"Source Sentence 0 = \"+str(source_sentence[0]))\n",
    "        embeds_source = self.embed_source(source_sentence)\n",
    "        print (\"embeds source size = \"+str(embeds_source.size()))\n",
    "        embeds_source = source_mask*embeds_source + (1-_source_mask)*embeds_source.clone().detach()\n",
    "        \n",
    "        embeds_source = torch.nn.utils.rnn.pack_padded_sequence(embeds_source, \n",
    "                                                                source_lengths, \n",
    "                                                                batch_first=True)\n",
    "        \n",
    "        gru_out_source, self.hidden_source = self.GRU(embeds_source, self.hidden_source)\n",
    "        \n",
    "        # undo packing\n",
    "        gru_out_source, _ = torch.nn.utils.rnn.pad_packed_sequence(gru_out_source,\n",
    "                                                                   batch_first=True)\n",
    "        \n",
    "        gru_out_source = gru_out_source.view(batch_size, -1, 2, self.hidden_size)\n",
    "        gru_out_source = torch.mean(gru_out_source, dim=1) ## mean instead of sum for source representation as suggested in the class\n",
    "        gru_out_source = torch.cat([gru_out_source[:,i,:] for i in range(2)], dim=1)\n",
    "        gru_out_source = gru_out_source[unsort_to_original_source] ## back to original indices\n",
    "        \n",
    "        # normalizing the hidden vectors in the batch by their own length\n",
    "        source_lengths = source_lengths[unsort_to_original_source]\n",
    "#         print (\"gru_out_source size = \"+str(gru_out_source.size()))\n",
    "#         print (\"gru_out_source = \"+str(gru_out_source))\n",
    "#         print (\"source_lengths size = \"+str(torch.LongTensor(source_lengths).size()))\n",
    "#         print (\"source_lengths = \"+str(source_lengths))\n",
    "        \n",
    "        source_lengths_to_norm = torch.transpose(torch.mul(torch.ones(self.hidden_size*2, batch_size),\n",
    "                                           torch.FloatTensor(source_lengths)),0,1)\n",
    "        \n",
    "#         print (\"source_lengths_to_norm = \"+str(source_lengths_to_norm))\n",
    "        \n",
    "        gru_out_source = torch.div(gru_out_source, source_lengths_to_norm)\n",
    "#         print (\"gru_out_source size = \"+str(gru_out_source.size()))\n",
    "        return gru_out_source, source_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNdecoder(nn.Module):\n",
    "    \n",
    "    \"\"\"Given the source sentence and the previously decoded target\n",
    "    tokens, if any, outputs the softmax over vocabulary for the next token's\n",
    "    representation. \n",
    "    \n",
    "    We input this softmax to the beam search to get the\n",
    "    beam_size-many tokens that have the highest probability among all the\n",
    "    tokens in the vocabulary.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 vocab_size=len(zhen_en_train_token2id), # for chinese-english's english\n",
    "                 embedding_size=300,\n",
    "                 percent_dropout=0.3, \n",
    "                 hidden_size=256,\n",
    "                 num_gru_layers=1\n",
    "                 ):\n",
    "        \n",
    "        super(RNNdecoder, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embedding_size\n",
    "        self.dropout = percent_dropout\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_gru_layers\n",
    "        \n",
    "        self.GRU = nn.GRU(self.embed_size, \n",
    "                          self.hidden_size, \n",
    "                          self.num_layers, \n",
    "                          batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.drop_out_function = nn.Dropout(self.dropout)\n",
    "        \n",
    "        self.embed_target = nn.Embedding(self.vocab_size,\n",
    "                                         self.embed_size, padding_idx=0)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # the prev_ys tensor at time step 0, \n",
    "        # before we have generated any y_s\n",
    "        self.prev_ys = torch.empty(0)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(2*self.num_layers, ## 2 for bidirectional\n",
    "                             batch_size, self.hidden_size).to(device)\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self,\n",
    "                hidden_source, ## gru_out_source from the encoder\n",
    "                target_sentence_upto_t, # target sentence tokens generated up to time t\n",
    "                source_lengths):\n",
    "        \n",
    "        # input hidden_source\n",
    "        self.hidden_source = hidden_source\n",
    "        \n",
    "        if target_sentence_upto_t.size(0) == 0:\n",
    "            gru_out_target = torch.empty(0)\n",
    "            \n",
    "        else:\n",
    "            # init hidden\n",
    "            self.hidden_target = self.init_hidden(batch_size)\n",
    "            embeds_target = self.embed_target(target_sentence_upto_t)\n",
    "            print (\"embeds_target = \"+str(embeds_target))\n",
    "            print (\"embeds_target size = \"+str(embeds_target.size()))\n",
    "            gru_out_target, self.hidden_target = self.GRU(embeds_target, self.hidden_target)\n",
    "\n",
    "            # undo packing\n",
    "            gru_out_target, _ = torch.nn.utils.rnn.pad_packed_sequence(gru_out_target,\n",
    "                                                                       batch_first=True)\n",
    "\n",
    "            gru_out_target = gru_out_target.view(batch_size, -1, 2, self.hidden_size)\n",
    "            gru_out_target = torch.sum(gru_out_target, dim=1) # we don't divide here, just sum\n",
    "            gru_out_target = torch.cat([gru_out_target[:,i,:] for i in range(2)], dim=1)\n",
    "            gru_out_target = gru_out_target[unsort_to_original_target] ## back to original indices\n",
    "\n",
    "            gru_out_target = self.sigmoid(gru_out_target)\n",
    "        \n",
    "        # moved linear layers to here, otherwise it will be too crowded\n",
    "        # concatenate hidden and prev source representations\n",
    "#         print (\"gru out target = \"+str(gru_out_target))\n",
    "#         print (\"hidden source = \"+str(self.hidden_source))\n",
    "        hidden = torch.cat([self.hidden_source, gru_out_target], dim=1)\n",
    "#         print (\"hidden = \"+str(hidden))\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([])"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation and linearity\n",
    "class Linear_Layers(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_size=512,\n",
    "                 hidden_size=1028,\n",
    "                 percent_dropout_linear=0.3,\n",
    "                 vocab_size=len(zhen_en_train_token2id) # for chinese-english's english\n",
    "                ):\n",
    "        \n",
    "        super(Linear_Layers, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = percent_dropout_linear\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.drop_out = nn.Dropout(self.dropout)\n",
    "        self.log_softmax = nn.LogSoftmax()\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_normal_(module.weight)\n",
    "                nn.init.uniform_(module.bias)\n",
    "\n",
    "    def forward(self, \n",
    "                gru_out, # comes concatenated (source + target upto t)\n",
    "               ):\n",
    "        \n",
    "        gru_out = gru_out.view(gru_out.size(0),-1) \n",
    "        print (\"gru out size = \"+str(gru_out.size()))\n",
    "        gru_out = self.fc1(gru_out)\n",
    "        gru_out = self.drop_out(self.ReLU(gru_out))\n",
    "        out = self.fc2(gru_out)\n",
    "        \n",
    "        ## log-softmax over vocabulary\n",
    "        out = self.log_softmax(out)\n",
    "#         print (\"out from generator = \"+str(out))\n",
    "        print (\"generator out shape = \"+str(out.size()))\n",
    "        # not getting the max inside the function to get the vocabulary index \n",
    "        # since for the beam search we will need to get the top k indices \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.FloatTensor([[2,3,4], [4,5,6]])\n",
    "A[:,0] = torch.FloatTensor([3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(torch.max(torch.FloatTensor([2,3,4]),0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(10)[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 4.],\n",
       "        [3., 5., 6.]])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNNenc = # encoder model\n",
    "# RNNdec = # decoder model\n",
    "# Generator = # concat and softmax over vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(RNNenc=RNNencoder,\n",
    "          RNNdec=RNNdecoder,\n",
    "          generator=Linear_Layers, # Linear_Layers to generate next 1 token\n",
    "          loader=zhen_train_loader, # automate\n",
    "          optimizer=None, \n",
    "          epoch=None):\n",
    "    \n",
    "    RNNenc.train()\n",
    "    RNNdec.train()\n",
    "    generator.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (source_sentence, source_mask, source_lengths, \n",
    "                    target_sentence, target_mask, target_lengths)\\\n",
    "    in enumerate(DataLoader):\n",
    "            \n",
    "        source_sentence, source_mask = source_sentence.to(device), source_mask.to(device),  \n",
    "        target_sentence, target_mask = target_sentence.to(device), target_mask.to(device),\n",
    "        \n",
    "        RNNenc.train()\n",
    "        RNNdec.train()\n",
    "        generator.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        generated_target = torch.empty(0)\n",
    "        \n",
    "        for t in range(target_sentence.size(1)):\n",
    "            target_sentence_upto_t = target_sentence[:,t]\n",
    "            encoded_source = RNNenc(source_sentence,\n",
    "                                    source_mask,\n",
    "                                    source_lengths)\n",
    "        \n",
    "            encoded_source_concat_target = RNNdec(encoded_source[0], # gru_out_source\n",
    "                                                  target_sentence_upto_t, # take care of this\n",
    "                                                  encoded_source[1]  # source lengths\n",
    "                                                 )\n",
    "        \n",
    "            out = generator(encoded_source_concat_target) # returns softmax\n",
    "            \n",
    "            print (\"out from generator size = \"+str(out.size()))\n",
    "            print (\"target sentence size = \"+str(target_sentence.size()))\n",
    "            \n",
    "            generated_target = torch.cat([generated_target, out], dim=1)\n",
    "            target_token_softmax = torch.eye(59327)[int(torch.max(out,0)[0])]\n",
    "            loss = loss_function(out[t], target_sentence[:,t])\n",
    "            print (\"Loss = \"+str(loss))\n",
    "            loss.cuda().backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * len(sentence1) / len(DataLoader.dataset)\n",
    "        \n",
    "        if (batch_idx+1) % (len(DataLoader.dataset)//(20*labels.shape[0])) == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, (batch_idx+1) * labels.shape[0], len(DataLoader.dataset),\n",
    "                100. * (batch_idx+1) / len(DataLoader), loss.item()))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "# def test(RNN, \n",
    "#          Linear_Classifier, \n",
    "#          DataLoader, \n",
    "#          criterion):\n",
    "\n",
    "#     RNN.eval()\n",
    "#     Linear_Classifier.eval()\n",
    "    \n",
    "#     test_loss = 0\n",
    "#     label_list = []\n",
    "#     output_list = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (sentence1, s1_original, sentence1_lengths, \n",
    "#                     sentence2, s2_original, sentence2_lengths, labels)\\\n",
    "#                     in enumerate(DataLoader):\n",
    "\n",
    "#             sentence1, s1_original = sentence1.to(device), s1_original.to(device),  \n",
    "#             sentence2, s2_original = sentence2.to(device), s2_original.to(device),\n",
    "#             labels = labels.to(device)\n",
    "            \n",
    "#             # Forward\n",
    "#             output_s1 = RNN(sentence1, \n",
    "#                                   s1_original, \n",
    "#                                   sentence1_lengths)\n",
    "#             # Reverse\n",
    "#             output_s2 = RNN(sentence2, \n",
    "#                                   s2_original, \n",
    "#                                   sentence2_lengths)\n",
    "            \n",
    "#             out = Linear_Classifier(output_s1, output_s2)\n",
    "        \n",
    "#             loss = criterion(out, labels)\n",
    "\n",
    "#             test_loss += loss.item()/len(DataLoader.dataset)\n",
    "\n",
    "#             output_list.append(out)\n",
    "#             label_list.append(labels)\n",
    "            \n",
    "#             print (\"outputs= \"+str(torch.cat(output_list, dim=0)))\n",
    "#             print (\"labels= \"+str(torch.cat(label_list, dim=0)))\n",
    "            \n",
    "#     return test_loss, torch.cat(output_list, dim=0), torch.cat(label_list, dim=0)\n",
    "\n",
    "# def accuracy(RNN, \n",
    "#              Linear_Classifier, \n",
    "#              DataLoader, \n",
    "#              criterion):\n",
    "    \n",
    "#     _, predicted, true_labels = test(RNN = RNN,\n",
    "#                               Linear_Classifier = Linear_Classifier,\n",
    "#                               DataLoader = DataLoader,\n",
    "#                               criterion = criterion)\n",
    "\n",
    "#     predicted = predicted.max(1)[1]\n",
    "#     return 100 * predicted.eq(true_labels.data.view_as(predicted)).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "source sentence shape = torch.Size([32, 300])\n",
      "embeds source size = torch.Size([32, 300, 300])\n",
      "embeds_target = tensor([[-0.5268, -0.8680,  0.5817,  ..., -1.9101, -0.8338, -1.1607],\n",
      "        [-0.5268, -0.8680,  0.5817,  ..., -1.9101, -0.8338, -1.1607],\n",
      "        [-0.5268, -0.8680,  0.5817,  ..., -1.9101, -0.8338, -1.1607],\n",
      "        ...,\n",
      "        [-0.5268, -0.8680,  0.5817,  ..., -1.9101, -0.8338, -1.1607],\n",
      "        [-0.5268, -0.8680,  0.5817,  ..., -1.9101, -0.8338, -1.1607],\n",
      "        [-0.5268, -0.8680,  0.5817,  ..., -1.9101, -0.8338, -1.1607]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "embeds_target size = torch.Size([32, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-570-14df36270439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                    \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                                                    lr=lr),\n\u001b[0;32m---> 23\u001b[0;31m                       epoch = epoch)\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-569-de953c28f6bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(RNNenc, RNNdec, generator, loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     33\u001b[0m             encoded_source_concat_target = RNNdec(encoded_source[0], # gru_out_source\n\u001b[1;32m     34\u001b[0m                                                   \u001b[0mtarget_sentence_upto_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# take care of this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                                                   \u001b[0mencoded_source\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# source lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                                                  )\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-561-a18db0cd4de8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_source, target_sentence_upto_t, source_lengths)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"embeds_target = \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"embeds_target size = \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mgru_out_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# undo packing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mflat_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         func = self._backend.RNN(\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    124\u001b[0m             raise RuntimeError(\n\u001b[1;32m    125\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[0;32m--> 126\u001b[0;31m                     expected_input_dim, input.dim()))\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             raise RuntimeError(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 2"
     ]
    }
   ],
   "source": [
    "RNNencoder_model = RNNencoder() # encoder model\n",
    "RNNdecoder_model = RNNdecoder() # decoder model and concatenation\n",
    "generator_model = Linear_Layers() # logsoftmax over vocab\n",
    "DataLoader = zhen_train_loader\n",
    "\n",
    "num_epochs = 3\n",
    "lr = 1e-4\n",
    "# batch_\n",
    "\n",
    "loss_train = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print (\"epoch = \"+str(epoch))\n",
    "\n",
    "    loss = train(RNNencoder_model,\n",
    "                 RNNdecoder_model,\n",
    "                 generator_model,\n",
    "                       loader = DataLoader,\n",
    "                       optimizer = torch.optim.Adam(list(RNNencoder_model.parameters()) + \\\n",
    "                                                    list(RNNdecoder_model.parameters()) + \\\n",
    "                                                   list(generator_model.parameters()), \n",
    "                                                   lr=lr),\n",
    "                      epoch = epoch)\n",
    "    \n",
    "    loss_train.append(loss)\n",
    "    \n",
    "    print (loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RNN-based Encoder-Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Encoder Replacement with Eonvolutional or Self-attention-based Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Fully self-attention Translation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Multilingual Translation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
