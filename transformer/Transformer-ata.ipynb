{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Spring 2018 NLP Class Project: Neural Machine Translation</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atakanokan/anaconda/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator MultiLabelBinarizer from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/atakanokan/anaconda/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/atakanokan/anaconda/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator SVC from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/atakanokan/anaconda/lib/python3.6/site-packages/sklearn/base.py:311: UserWarning: Trying to unpickle estimator OneVsRestClassifier from version 0.19.0 when using version 0.19.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import pdb\n",
    "import os\n",
    "from underthesea import word_tokenize\n",
    "import jieba\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# running on cpu\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ! pip install spacy && python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Project Overview\n",
    "\n",
    "The goal of this project is to build a neural machine translation system and experience how recent advances have made their way. Each team will build the following sequence of neural translation systems for two language pairs, __Vietnamese (Vi)→English (En)__ and __Chinese (Zh)→En__ (prepared corpora is be provided):\n",
    "\n",
    "1. Recurrent neural network based encoder-decoder without attention\n",
    "2. Recurrent neural network based encoder-decoder with attention\n",
    "2. Replace the recurrent encoder with either convolutional or self-attention based encoder.\n",
    "4. [Optional] Build either or both fully self-attention translation system or/and multilingual translation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Upload & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1 # start of sentence\n",
    "UNK_token = 2 # 2 = unk\n",
    "EOS_token = 3 # end of sentence\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}    # dictionary of words and their \n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token:\"<PAD>\",\n",
    "                           SOS_token: \"<SOS>\",\n",
    "                           UNK_token:\"<UNK>\", \n",
    "                           EOS_token: \"<EOS>\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        # adds the new word to the vocabulary\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    \"\"\"About \"NFC\" and \"NFD\": \n",
    "    \n",
    "    For each character, there are two normal forms: normal form C \n",
    "    and normal form D. Normal form D (NFD) is also known as canonical \n",
    "    decomposition, and translates each character into its decomposed form. \n",
    "    Normal form C (NFC) first applies a canonical decomposition, then composes \n",
    "    pre-combined characters again.\n",
    "    \n",
    "    About unicodedata.category: \n",
    "    \n",
    "    Returns the general category assigned to the Unicode character \n",
    "    unichr as string.\"\"\"\n",
    "    \n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trim\n",
    "def normalizeString(s):\n",
    "    # removes blankspaces at the beginning and the end of the string\n",
    "    s = unicodeToAscii(s.strip())\n",
    "    # \n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # \n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False,\n",
    "             dataset=\"train\"):\n",
    "    \n",
    "    \"\"\"Takes as input;\n",
    "    - lang1, lang2: either (vi, en) or (zh, en)\n",
    "    - dataset: one of (\"train\",\"dev\",\"test\")\"\"\"\n",
    "    \n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    eos = [\".\",\"?\",\"!\",\"\\n\"]\n",
    "    \n",
    "    # Read the pretokenized lang1 file and split into lines\n",
    "    lang1_lines = open(\"../data/tokens_and_preprocessing_em/pretokenized_data/iwslt-%s-%s-processed/%s.tok.%s\" % (lang1, lang2, dataset, lang1), encoding=\"utf-8\").\\\n",
    "        read().strip().split(\"\\n\")\n",
    "        \n",
    "    # Read the lang2 file and split into lines\n",
    "    lang2_lines = open(\"../data/tokens_and_preprocessing_em/pretokenized_data/iwslt-%s-%s-processed/%s.tok.%s\" % (lang1, lang2, dataset, lang2), encoding=\"utf-8\").\\\n",
    "        read().strip().split(\"\\n\")\n",
    "        \n",
    "    # Examples of Pretokenized Sentences\n",
    "    print(\"Example of Language #1 sentence: \" + str(lang1_lines[0]))\n",
    "    print(\"Example of Language #2 sentence: \" + str(lang2_lines[0]))\n",
    "    \n",
    "    # create sentence pairs (lists of length 2 that consist of string pairs)\n",
    "    # e.g. [\"And we &apos;re going to tell you some stories from the sea here in video .\",\n",
    "    #       \"我们 将 用 一些 影片 来讲 讲述 一些 深海 海里 的 故事  \"]\n",
    "    # check if there are the same number of sentences in each set\n",
    "    assert len(lang1_lines) == len(lang2_lines), \"Two languages must have the same number of sentences. \"+ str(len(lang1_lines)) + \" sentences were passed for \" + str(lang1) + \".\" + str(len(lang2_lines)) + \" sentences were passed for \" + str(lang2)+\".\"\n",
    "    print(\"Number of sentences in Language #1 = \" + str(len(lang1_lines)))\n",
    "    print(\"Number of sentences in Language #2 = \" + str(len(lang2_lines)))\n",
    "    \n",
    "    # normalize if not Chinese, Chinese normalization is already handeled\n",
    "    # add <EOS> tag at the end of the sentence for chinese\n",
    "    if lang1 == \"zh\":\n",
    "        lang1_lines = [s + \"<EOS>\" for s in lang1_lines]\n",
    "    else:\n",
    "        # replace .?!\\n with <EOS> tag for Vietnamese and English\n",
    "        lang1_lines = [normalizeString(s).replace(\".\",\"<EOS>\").\\\n",
    "                       replace(\"?\",\"<EOS>\").replace(\"!\",\"<EOS>\").replace(\"\\n\",\"<EOS>\") for s in lang1_lines]\n",
    "    lang2_lines = [normalizeString(s).replace(\".\",\"<EOS>\").\\\n",
    "                       replace(\"?\",\"<EOS>\").replace(\"!\",\"<EOS>\").replace(\"\\n\",\"<EOS>\") for s in lang2_lines]\n",
    "    \n",
    "    # construct pairs\n",
    "    pair_ran = range(len(lang1_lines))\n",
    "    pairs = [[lang1_lines[i]] + [lang2_lines[i]] for i in pair_ran]\n",
    "    \n",
    "#     # Split every line into pairs and normalize\n",
    "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False, dataset=\"train\"):\n",
    "    \n",
    "    input_lang, output_lang, pairs = readLangs(lang1 = lang1, \n",
    "                                               lang2 = lang2, \n",
    "                                               reverse = reverse, \n",
    "                                               dataset = dataset)\n",
    "    \n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Example of Language #1 sentence: Khoa_học đằng_sau một tiêu_đề về khí_hậu\n",
      "Example of Language #2 sentence: Rachel Pike : The science behind a climate headline\n",
      "Number of sentences in Language #1 = 133317\n",
      "Number of sentences in Language #2 = 133317\n",
      "Read 133317 sentence pairs\n",
      "Trimmed to 133317 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 16142\n",
      "en 47566\n",
      "['Xem toi lam ay nhe <EOS>', 'So let me see if this will work <EOS>']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(lang1 = 'vi', \n",
    "                                             lang2 = 'en', \n",
    "                                             reverse = False, \n",
    "                                             dataset = \"train\")\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Khoa': 2,\n",
       " 'hoc': 3,\n",
       " 'ang': 4,\n",
       " 'sau': 5,\n",
       " 'mot': 6,\n",
       " 'tieu': 7,\n",
       " 'e': 8,\n",
       " 've': 9,\n",
       " 'khi': 10,\n",
       " 'hau': 11,\n",
       " 'Trong': 12,\n",
       " 'phut': 13,\n",
       " 'chuyen': 14,\n",
       " 'gia': 15,\n",
       " 'hoa': 16,\n",
       " 'quyen': 17,\n",
       " 'Rachel': 18,\n",
       " 'Pike': 19,\n",
       " 'gioi': 20,\n",
       " 'thieu': 21,\n",
       " 'so': 22,\n",
       " 'luoc': 23,\n",
       " 'nhung': 24,\n",
       " 'no': 25,\n",
       " 'luc': 26,\n",
       " 'khoa': 27,\n",
       " 'miet': 28,\n",
       " 'mai': 29,\n",
       " 'tao': 30,\n",
       " 'bao': 31,\n",
       " 'bien': 32,\n",
       " 'oi': 33,\n",
       " 'cung': 34,\n",
       " 'voi': 35,\n",
       " 'oan': 36,\n",
       " 'nghien': 37,\n",
       " 'cuu': 38,\n",
       " 'cua': 39,\n",
       " 'minh': 40,\n",
       " 'hang': 41,\n",
       " 'ngan': 42,\n",
       " 'nguoi': 43,\n",
       " 'a': 44,\n",
       " 'cong': 45,\n",
       " 'hien': 46,\n",
       " 'cho': 47,\n",
       " 'du': 48,\n",
       " 'an': 49,\n",
       " 'nay': 50,\n",
       " 'bay': 51,\n",
       " 'mao': 52,\n",
       " 'hiem': 53,\n",
       " 'qua': 54,\n",
       " 'rung': 55,\n",
       " 'tim': 56,\n",
       " 'kiem': 57,\n",
       " 'thong': 58,\n",
       " 'tin': 59,\n",
       " 'phan': 60,\n",
       " 'tu': 61,\n",
       " 'then': 62,\n",
       " 'chot': 63,\n",
       " '<EOS>': 64,\n",
       " 'Toi': 65,\n",
       " 'muon': 66,\n",
       " 'cac': 67,\n",
       " 'ban': 68,\n",
       " 'biet': 69,\n",
       " 'su': 70,\n",
       " 'to': 71,\n",
       " 'lon': 72,\n",
       " 'gop': 73,\n",
       " 'lam': 74,\n",
       " 'nen': 75,\n",
       " 'dong': 76,\n",
       " 'tit': 77,\n",
       " 'thuong': 78,\n",
       " 'thay': 79,\n",
       " 'tren': 80,\n",
       " 'Co': 81,\n",
       " 'trong': 82,\n",
       " 'nhu': 83,\n",
       " 'the': 84,\n",
       " 'va': 85,\n",
       " 'noi': 86,\n",
       " 'chat': 87,\n",
       " 'luong': 88,\n",
       " 'khong': 89,\n",
       " 'hay': 90,\n",
       " 'khoi': 91,\n",
       " 'bui': 92,\n",
       " 'Ca': 93,\n",
       " 'hai': 94,\n",
       " 'eu': 95,\n",
       " 'la': 96,\n",
       " 'nhanh': 97,\n",
       " 'linh': 98,\n",
       " 'vuc': 99,\n",
       " 'nganh': 100,\n",
       " 'Cac': 101,\n",
       " 'gan': 102,\n",
       " 'ay': 103,\n",
       " 'Ban': 104,\n",
       " 'ieu': 105,\n",
       " 'hanh': 106,\n",
       " 'Bien': 107,\n",
       " 'Lien': 108,\n",
       " 'chinh': 109,\n",
       " 'phu': 110,\n",
       " 'goi': 111,\n",
       " 'tat': 112,\n",
       " 'IPCC': 113,\n",
       " 'ua': 114,\n",
       " 'ra': 115,\n",
       " 'bai': 116,\n",
       " 'ho': 117,\n",
       " 'he': 118,\n",
       " 'Nghien': 119,\n",
       " 'uoc': 120,\n",
       " 'viet': 121,\n",
       " 'boi': 122,\n",
       " 'nha': 123,\n",
       " 'quoc': 124,\n",
       " 'khac': 125,\n",
       " 'nhau': 126,\n",
       " 'Ho': 127,\n",
       " 'trang': 128,\n",
       " 'chu': 129,\n",
       " 'Va': 130,\n",
       " 'ca': 131,\n",
       " 'xem': 132,\n",
       " 'xet': 133,\n",
       " 'phe': 134,\n",
       " 'binh': 135,\n",
       " '': 136,\n",
       " 'o': 137,\n",
       " 'ong': 138,\n",
       " 'en': 139,\n",
       " 'thuc': 140,\n",
       " 'te': 141,\n",
       " 'cuoc': 142,\n",
       " 'hoi': 143,\n",
       " 'nam': 144,\n",
       " 'chung': 145,\n",
       " 'toi': 146,\n",
       " 'nghi': 147,\n",
       " 'nhien': 148,\n",
       " 'nhat': 149,\n",
       " 'Moi': 150,\n",
       " 'hon': 151,\n",
       " 'San': 152,\n",
       " 'Francisco': 153,\n",
       " 'tham': 154,\n",
       " 'thuoc': 155,\n",
       " 'nhom': 156,\n",
       " 'moi': 157,\n",
       " 'rat': 158,\n",
       " 'nhieu': 159,\n",
       " 'tai': 160,\n",
       " 'dang': 161,\n",
       " 'Voi': 162,\n",
       " 'Cambridge': 163,\n",
       " 'dao': 164,\n",
       " 'El': 165,\n",
       " 'Nino': 166,\n",
       " 'von': 167,\n",
       " 'co': 168,\n",
       " 'tac': 169,\n",
       " 'thoi': 170,\n",
       " 'tiet': 171,\n",
       " 'tinh': 172,\n",
       " 'thai': 173,\n",
       " 'canh': 174,\n",
       " 'lieu': 175,\n",
       " 'sinh': 176,\n",
       " 'lai': 177,\n",
       " 'chia': 178,\n",
       " 'nho': 179,\n",
       " 'bang': 180,\n",
       " 'tien': 181,\n",
       " 'si': 182,\n",
       " 'phai': 183,\n",
       " 'vo': 184,\n",
       " 'cu': 185,\n",
       " 'chi': 186,\n",
       " 'vai': 187,\n",
       " 'quy': 188,\n",
       " 'trinh': 189,\n",
       " 'Mot': 190,\n",
       " 'ten': 191,\n",
       " 'isoprene': 192,\n",
       " 'No': 193,\n",
       " 'huu': 194,\n",
       " 'chua': 195,\n",
       " 'tung': 196,\n",
       " 'nghe': 197,\n",
       " 'chiec': 198,\n",
       " 'kep': 199,\n",
       " 'giay': 200,\n",
       " 'vao': 201,\n",
       " 'khoang': 202,\n",
       " 'zeta': 203,\n",
       " 'illion': 204,\n",
       " 'mu': 205,\n",
       " 'Du': 206,\n",
       " 'ngang': 207,\n",
       " 'ngua': 208,\n",
       " 'tong': 209,\n",
       " 'dan': 210,\n",
       " 'toan': 211,\n",
       " 'cau': 212,\n",
       " 'lo': 213,\n",
       " 'metan': 214,\n",
       " 'Chinh': 215,\n",
       " 'vi': 216,\n",
       " 'y': 217,\n",
       " 'nghia': 218,\n",
       " 'quan': 219,\n",
       " 'nao': 220,\n",
       " 'theo': 221,\n",
       " 'uoi': 222,\n",
       " 'Chung': 223,\n",
       " 'manh': 224,\n",
       " 'Phong': 225,\n",
       " 'EUPHORE': 226,\n",
       " 'Tay': 227,\n",
       " 'Nha': 228,\n",
       " 'chay': 229,\n",
       " 'hoan': 230,\n",
       " 'dien': 231,\n",
       " 'cham': 232,\n",
       " 'lan': 233,\n",
       " 'ung': 234,\n",
       " 'xe': 235,\n",
       " 'vay': 236,\n",
       " 'van': 237,\n",
       " 'mo': 238,\n",
       " 'hinh': 239,\n",
       " 'sieu': 240,\n",
       " 'may': 241,\n",
       " 'viec': 242,\n",
       " 'Mo': 243,\n",
       " 'gom': 244,\n",
       " 'tram': 245,\n",
       " 'thung': 246,\n",
       " 'xep': 247,\n",
       " 'chong': 248,\n",
       " 'gian': 249,\n",
       " 'cuc': 250,\n",
       " 'Ma': 251,\n",
       " 'can': 252,\n",
       " 'tuan': 253,\n",
       " 'xong': 254,\n",
       " 'phep': 255,\n",
       " 'tich': 256,\n",
       " 'ta': 257,\n",
       " 'hieu': 258,\n",
       " 'gi': 259,\n",
       " 'xay': 260,\n",
       " 'con': 261,\n",
       " 'khap': 262,\n",
       " 'Gan': 263,\n",
       " 'khao': 264,\n",
       " 'sat': 265,\n",
       " 'ia': 266,\n",
       " 'Malaysia': 267,\n",
       " 'Con': 268,\n",
       " 'nua': 269,\n",
       " 'thap': 270,\n",
       " 'ngay': 271,\n",
       " 'giua': 272,\n",
       " 'treo': 273,\n",
       " 'thiet': 274,\n",
       " 'bi': 275,\n",
       " 'tri': 276,\n",
       " 'xa': 277,\n",
       " 'cai': 278,\n",
       " 'thu': 279,\n",
       " 'suot': 280,\n",
       " 'nhin': 281,\n",
       " 'cao': 282,\n",
       " 'duoi': 283,\n",
       " 'at': 284,\n",
       " 'giai': 285,\n",
       " 'mang': 286,\n",
       " 'Chiec': 287,\n",
       " 'phi': 288,\n",
       " 'mau': 289,\n",
       " 'BA': 290,\n",
       " 'do': 291,\n",
       " 'FAAM': 292,\n",
       " 'Rat': 293,\n",
       " 'tuong': 294,\n",
       " 'hom': 295,\n",
       " 'cach': 296,\n",
       " 'tang': 297,\n",
       " 'vom': 298,\n",
       " 'met': 299,\n",
       " 'ac': 300,\n",
       " 'nguy': 301,\n",
       " 'nghieng': 302,\n",
       " 'Phai': 303,\n",
       " 'thue': 304,\n",
       " 'hach': 305,\n",
       " 'khien': 306,\n",
       " 'xin': 307,\n",
       " 'lenh': 308,\n",
       " 'Khi': 309,\n",
       " 'quanh': 310,\n",
       " 'bo': 311,\n",
       " 'song': 312,\n",
       " 'lung': 313,\n",
       " 'len': 314,\n",
       " 'G': 315,\n",
       " 'that': 316,\n",
       " 'ghe': 317,\n",
       " 'Vi': 318,\n",
       " 'dung': 319,\n",
       " 'ben': 320,\n",
       " 'giong': 321,\n",
       " 'bat': 322,\n",
       " 'ky': 323,\n",
       " 'lich': 324,\n",
       " 'phong': 325,\n",
       " 'thi': 326,\n",
       " 'nghiem': 327,\n",
       " 'di': 328,\n",
       " 'giup': 329,\n",
       " 'thich': 330,\n",
       " 'ai': 331,\n",
       " 'loai': 332,\n",
       " 'se': 333,\n",
       " 'ngoai': 334,\n",
       " 'kien': 335,\n",
       " 'inh': 336,\n",
       " 'thanh': 337,\n",
       " 'muc': 338,\n",
       " 'mac': 339,\n",
       " 'chuong': 340,\n",
       " 'Noi': 341,\n",
       " 'anh': 342,\n",
       " 'luon': 343,\n",
       " 'kem': 344,\n",
       " 'tom': 345,\n",
       " 'oc': 346,\n",
       " 'sach': 347,\n",
       " 'Cam': 348,\n",
       " 'on': 349,\n",
       " 'Christopher': 350,\n",
       " 'deCharms': 351,\n",
       " 'quet': 352,\n",
       " 'than': 353,\n",
       " 'kinh': 354,\n",
       " 'sang': 355,\n",
       " 'che': 356,\n",
       " 'fMRI': 357,\n",
       " 'ghi': 358,\n",
       " 'hoat': 359,\n",
       " 'suy': 360,\n",
       " 'cam': 361,\n",
       " 'xuc': 362,\n",
       " 'au': 363,\n",
       " 'nhan': 364,\n",
       " 'Xin': 365,\n",
       " 'chao': 366,\n",
       " 'gio': 367,\n",
       " 'tay': 368,\n",
       " 'phia': 369,\n",
       " 'hoang': 370,\n",
       " 'Bat': 371,\n",
       " 'chuoc': 372,\n",
       " 'lap': 373,\n",
       " 'bap': 374,\n",
       " 'som': 375,\n",
       " 'vung': 376,\n",
       " 'ma': 377,\n",
       " 'Vang': 378,\n",
       " 'buoc': 379,\n",
       " 'quyet': 380,\n",
       " 'kho': 381,\n",
       " 'thuyen': 382,\n",
       " 'mach': 383,\n",
       " 'bach': 384,\n",
       " 'tan': 385,\n",
       " 'Nhung': 386,\n",
       " 'nghiep': 387,\n",
       " 'Peter': 388,\n",
       " 'xam': 389,\n",
       " 'nhap': 390,\n",
       " 'MRI': 391,\n",
       " 'Khong': 392,\n",
       " 'bom': 393,\n",
       " 'tia': 394,\n",
       " 'buc': 395,\n",
       " 'hop': 396,\n",
       " 'tam': 397,\n",
       " 'vang': 398,\n",
       " 'be': 399,\n",
       " 'mat': 400,\n",
       " 'Truoc': 401,\n",
       " 'ien': 402,\n",
       " 'robot': 403,\n",
       " 'chup': 404,\n",
       " 'Cai': 405,\n",
       " 'chiem': 406,\n",
       " 'hoac': 407,\n",
       " 'thang': 408,\n",
       " 'mili': 409,\n",
       " 'Anh': 410,\n",
       " 'iem': 411,\n",
       " 'kich': 412,\n",
       " 'Neu': 413,\n",
       " 'ba': 414,\n",
       " 'huong': 415,\n",
       " 'giuong': 416,\n",
       " 'vien': 417,\n",
       " 'lua': 418,\n",
       " 'chon': 419,\n",
       " 'Ta': 420,\n",
       " 'rang': 421,\n",
       " 'kenh': 422,\n",
       " 'nien': 423,\n",
       " 'giat': 424,\n",
       " 'neu': 425,\n",
       " 'dut': 426,\n",
       " 'vong': 427,\n",
       " 'san': 428,\n",
       " 'xuat': 429,\n",
       " 'xung': 430,\n",
       " 'chieu': 431,\n",
       " 'Bay': 432,\n",
       " 'uong': 433,\n",
       " 'i': 434,\n",
       " 'benh': 435,\n",
       " 'shock': 436,\n",
       " 'doi': 437,\n",
       " 'gay': 438,\n",
       " 'tap': 439,\n",
       " 'xoa': 440,\n",
       " 'diu': 441,\n",
       " 'goc': 442,\n",
       " 'trai': 443,\n",
       " 'ket': 444,\n",
       " 'phuong': 445,\n",
       " 'phap': 446,\n",
       " 'giam': 447,\n",
       " 'tran': 448,\n",
       " 'ki': 449,\n",
       " 'uc': 450,\n",
       " 'danh': 451,\n",
       " 'tue': 452,\n",
       " 'Beeban': 453,\n",
       " 'Kidron': 454,\n",
       " 'dieu': 455,\n",
       " 'phim': 456,\n",
       " 'suc': 457,\n",
       " 'thuat': 458,\n",
       " 'ao': 459,\n",
       " 'Phep': 460,\n",
       " 'Milan': 461,\n",
       " 'khu': 462,\n",
       " 'ke': 463,\n",
       " 'FILMCLUB': 464,\n",
       " 'lu': 465,\n",
       " 'tre': 466,\n",
       " 'Bang': 467,\n",
       " 'tuoi': 468,\n",
       " 'Tu': 469,\n",
       " 'me': 470,\n",
       " 'gai': 471,\n",
       " 'thuyet': 472,\n",
       " 'giao': 473,\n",
       " 'khan': 474,\n",
       " 'thinh': 475,\n",
       " 'Internet': 476,\n",
       " 'ngon': 477,\n",
       " 'nang': 478,\n",
       " 'coi': 479,\n",
       " 'trao': 480,\n",
       " 'trung': 481,\n",
       " 'loi': 482,\n",
       " 'liet': 483,\n",
       " 'sac': 484,\n",
       " 'qui': 485,\n",
       " 'truyen': 486,\n",
       " 'tranh': 487,\n",
       " 'vuot': 488,\n",
       " 'ranh': 489,\n",
       " 'ngu': 490,\n",
       " 'triet': 491,\n",
       " 'ly': 492,\n",
       " 'Thuc': 493,\n",
       " 'rong': 494,\n",
       " 'Hollywood': 495,\n",
       " 'phuc': 496,\n",
       " 'vu': 497,\n",
       " 'kieng': 498,\n",
       " 'giac': 499,\n",
       " 'quen': 500,\n",
       " 'truoc': 501,\n",
       " 'La': 502,\n",
       " 'ngai': 503,\n",
       " 'reo': 504,\n",
       " 'Chua': 505,\n",
       " 'Tuong': 506,\n",
       " 'it': 507,\n",
       " 'That': 508,\n",
       " 'mia': 509,\n",
       " 'yeu': 510,\n",
       " 'chuc': 511,\n",
       " 'truong': 512,\n",
       " 'thao': 513,\n",
       " 'luan': 514,\n",
       " 'tra': 515,\n",
       " 'soat': 516,\n",
       " 'le': 517,\n",
       " 'ngung': 518,\n",
       " 'tiep': 519,\n",
       " 'thon': 520,\n",
       " 'DVD': 521,\n",
       " 'lac': 522,\n",
       " 'doc': 523,\n",
       " 'nuoc': 524,\n",
       " 'em': 525,\n",
       " 'ngat': 526,\n",
       " 'quang': 527,\n",
       " 'mon': 528,\n",
       " 'giau': 529,\n",
       " 'cap': 530,\n",
       " 'tuc': 531,\n",
       " 'duc': 532,\n",
       " 'tuy': 533,\n",
       " 'kha': 534,\n",
       " 'kham': 535,\n",
       " 'pha': 536,\n",
       " 'Ngay': 537,\n",
       " 'mong': 538,\n",
       " 'Bo': 539,\n",
       " 'Vittorio': 540,\n",
       " 'De': 541,\n",
       " 'Sica': 542,\n",
       " 'chuot': 543,\n",
       " 'ngheo': 544,\n",
       " 'khat': 545,\n",
       " 'dip': 546,\n",
       " 'Cong': 547,\n",
       " 'rap': 548,\n",
       " 'in': 549,\n",
       " 'cha': 550,\n",
       " 'Su': 551,\n",
       " 'mung': 552,\n",
       " 'teen': 553,\n",
       " 'niem': 554,\n",
       " 'hy': 555,\n",
       " 'cuoi': 556,\n",
       " 'bau': 557,\n",
       " 'troi': 558,\n",
       " 'cay': 559,\n",
       " 'choi': 560,\n",
       " 'Sau': 561,\n",
       " 'muoi': 562,\n",
       " 'guong': 563,\n",
       " 'ngac': 564,\n",
       " 'ngo': 565,\n",
       " 'toc': 566,\n",
       " 'lien': 567,\n",
       " 'Trieu': 568,\n",
       " 'pho': 569,\n",
       " 'favela': 570,\n",
       " 'Rio': 571,\n",
       " 'mua': 572,\n",
       " 'Cau': 573,\n",
       " 'Ong': 574,\n",
       " 'Smith': 575,\n",
       " 'Washington': 576,\n",
       " 'het': 577,\n",
       " 'Frank': 578,\n",
       " 'Capra': 579,\n",
       " 'tro': 580,\n",
       " 'long': 581,\n",
       " 'nguon': 582,\n",
       " 'lau': 583,\n",
       " 'buoi': 584,\n",
       " 'luat': 585,\n",
       " 'Toa': 586,\n",
       " 'vui': 587,\n",
       " 'sao': 588,\n",
       " 'nguyen': 589,\n",
       " 'Jimmy': 590,\n",
       " 'Stewart': 591,\n",
       " 'Khach': 592,\n",
       " 'Rwanda': 593,\n",
       " 'bon': 594,\n",
       " 'diet': 595,\n",
       " 'giot': 596,\n",
       " 'thuy': 597,\n",
       " 'gat': 598,\n",
       " 'Schindler': 599,\n",
       " 'roi': 600,\n",
       " 'Ke': 601,\n",
       " 'moc': 602,\n",
       " 'tui': 603,\n",
       " 'tuoc': 604,\n",
       " 'pham': 605,\n",
       " 'Gui': 606,\n",
       " 'men': 607,\n",
       " 'ot': 608,\n",
       " 'Briton': 609,\n",
       " 'da': 610,\n",
       " 'chui': 611,\n",
       " 'rua': 612,\n",
       " 'ngoi': 613,\n",
       " 'Sidney': 614,\n",
       " 'Potier': 615,\n",
       " 'lay': 616,\n",
       " 'xuoi': 617,\n",
       " 'am': 618,\n",
       " 'cang': 619,\n",
       " 'ganh': 620,\n",
       " 'vinh': 621,\n",
       " 'trieu': 622,\n",
       " 'Mac': 623,\n",
       " 'cat': 624,\n",
       " 'Persepolis': 625,\n",
       " 'Iran': 626,\n",
       " 'Ham': 627,\n",
       " 'map': 628,\n",
       " 'giet': 629,\n",
       " 'chet': 630,\n",
       " 'nem': 631,\n",
       " 'man': 632,\n",
       " 'tau': 633,\n",
       " 'Ai': 634,\n",
       " 'sai': 635,\n",
       " 'iep': 636,\n",
       " 'dau': 637,\n",
       " 'Lam': 638,\n",
       " 'mieng': 639,\n",
       " 'chang': 640,\n",
       " 'tuyet': 641,\n",
       " 'chan': 642,\n",
       " 'nui': 643,\n",
       " 'cuop': 644,\n",
       " 'Kha': 645,\n",
       " 'Israel': 646,\n",
       " 'loan': 647,\n",
       " 'Me': 648,\n",
       " 'chau': 649,\n",
       " 'Au': 650,\n",
       " 'nan': 651,\n",
       " 'kim': 652,\n",
       " 'cuong': 653,\n",
       " 'khau': 654,\n",
       " 'tron': 655,\n",
       " 'Luan': 656,\n",
       " 'im': 657,\n",
       " 'lang': 658,\n",
       " 'Anne': 659,\n",
       " 'thoat': 660,\n",
       " 'Shoah': 661,\n",
       " 'Chien': 662,\n",
       " 'Will': 663,\n",
       " 'Leni': 664,\n",
       " 'Riefenstahl': 665,\n",
       " 'Nazi': 666,\n",
       " 'chiu': 667,\n",
       " 'ich': 668,\n",
       " 'sot': 669,\n",
       " 'thoang': 670,\n",
       " 'xuyen': 671,\n",
       " 'Nguoi': 672,\n",
       " 'thuan': 673,\n",
       " 'xua': 674,\n",
       " 'tho': 675,\n",
       " 'thien': 676,\n",
       " 'cuon': 677,\n",
       " 'Nhu': 678,\n",
       " 'Phu': 679,\n",
       " 'xu': 680,\n",
       " 'Oz': 681,\n",
       " 'Hay': 682,\n",
       " 'Kane': 683,\n",
       " 'Jane': 684,\n",
       " 'Austen': 685,\n",
       " 'Tennyson': 686,\n",
       " 'khung': 687,\n",
       " 'thau': 688,\n",
       " 'phoi': 689,\n",
       " 'gach': 690,\n",
       " 'Tom': 691,\n",
       " 'Hanks': 692,\n",
       " 'tru': 693,\n",
       " 'Jim': 694,\n",
       " 'Lovell': 695,\n",
       " 'khuon': 696,\n",
       " 'Ben': 697,\n",
       " 'Kingley': 698,\n",
       " 'Gandhi': 699,\n",
       " 'Eve': 700,\n",
       " 'Harrington': 701,\n",
       " 'Howard': 702,\n",
       " 'Beale': 703,\n",
       " 'Mildred': 704,\n",
       " 'Pierce': 705,\n",
       " 'bot': 706,\n",
       " 'Shakespeare': 707,\n",
       " 'Elizabeth': 708,\n",
       " 'nhac': 709,\n",
       " 'hung': 710,\n",
       " 'phat': 711,\n",
       " 'trien': 712,\n",
       " 'mien': 713,\n",
       " 'Thanh': 714,\n",
       " 'thach': 715,\n",
       " 'nhi': 716,\n",
       " 'nac': 717,\n",
       " 'Boi': 718,\n",
       " 'Cua': 719,\n",
       " 'toa': 720,\n",
       " 'kia': 721,\n",
       " 'Ellen': 722,\n",
       " 'Jorgensen': 723,\n",
       " 'Hack': 724,\n",
       " 'vat': 725,\n",
       " 'Genspace': 726,\n",
       " 'nhuan': 727,\n",
       " 'Brooklyn': 728,\n",
       " 'Khac': 729,\n",
       " 'xau': 730,\n",
       " 'Frankenstein': 731,\n",
       " 'dai': 732,\n",
       " 'nhon': 733,\n",
       " 'DIYbio': 734,\n",
       " 'Thoi': 735,\n",
       " 'Viec': 736,\n",
       " 'DNA': 737,\n",
       " 'de': 738,\n",
       " 're': 739,\n",
       " 'gen': 740,\n",
       " 'euro': 741,\n",
       " 'tiem': 742,\n",
       " 'khia': 743,\n",
       " 'Vay': 744,\n",
       " 'yen': 745,\n",
       " 'Vao': 746,\n",
       " 'khuyen': 747,\n",
       " 'khich': 748,\n",
       " 'Y': 749,\n",
       " 'tot': 750,\n",
       " 'ro': 751,\n",
       " 'xac': 752,\n",
       " 'Do': 753,\n",
       " 'Nen': 754,\n",
       " 'New': 755,\n",
       " 'York': 756,\n",
       " 'lop': 757,\n",
       " 'voc': 758,\n",
       " 'chuan': 759,\n",
       " 'Bao': 760,\n",
       " 'google': 761,\n",
       " 'buon': 762,\n",
       " 'duy': 763,\n",
       " 'gang': 764,\n",
       " 'hacker': 765,\n",
       " 'soi': 766,\n",
       " 'sap': 767,\n",
       " 'Moscow': 768,\n",
       " 'Han': 769,\n",
       " 'Quoc': 770,\n",
       " 'rieng': 771,\n",
       " 'dua': 772,\n",
       " 'chut': 773,\n",
       " 'ap': 774,\n",
       " 'khuan': 775,\n",
       " 'hack': 776,\n",
       " 'mem': 777,\n",
       " 'uot': 778,\n",
       " 'nhay': 779,\n",
       " 'Tinh': 780,\n",
       " 'ninh': 781,\n",
       " 'luoi': 782,\n",
       " 'nano': 783,\n",
       " 'ha': 784,\n",
       " 'Hiep': 785,\n",
       " 'DYI': 786,\n",
       " 'My': 787,\n",
       " 'Chau': 788,\n",
       " 'Gio': 789,\n",
       " 'li': 790,\n",
       " 'rac': 791,\n",
       " 'A': 792,\n",
       " 'sa': 793,\n",
       " 'Sahara': 794,\n",
       " 'An': 795,\n",
       " 'Gen': 796,\n",
       " 'Nhan': 797,\n",
       " 'Havard': 798,\n",
       " 'chap': 799,\n",
       " 'xuong': 800,\n",
       " 'ADN': 801,\n",
       " 'Nao': 802,\n",
       " 'biohacker': 803,\n",
       " 'banh': 804,\n",
       " 'vot': 805,\n",
       " 'Nhat': 806,\n",
       " 'vach': 807,\n",
       " 'sushi': 808,\n",
       " 'coc': 809,\n",
       " 'tha': 810,\n",
       " 'duyet': 811,\n",
       " 'nhiem': 812,\n",
       " 'pin': 813,\n",
       " 'ngoan': 814,\n",
       " 'Vai': 815,\n",
       " 'hao': 816,\n",
       " 'Van': 817,\n",
       " 'thieng': 818,\n",
       " 'lieng': 819,\n",
       " 'huyt': 820,\n",
       " 'Tai': 821,\n",
       " 'TEDxRotterdam': 822,\n",
       " 'Geert': 823,\n",
       " 'Chatrou': 824,\n",
       " 'bieu': 825,\n",
       " 'Eleonora': 826,\n",
       " 'Honhoff': 827,\n",
       " 'Fete': 828,\n",
       " 'Belle': 829,\n",
       " 'huyet': 830,\n",
       " 'tieng': 831,\n",
       " 'tria': 832,\n",
       " 'xoan': 833,\n",
       " 'Ha': 834,\n",
       " 'Lan': 835,\n",
       " 'and': 836,\n",
       " 'quay': 837,\n",
       " 'ray': 838,\n",
       " 'tiec': 839,\n",
       " 'giang': 840,\n",
       " 'Bai': 841,\n",
       " 'loc': 842,\n",
       " 'mui': 843,\n",
       " 'Rudolph': 844,\n",
       " 'bua': 845,\n",
       " 'Chi': 846,\n",
       " 'ruou': 847,\n",
       " 'thua': 848,\n",
       " 'Em': 849,\n",
       " 'chac': 850,\n",
       " 'Louisburg': 851,\n",
       " 'bac': 852,\n",
       " 'Carolina': 853,\n",
       " 'chien': 854,\n",
       " 'judokas': 855,\n",
       " 'gianh': 856,\n",
       " 'Tokyo': 857,\n",
       " 'Rotterdam': 858,\n",
       " 'xinh': 859,\n",
       " 'ep': 860,\n",
       " 'Okay': 861,\n",
       " 'Troi': 862,\n",
       " 'luyen': 863,\n",
       " 'nhe': 864,\n",
       " 'hua': 865,\n",
       " 'hen': 866,\n",
       " 'ga': 867,\n",
       " 'Oh': 868,\n",
       " 'hah': 869,\n",
       " 'Phan': 870,\n",
       " 'Max': 871,\n",
       " 'Westerman': 872,\n",
       " 'Chartrou': 873,\n",
       " 'Roberto': 874,\n",
       " 'D': 875,\n",
       " 'Angelo': 876,\n",
       " 'Francesca': 877,\n",
       " 'Fedeli': 878,\n",
       " 'Mario': 879,\n",
       " 'khoe': 880,\n",
       " 'khoan': 881,\n",
       " 'Be': 882,\n",
       " 'ven': 883,\n",
       " 'thia': 884,\n",
       " 'xoay': 885,\n",
       " 'ruoi': 886,\n",
       " 'duong': 887,\n",
       " 'u': 888,\n",
       " 'Apgar': 889,\n",
       " 'ton': 890,\n",
       " 'Hau': 891,\n",
       " 'gui': 892,\n",
       " 'Giong': 893,\n",
       " 'hoach': 894,\n",
       " 'day': 895,\n",
       " 'khuyet': 896,\n",
       " 'ne': 897,\n",
       " 'neuron': 898,\n",
       " 'Ve': 899,\n",
       " 'sup': 900,\n",
       " 'Video': 901,\n",
       " 'cot': 902,\n",
       " 'Tam': 903,\n",
       " 'Mark': 904,\n",
       " 'Shaw': 905,\n",
       " 'Cuc': 906,\n",
       " 'Kho': 907,\n",
       " 'O': 908,\n",
       " 'Hom': 909,\n",
       " 'sua': 910,\n",
       " 'xi': 911,\n",
       " 'xit': 912,\n",
       " 'hut': 913,\n",
       " 'Rong': 914,\n",
       " 'Giot': 915,\n",
       " 'vua': 916,\n",
       " 'sut': 917,\n",
       " 'nanomet': 918,\n",
       " 'ti': 919,\n",
       " 'hat': 920,\n",
       " 'son': 921,\n",
       " 'bun': 922,\n",
       " 'vuong': 923,\n",
       " 'ria': 924,\n",
       " 'nhuom': 925,\n",
       " 'xanh': 926,\n",
       " 'khe': 927,\n",
       " 'truot': 928,\n",
       " 'ri': 929,\n",
       " 'set': 930,\n",
       " 'Thu': 931,\n",
       " 'Se': 932,\n",
       " 'TED': 933,\n",
       " 'Hai': 934,\n",
       " 'Dan': 935,\n",
       " 'Ariely': 936,\n",
       " 'trom': 937,\n",
       " 'kheo': 938,\n",
       " 'leo': 939,\n",
       " 'Niem': 940,\n",
       " 'bong': 941,\n",
       " 'gap': 942,\n",
       " 'Cach': 943,\n",
       " 'boc': 944,\n",
       " 'giu': 945,\n",
       " 'ghet': 946,\n",
       " 'khoanh': 947,\n",
       " 'toac': 948,\n",
       " 'thiep': 949,\n",
       " 'Hebrew': 950,\n",
       " 'truu': 951,\n",
       " 'Hoac': 952,\n",
       " 'kieu': 953,\n",
       " 'them': 954,\n",
       " 'rut': 955,\n",
       " 'Hoa': 956,\n",
       " 'Le': 957,\n",
       " 'keo': 958,\n",
       " 'Tat': 959,\n",
       " 'Ly': 960,\n",
       " 'Enron': 961,\n",
       " 'bung': 962,\n",
       " 'Lieu': 963,\n",
       " 'rau': 964,\n",
       " 'dich': 965,\n",
       " 'Nhet': 966,\n",
       " 'vun': 967,\n",
       " 'Xet': 968,\n",
       " 'cent': 969,\n",
       " 'The': 970,\n",
       " 'uu': 971,\n",
       " 'Mat': 972,\n",
       " 'Ran': 973,\n",
       " 'Ket': 974,\n",
       " 'nguong': 975,\n",
       " 'ran': 976,\n",
       " 'Khoanh': 977,\n",
       " 'Kinh': 978,\n",
       " 'Danh': 979,\n",
       " 'MIT': 980,\n",
       " 'Thi': 981,\n",
       " 'Coke': 982,\n",
       " 'lanh': 983,\n",
       " 'Nguoc': 984,\n",
       " 'X': 985,\n",
       " 'phieu': 986,\n",
       " 'ft': 987,\n",
       " 'truc': 988,\n",
       " 'but': 989,\n",
       " 'iieu': 990,\n",
       " 'Sinh': 991,\n",
       " 'Nhiem': 992,\n",
       " 'Chuyen': 993,\n",
       " 'Carnegie': 994,\n",
       " 'Mellon': 995,\n",
       " 'Pittsburgh': 996,\n",
       " 'ngot': 997,\n",
       " 'meo': 998,\n",
       " 'tach': 999,\n",
       " 'xoi': 1000,\n",
       " 'Khai': 1001,\n",
       " ...}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Example of Language #1 sentence: 深海 海中 的 生命   大卫   盖罗 \n",
      "Example of Language #2 sentence: Life in the deep oceans\n",
      "Read 213376 sentence pairs\n",
      "Trimmed to 213376 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 89202\n",
      "en 59327\n",
      "['哈马 哈马斯 组织 织成 成员    我们 是 完全 和平 的   我们 希望 让 它 遍及 整个 巴勒 巴勒斯 巴勒斯坦 勒斯 坦 <EOS>', 'Hamas Party Member We were in complete harmony and we wanted to spread it to all of Palestine <EOS>']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData(lang1 = 'zh', \n",
    "                                             lang2 = 'en', \n",
    "                                             reverse = False, \n",
    "                                             dataset = \"train\")\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Vietnamese to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 133317 sentence pairs\n",
      "Trimmed to 133317 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 16142\n",
      "en 47566\n",
      "Reading lines...\n",
      "Read 1268 sentence pairs\n",
      "Trimmed to 1268 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 1368\n",
      "en 3814\n",
      "Reading lines...\n",
      "Read 1553 sentence pairs\n",
      "Trimmed to 1553 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "vi 1323\n",
      "en 3617\n"
     ]
    }
   ],
   "source": [
    "# Format: languagepair_language_dataset\n",
    "# Train \n",
    "vien_vi_train, vien_en_train, vi_en_train_pairs = prepareData('vi', 'en', False, dataset=\"train\")\n",
    "# Dev \n",
    "vien_vi_dev, vien_en_dev, vi_en_dev_pairs = prepareData('vi', 'en', False, dataset=\"dev\")\n",
    "# Test\n",
    "vien_vi_test, vien_en_test, vi_en_test_pairs = prepareData('vi', 'en', False, dataset=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Chinese to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 213376 sentence pairs\n",
      "Trimmed to 213376 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 89202\n",
      "en 59327\n",
      "Reading lines...\n",
      "Read 1261 sentence pairs\n",
      "Trimmed to 1261 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 6134\n",
      "en 3914\n",
      "Reading lines...\n",
      "Read 1397 sentence pairs\n",
      "Trimmed to 1397 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "zh 5216\n",
      "en 3421\n"
     ]
    }
   ],
   "source": [
    "# Format: languagepair_language_dataset\n",
    "# Train \n",
    "zhen_zh_train, zhen_en_train, zh_en_train_pairs = prepareData('zh', 'en', False, dataset=\"train\")\n",
    "# Dev \n",
    "zhen_zh_dev, zhen_en_dev, zh_en_dev_pairs = prepareData('zh', 'en', False, dataset=\"dev\")\n",
    "# Test\n",
    "zhen_zh_test, zhen_en_test, zh_en_test_pairs = prepareData('zh', 'en', False, dataset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我们 将 用 一些 影片 来讲 讲述 一些 深海 海里 的 故事  <EOS>',\n",
       " 'And we apos re going to tell you some stories from the sea here in video <EOS>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_en_train_pairs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Check Source & Target Vocabs\n",
    "\n",
    "Since the source and target languages can have very different table lookup layers, it's good practice to have separate vocabularies for each. Thus, we build vocabularies for each language that we will be using. \n",
    "\n",
    "In the first class (Lang) of this section, we have already defined vocabularies for all languages. So, there is no need to redefine another function. We chech each vocabulary below.\n",
    "\n",
    "#### Chinese Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in Chinese training corpus is 89202\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in Chinese training corpus is \" + str(zhen_zh_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10481"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_zh_train.word2index[\"格\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'格'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_zh_train.index2word[10481]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vietnamese Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in Vietnamese training corpus is 16142\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in Vietnamese training corpus is \" + str(vien_vi_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6750"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_vi_train.word2index[\"Hamburger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hamburger'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_vi_train.index2word[6750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Vocabulary for Zh-En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in English training corpus for Zh-En is 59327\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in English training corpus for Zh-En is \" + str(zhen_en_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_en_train.word2index[\"translate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'directly'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zhen_en_train.index2word[1451]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### English Vocabulary for Vi-En"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in English training corpus for Vi-En is 47566\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of words in English training corpus for Vi-En is \" + str(vien_en_train.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_en_train.word2index[\"machine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_en_train.index2word[846]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_en_dev.word2index[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<EOS>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vien_en_dev.index2word[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "SOS_IDX = 1\n",
    "UNK_IDX = 2\n",
    "# EOS_IDX = 3\n",
    "# convert token to id in the dataset\n",
    "def token2index_dataset(paired_tokens, \n",
    "                        lang1_token2id_vocab,\n",
    "                        lang2_token2id_vocab):\n",
    "    \"\"\"Takes as input:\n",
    "    - paired_tokens: a list of sentence pairs that consist of source & target lang sentences.\n",
    "    - lang1_token2id_vocab: token2index vocabulary for the first language. \n",
    "                            Get by method Lang_dataset.word2index\n",
    "    - lang2_token2id_vocab: token2index vocabulary for the second language. \n",
    "                            Get by method Lang_dataset.word2index\n",
    "                            \n",
    "    Returns:\n",
    "    - indices_data_lang_1, indices_data_lang2: A list of lists where each sub-list holds corresponding indices for each\n",
    "                                               token in the sentence.\"\"\"\n",
    "    indices_data_lang_1, indices_data_lang_2 = [], []\n",
    "    vocabs = [lang1_token2id_vocab, lang2_token2id_vocab]\n",
    "    \n",
    "    # lang1\n",
    "    for t in range(len(paired_tokens)):\n",
    "        # replaces token with UNK_IDX if the token is not in vocab\n",
    "        index_list = [vocabs[0][token] if token in vocabs[0]\\\n",
    "                                    else UNK_IDX for token in paired_tokens[t][0]] \n",
    "        indices_data_lang_1.append(index_list)\n",
    "    # lang2\n",
    "    for t in range(len(paired_tokens)):\n",
    "        index_list =  [vocabs[1][token] if token in vocabs[1] \\\n",
    "                                    else UNK_IDX for token in paired_tokens[t][1]] \n",
    "        indices_data_lang_2.append(index_list)\n",
    "        \n",
    "    return indices_data_lang_1, indices_data_lang_2\n",
    "\n",
    "# train indices\n",
    "zhen_zh_train_indices, zhen_en_train_indices = token2index_dataset(zh_en_train_pairs,\n",
    "                                                                   zhen_zh_train.word2index,\n",
    "                                                                   zhen_en_train.word2index)\n",
    "\n",
    "vien_vi_train_indices, vien_en_train_indices = token2index_dataset(vi_en_train_pairs,\n",
    "                                                                   vien_vi_train.word2index,\n",
    "                                                                   vien_en_train.word2index)\n",
    "\n",
    "# dev indices\n",
    "zhen_zh_dev_indices, zhen_en_dev_indices = token2index_dataset(zh_en_dev_pairs,\n",
    "                                                               zhen_zh_dev.word2index,\n",
    "                                                               zhen_en_dev.word2index)\n",
    "\n",
    "vien_vi_dev_indices, vien_en_dev_indices = token2index_dataset(vi_en_dev_pairs,\n",
    "                                                               vien_vi_dev.word2index,\n",
    "                                                               vien_en_dev.word2index)\n",
    "\n",
    "# test indices\n",
    "zhen_zh_test_indices, zhen_en_test_indices = token2index_dataset(zh_en_test_pairs,\n",
    "                                                                 zhen_zh_test.word2index,\n",
    "                                                                 zhen_en_test.word2index)\n",
    "\n",
    "vien_vi_test_indices, vien_en_test_indices = token2index_dataset(vi_en_test_pairs,\n",
    "                                                                 vien_vi_test.word2index,\n",
    "                                                                 vien_en_test.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[321, 7912, 2, 7912, 310, 2, 4, 2, 1586, 23701, 2, 2, 2, 275, 49581, 2, 2, 2, 5915, 6331, 2, 2, 5868, 16124, 5789, 2]\n"
     ]
    }
   ],
   "source": [
    "print(zhen_zh_train_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4216, 16909, 49096, 8295, 2, 16909, 2107, 2, 268, 2, 8295, 2, 1735, 8295, 8295, 10558, 2, 1263, 28417, 8295, 158, 2107, 23]\n"
     ]
    }
   ],
   "source": [
    "print(zhen_en_train_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese training sentence count = 213376\n",
      "Chinese-English (En) training sentence count = 213376\n",
      "\n",
      "Vietnamese training sentence count = 133317\n",
      "Vietnamese-English (En) training sentence count = 133317\n",
      "\n",
      "Chinese dev sentence count = 1261\n",
      "Chinese-English (En) dev sentence count = 1261\n",
      "\n",
      "Vietnamese dev sentence count = 1268\n",
      "Vietnamese-English (En) dev sentence count = 1268\n",
      "\n",
      "Chinese test sentence count = 1397\n",
      "Chinese-English (En) test sentence count = 1397\n",
      "\n",
      "Vietnamese test sentence count = 1553\n",
      "Vietnamese-English (En) test sentence count = 1553\n"
     ]
    }
   ],
   "source": [
    "# check length\n",
    "# train\n",
    "print (\"Chinese training sentence count = \"+str(len(zhen_zh_train_indices)))\n",
    "print (\"Chinese-English (En) training sentence count = \"+str(len(zhen_en_train_indices)))\n",
    "print (\"\\nVietnamese training sentence count = \"+str(len(vien_vi_train_indices)))\n",
    "print (\"Vietnamese-English (En) training sentence count = \"+str(len(vien_en_train_indices)))\n",
    "# dev\n",
    "print (\"\\nChinese dev sentence count = \"+str(len(zhen_zh_dev_indices)))\n",
    "print (\"Chinese-English (En) dev sentence count = \"+str(len(zhen_en_dev_indices)))\n",
    "print (\"\\nVietnamese dev sentence count = \"+str(len(vien_vi_dev_indices)))\n",
    "print (\"Vietnamese-English (En) dev sentence count = \"+str(len(vien_en_dev_indices)))\n",
    "# test\n",
    "print (\"\\nChinese test sentence count = \"+str(len(zhen_zh_test_indices)))\n",
    "print (\"Chinese-English (En) test sentence count = \"+str(len(zhen_en_test_indices)))\n",
    "print (\"\\nVietnamese test sentence count = \"+str(len(vien_vi_test_indices)))\n",
    "print (\"Vietnamese-English (En) test sentence count = \"+str(len(vien_en_test_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zhen_train_dataset:\n",
      "self.source_sentences = [321, 7912, 2, 7912, 310, 2, 4, 2, 1586, 23701, 2, 2, 2, 275, 49581, 2, 2, 2, 5915, 6331, 2, 2, 5868, 16124, 5789, 2]\n",
      "self.target_sentences = [4216, 16909, 49096, 8295, 2, 16909, 2107, 2, 268, 2, 8295, 2, 1735, 8295, 8295, 10558, 2, 1263, 28417, 8295, 158, 2107, 23]\n",
      "\n",
      "Loading zhen_dev_dataset:\n",
      "self.source_sentences = [2, 2, 1232, 1232, 2, 4, 2, 55, 91, 2, 2, 2, 2, 2695, 650, 2, 650, 14, 2, 766, 678, 2, 4782, 2, 2, 2, 281, 2, 2, 2, 27, 2802, 2, 430, 729, 2, 14, 2, 2, 2, 2, 16, 2, 4733, 5952, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "self.target_sentences = [2, 2, 2, 2, 2, 3, 2, 2, 30, 199, 2, 3, 2, 2, 2, 419, 2, 419, 2, 2, 2, 2, 2, 30, 2, 1211, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 419, 2, 2, 2, 1211, 2, 2, 2, 51, 2, 2, 51, 2, 2, 2, 199, 2, 2, 2, 1109, 2, 2, 2, 2, 2, 2, 2, 2, 1211, 2, 2, 419, 2, 2, 2, 2, 2, 199, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "Loading vien_train_dataset:\n",
      "self.source_sentences = [3018, 2843, 137, 44, 2, 2843, 137, 1836, 2, 44, 1830, 5219, 2, 1082, 44, 888, 2, 1928, 137, 2682, 2, 2682, 434, 8, 888, 2, 8, 2, 1593, 8, 2, 8953, 2843, 434, 2, 2843, 44, 888]\n",
      "self.target_sentences = [7417, 7, 22911, 2, 10626, 10760, 2, 6843, 14360, 35190, 10626, 2, 4493, 2, 10626, 2, 113, 22911, 14360, 10626, 595, 22911, 10626, 2, 22436, 10626, 2, 14360, 595, 45, 2, 7, 2, 22911, 10760, 14360, 391, 7, 294, 10626, 2, 2, 10626, 7, 45, 10760, 14360, 595, 10626]\n",
      "\n",
      "Loading vien_dev_dataset:\n",
      "self.source_sentences = [2, 2, 160, 2, 2, 83, 160, 2, 2, 83, 2, 2, 2, 2, 83, 2, 2, 83, 160, 2, 2, 2, 2, 160, 2, 2, 33, 2, 2, 2, 2, 33, 2, 2, 2, 160, 45, 394, 2, 2, 160, 45, 2, 2, 2, 33, 2, 33, 2, 2, 2, 394, 83, 2, 2, 2, 83, 2, 2, 2, 2, 33, 2, 2, 2, 2, 45, 2, 2, 2, 2, 45, 2, 2, 160, 83, 160, 2, 2, 33, 2, 2, 83, 160, 2, 2, 2, 394, 83, 2, 2, 2, 2, 33, 2, 2, 2, 33, 160, 2, 1325, 2, 394, 2, 2, 2, 2, 33, 2, 2, 2, 33, 2, 2, 2, 2, 83, 2, 2, 160, 2, 2, 2, 33, 160, 2, 2, 2, 45, 2, 2, 2, 160, 2, 2, 2, 38, 2, 2, 2]\n",
      "self.target_sentences = [2, 2, 2, 2, 2, 3, 2, 2, 17, 95, 2, 2, 2, 108, 108, 2, 2, 2, 3, 2, 108, 2, 2, 2, 2, 2, 108, 2, 532, 2, 2, 2, 2, 2, 2, 108, 2, 2, 2, 2, 17, 95, 2, 108, 2, 2, 2, 2, 2, 95, 108, 2, 2, 2, 2, 108, 2, 2, 2, 2, 2, 17, 2, 2, 108, 2, 17, 2, 584, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 95, 2, 2, 2, 2, 2, 2, 2, 17, 2, 95, 2, 2, 2, 2, 2, 17, 2, 2, 2, 584, 2, 2, 2, 2, 108, 2, 2, 2, 108, 2, 2, 2, 2, 2, 2, 2, 2, 1776, 2, 2, 2, 2, 2, 1776, 2, 2, 2, 2, 2, 2, 2, 108, 2]\n"
     ]
    }
   ],
   "source": [
    "## TODO \n",
    "\n",
    "MAX_SENTENCE_LENGTH = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# zhen token2index vocabs\n",
    "zhen_zh_train_token2id = zhen_zh_train.word2index\n",
    "zhen_en_train_token2id = zhen_en_train.word2index\n",
    "\n",
    "# vien token2index vocabs\n",
    "vien_vi_train_token2id = vien_vi_train.word2index\n",
    "vien_en_train_token2id = vien_en_train.word2index\n",
    "\n",
    "class TranslationDataset():\n",
    "    \"\"\"\n",
    "    Class that represents a train/dev/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 data_source, # training indices data of the source language\n",
    "                 data_target, # training indices data of the target language\n",
    "                 token2id_source=None, # token2id dict of the source language\n",
    "                 token2id_target=None  # token2id dict of the target language\n",
    "                ):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.source_sentences = data_source\n",
    "        self.target_sentences = data_target\n",
    "        print(\"self.source_sentences = \" + str(self.source_sentences[0]))\n",
    "        print(\"self.target_sentences = \" + str(self.target_sentences[0]))\n",
    "        \n",
    "        self.token2id_source = token2id_source\n",
    "        self.token2id_target = token2id_target\n",
    "        # prints the mandarin token -> # dictionary\n",
    "        \"\"\"\n",
    "        It also contains wrong tokenized words & Latin Alphabet words too\n",
    "        '11<EOS>': 13275, '为啥': 13276, '指责': 13277, '超载': 13278, \n",
    "        '复杂度': 13279, '小玩意': 13280, '小玩意儿': 13281, '此行': 13282, \n",
    "        '断面': 13283, '强制': 13284, '制发': 13285, '花瓶': 13286,\n",
    "        '糖': 13287, '年缴': 13288, '缴纳': 13289, '会费': 13290,\n",
    "        '99': 13291, 'Photoshop': 13292, '4000<EOS>': 13293, \n",
    "        '升级': 13294, '佯': 13295, '谬': 13296, 'Microsoft': 13297, \n",
    "        'Word': 13298, '文字': 13299,\n",
    "        \"\"\"\n",
    "#         print(\"self.token2id_source = \" + str(self.token2id_source))\n",
    "        # prints the english token -> # dictionary\n",
    "#         print(\"self.token2id_target = \" + str(self.token2id_target))        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_sentences)\n",
    "\n",
    "    def __getitem__(self, batch_index):\n",
    "\n",
    "#         source_word_idx, target_word_idx = [], []\n",
    "        source_mask, target_mask = [], []\n",
    "        \n",
    "        for index in self.source_sentences[batch_index][:MAX_SENTENCE_LENGTH]:\n",
    "            if index != UNK_IDX:\n",
    "                source_mask.append(0)\n",
    "            else:\n",
    "                source_mask.append(1)\n",
    "                \n",
    "        for index in self.target_sentences[batch_index][:MAX_SENTENCE_LENGTH]:\n",
    "            if index != UNK_IDX:\n",
    "                target_mask.append(0)\n",
    "            else:\n",
    "                target_mask.append(1)\n",
    "        \n",
    "        source_indices = self.source_sentences[batch_index][:MAX_SENTENCE_LENGTH]\n",
    "        target_indices = self.target_sentences[batch_index][:MAX_SENTENCE_LENGTH]\n",
    "        \n",
    "        source_list = [source_indices, source_mask, len(source_indices)]\n",
    "        target_list = [target_indices, target_mask, len(target_indices)]\n",
    "        \n",
    "        return source_list + target_list\n",
    "\n",
    "    \n",
    "def translation_collate(batch, max_sentence_length):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the \n",
    "    batch so that all data have the same length\n",
    "    \"\"\"\n",
    "    source_data, target_data = [], []\n",
    "    source_mask, target_mask = [], []\n",
    "    source_lengths, target_lengths = [], []\n",
    "\n",
    "    for datum in batch:\n",
    "        source_lengths.append(datum[2])\n",
    "        target_lengths.append(datum[5])\n",
    "        \n",
    "        # PAD\n",
    "        source_data_padded = np.pad(np.array(datum[0]), \n",
    "                                    pad_width=((0, MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", \n",
    "                                    constant_values=0)\n",
    "        source_data.append(source_data_padded)\n",
    "        \n",
    "        source_mask_padded = np.pad(np.array(datum[1]), \n",
    "                                    pad_width=((0, MAX_SENTENCE_LENGTH-datum[2])),\n",
    "                                mode=\"constant\", \n",
    "                                    constant_values=0)\n",
    "        source_mask.append(source_mask_padded)\n",
    "        \n",
    "        target_data_padded = np.pad(np.array(datum[3]), pad_width=((0, MAX_SENTENCE_LENGTH-datum[5])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        target_data.append(target_data_padded)\n",
    "        \n",
    "        target_mask_padded = np.pad(np.array(datum[4]), pad_width=((0, MAX_SENTENCE_LENGTH-datum[5])),\n",
    "                               mode=\"constant\", constant_values=0)\n",
    "        target_mask.append(target_mask_padded)\n",
    "        \n",
    "    ind_dec_order = np.argsort(source_lengths)[::-1]\n",
    "    source_data = np.array(source_data)[ind_dec_order]\n",
    "    target_data = np.array(target_data)[ind_dec_order]\n",
    "    source_mask = np.array(source_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    target_mask = np.array(target_mask)[ind_dec_order].reshape(len(batch), -1, 1)\n",
    "    source_lengths = np.array(source_lengths)[ind_dec_order]\n",
    "    target_lengths = np.array(target_lengths)[ind_dec_order]\n",
    "    \n",
    "    source_list = [torch.from_numpy(source_data), \n",
    "               torch.from_numpy(source_mask).float(), source_lengths]\n",
    "    target_list = [torch.from_numpy(target_data), \n",
    "               torch.from_numpy(target_mask).float(), target_lengths]\n",
    "        \n",
    "    return source_list + target_list\n",
    "\n",
    "print(\"Loading zhen_train_dataset:\")\n",
    "zhen_train_dataset = TranslationDataset(zhen_zh_train_indices,\n",
    "                                       zhen_en_train_indices,\n",
    "                                       token2id_source=zhen_zh_train_token2id,\n",
    "                                       token2id_target=zhen_en_train_token2id)\n",
    "\n",
    "zhen_train_loader = torch.utils.data.DataLoader(dataset=zhen_train_dataset,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                               shuffle=False)\n",
    "\n",
    "print(\"\\nLoading zhen_dev_dataset:\")\n",
    "zhen_dev_dataset = TranslationDataset(zhen_zh_dev_indices,\n",
    "                                       zhen_en_dev_indices,\n",
    "                                       token2id_source=zhen_zh_train_token2id,\n",
    "                                       token2id_target=zhen_en_train_token2id)\n",
    "\n",
    "zhen_dev_loader = torch.utils.data.DataLoader(dataset=zhen_dev_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                             shuffle=False)\n",
    "\n",
    "print(\"\\nLoading vien_train_dataset:\")\n",
    "vien_train_dataset = TranslationDataset(vien_vi_train_indices,\n",
    "                                       vien_en_train_indices,\n",
    "                                       token2id_source=vien_vi_train_token2id,\n",
    "                                       token2id_target=vien_en_train_token2id)\n",
    "\n",
    "vien_train_loader = torch.utils.data.DataLoader(dataset=vien_train_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                             shuffle=False)\n",
    "\n",
    "print(\"\\nLoading vien_dev_dataset:\")\n",
    "vien_dev_dataset = TranslationDataset(vien_vi_dev_indices,\n",
    "                                       vien_en_dev_indices,\n",
    "                                       token2id_source=vien_vi_train_token2id,\n",
    "                                       token2id_target=vien_en_train_token2id)\n",
    "\n",
    "vien_dev_loader = torch.utils.data.DataLoader(dataset=vien_dev_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "                             shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "#### SAMPLE DATASET - CLEAR OUT LATER ####\n",
    "##########################################\n",
    "\n",
    "# zhen_train_dataset = TranslationDataset(zhen_zh_train_indices[:480], # 15 batches\n",
    "#                                        zhen_en_train_indices[:480],\n",
    "#                                        token2id_source=zhen_zh_train_token2id,\n",
    "#                                        token2id_target=zhen_en_train_token2id)\n",
    "\n",
    "# zhen_train_loader = torch.utils.data.DataLoader(dataset=zhen_train_dataset,\n",
    "#                                batch_size=BATCH_SIZE,\n",
    "#                                collate_fn=lambda x, max_sentence_length=MAX_SENTENCE_LENGTH: translation_collate(x, MAX_SENTENCE_LENGTH),\n",
    "#                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Evaluation Metric\n",
    "\n",
    "We use BLEU as the evaluation metric. Specifically, we focus on the corpus-level BLEU function. \n",
    "\n",
    "The code for BLEU is taken from https://github.com/mjpost/sacreBLEU/blob/master/sacrebleu.py#L1022-L1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in /Users/atakanokan/anaconda/lib/python3.6/site-packages (1.2.12)\n",
      "Requirement already satisfied: typing in /Users/atakanokan/anaconda/lib/python3.6/site-packages (from sacrebleu) (3.6.6)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Beam Search Algorithm\n",
    "\n",
    "In this section, we implement the Beam Search algorithm in Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Model\n",
    "\n",
    "1. Recurrent neural network based encoder-decoder without attention\n",
    "2. Recurrent neural network based encoder-decoder with attention\n",
    "2. Replace the recurrent encoder with either convolutional or self-attention based encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reconstruction loss = binary cross entropy between two (vocab_size x 1) vectors\n",
    "# used during training, since we can compare the real Y and and the generated Y\n",
    "# still at each time step of the decoder, we compare up to and including\n",
    "# the real t-th token and the generated t-th, then optimize\n",
    "\n",
    "def loss_function(y_hat, y):\n",
    "    \n",
    "    \"\"\"Takes as input;\n",
    "    - y: correct \"log-softmax\"(binary vector) that represents the correct t-th token in the target sentence,\n",
    "                 (vocab_size x 1) vector\n",
    "    - y_hat: predicted LogSoftmax for the predicted t-th token in the target sentence.\n",
    "             (vocab_size x 1) vector\n",
    "    Returns;\n",
    "    - NLL Loss in training time\"\"\"\n",
    "#     y_hat = torch.log(y_hat) # log softmax\n",
    "    loss = nn.functional.binary_cross_entropy(y_hat,y)\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "# generation/inference time - validation loss = BLEU\n",
    "\n",
    "def compute_BLEU(corpus_hat,corpus):\n",
    "    ## TODO\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([7., 5., 4.]), tensor([3, 4, 1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([3,4,2,7,5,3,2]).topk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "class BeamSearch(nn.Module):\n",
    "    \n",
    "    \"\"\"network that conducts beam search over the outputs of\n",
    "     any translator network. The translator networks that can \n",
    "     be passed are:\n",
    "     \n",
    "     - Translate (for RNN-enc-dec),\n",
    "     - AttnTranslate (for RNN-enc-dec with attention),\n",
    "     - CNNtranslate (for CNN-encoder based translation).\n",
    "     \n",
    "     The translation networks take care of the encoder-decoder\n",
    "     choices specific to each task. Please see in below sections.\"\"\"\n",
    "\n",
    "    def __init__(self, translator_network, beam_size):\n",
    "        super().__init__()\n",
    "        # translator network that returns the logsoftmax\n",
    "        # over vocabulary size:(vocab_size, 1)\n",
    "        self.translator_network = translator_network\n",
    "        self.beam_size = beam_size\n",
    "        \n",
    "    def init_search_tree(self, batch_size):\n",
    "        beam_size = self.beam_size\n",
    "        self.search_tree = torch.empty(batch_size, beam_size, 1)\n",
    "        return self\n",
    "    \n",
    "    def init_score_tree(self, batch_size):\n",
    "        beam_size = self.beam_size\n",
    "        search_tree = self.search_tree\n",
    "        self.score_tree = torch.zeros(search_tree.size())\n",
    "        return self\n",
    "    \n",
    "    def forward(source_sentence, source_mask, source_lengths,\n",
    "                target_sentence, target_mask, target_lengths):\n",
    "        \n",
    "        self.init_search_tree(BATCH_SIZE)\n",
    "        self.init_score_tree(BATCH_SIZE)\n",
    "        \n",
    "        # at each time step the decoder will give us the logsoftmax\n",
    "        # of one token (batch_size, vocab_size). \n",
    "        output = model(source_sentence, target_sentence,source_mask, \n",
    "                       target_mask, source_lengths,target_lengths)\n",
    "        \n",
    "        # for each sentence in the batch we get the top k predictions\n",
    "        # for each token and append it to the search and score trees. \n",
    "        for i in range(BATCH_SIZE):\n",
    "            beam = output[i].topk(beam_size) # (token scores, token indices)\n",
    "            # cat instead\n",
    "            self.search_tree[i] = self.search_tree.cat(beam[1]) # cat the indices to the search tree\n",
    "            self.score_tree[i,:] = beam[0] # append the scores to the score tree \n",
    "        \n",
    "        # we will sum the logs \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: RNN-based Encoder-Decoder without Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_softmax(tensor_of_indices,\n",
    "                       batch_size,\n",
    "                       vocab_size = len(zhen_en_train_token2id)):\n",
    "    \"\"\"\n",
    "    - takes as input a time_step vector of the batch (t-th token of each sentence in the batch)\n",
    "      size: (batch_size, 1)\n",
    "    - converts it to softmax of (batch_size, vocab_size)\n",
    "    \"\"\"\n",
    "    index_tensor_ = tensor_of_indices.view(-1,1).long()\n",
    "        \n",
    "    one_hot = torch.FloatTensor(batch_size, vocab_size).zero_()\n",
    "    one_hot.scatter_(1, index_tensor_.detach().cpu(), 1)\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully self-attention Translation System / Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)    \n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "    \n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "    \n",
    "    \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "    \n",
    "    \n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    \n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "    \n",
    "    \n",
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "#             nn.init.xavier_uniform_(p)\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(10, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(10, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model = make_model(10, 10, 2)\n",
    "tmp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        \n",
    "        # creates a copy of the Variable\n",
    "        true_dist = x.data.clone()\n",
    "        print(\"true_dist = \" + str(true_dist))\n",
    "        \n",
    "        # Fills self tensor with the specified value\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2.0))\n",
    "        print(\"true_dist = \" + str(true_dist))\n",
    "        \n",
    "        # scatter_(dim, index, src) → Tensor\n",
    "        print(\"self.confidence = \" + str(self.confidence))\n",
    "        true_dist.scatter_(dim = 1, \n",
    "                           index = target.data.unsqueeze(1), \n",
    "                           src = self.confidence)\n",
    "        \n",
    "        true_dist[:, self.padding_idx] = 0.\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "#         if mask.dim() > 0:\n",
    "        if mask.sum() > 0 and len(mask) > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atakanokan/anaconda/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "crit = LabelSmoothing(5, 0, 0.1)\n",
    "def loss(x):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d],\n",
    "                                 ])\n",
    "    #print(predict)\n",
    "    return crit(Variable(predict.log()),\n",
    "                 Variable(torch.LongTensor([1]))).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        x_loss = x.contiguous().view(-1, x.size(-1)).float()\n",
    "        y_loss = y.contiguous().view(-1)\n",
    "        loss = self.criterion(x_loss, y_loss) / norm\n",
    "                              \n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.data[0] * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/atakanokan/anaconda/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true_dist = tensor([[-1.9340, -4.1510, -2.6695,  ..., -2.6970, -3.7252, -1.2385],\n",
      "        [-2.3561, -1.1062, -3.0696,  ..., -2.7260, -3.8816, -1.6418],\n",
      "        [-3.7725, -2.3680, -4.6145,  ..., -4.4205, -4.0762, -1.8362],\n",
      "        ...,\n",
      "        [-2.7200, -1.7991, -4.6643,  ..., -1.3054, -5.5390, -1.0155],\n",
      "        [-3.3538, -1.7163, -2.9694,  ..., -2.2880, -3.2859, -2.1620],\n",
      "        [-4.2577, -1.2764, -2.6886,  ..., -2.4744, -2.3833, -1.3999]])\n",
      "true_dist = tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "self.confidence = 1.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "scatter_() received an invalid combination of arguments - got (src=float, index=Tensor, dim=int, ), but expected one of:\n * (int dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mdim=int\u001b[0m, \u001b[32;1mindex=Tensor\u001b[0m, \u001b[31;1msrc=float\u001b[0m, )\n * (int dim, Tensor index, Number value)\n      didn't match because some of the keywords were incorrect: src\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-85d1304a84b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m               loss_compute = SimpleLossCompute(generator = model.generator, \n\u001b[1;32m     22\u001b[0m                                                \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                                                opt = model_opt))\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     print(run_epoch(data_iter = data_gen(V, 30, 5), \n",
      "\u001b[0;32m<ipython-input-51-f8ba8985578c>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(data_iter, model, loss_compute)\u001b[0m\n\u001b[1;32m      8\u001b[0m         out = model.forward(batch.src, batch.trg, \n\u001b[1;32m      9\u001b[0m                             batch.src_mask, batch.trg_mask)\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrg_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_tokens\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mntokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-9381dbd08ad8>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, y, norm)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-117-7ead1d9e8554>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     25\u001b[0m         true_dist.scatter_(dim = 1, \n\u001b[1;32m     26\u001b[0m                            \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                            src = self.confidence)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtrue_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter_() received an invalid combination of arguments - got (src=float, index=Tensor, dim=int, ), but expected one of:\n * (int dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mdim=int\u001b[0m, \u001b[32;1mindex=Tensor\u001b[0m, \u001b[31;1msrc=float\u001b[0m, )\n * (int dim, Tensor index, Number value)\n      didn't match because some of the keywords were incorrect: src\n"
     ]
    }
   ],
   "source": [
    "V = 11\n",
    "\n",
    "criterion = LabelSmoothing(size=V, \n",
    "                           padding_idx=0, \n",
    "                           smoothing=0.0)\n",
    "\n",
    "model = make_model(V, V, N=2)\n",
    "\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, \n",
    "                    1, \n",
    "                    400,\n",
    "                    torch.optim.Adam(model.parameters(), \n",
    "                                     lr=0, \n",
    "                                     betas=(0.9, 0.98), \n",
    "                                     eps=1e-9))\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    run_epoch(data_iter = data_gen(V, 30, 20), \n",
    "              model = model, \n",
    "              loss_compute = SimpleLossCompute(generator = model.generator, \n",
    "                                               criterion = criterion, \n",
    "                                               opt = model_opt))\n",
    "    model.eval()\n",
    "    print(run_epoch(data_iter = data_gen(V, 30, 5), \n",
    "                    model = model, \n",
    "                    loss_compute = SimpleLossCompute(generator = model.generator, \n",
    "                                                     criterion = criterion, \n",
    "                                                     opt = None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
